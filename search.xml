<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
    
    <entry>
      <title><![CDATA[Kylin 在 CDH 中的安装、错误解决]]></title>
      <url>http://yoursite.com/2017/06/21/Kylin%20%E5%9C%A8%20CDH%20%E4%B8%AD%E7%9A%84%E5%AE%89%E8%A3%85%E3%80%81%E9%94%99%E8%AF%AF%E8%A7%A3%E5%86%B3/</url>
      <content type="html"><![CDATA[<h2 id="Apache-Kylin"><a href="#Apache-Kylin" class="headerlink" title="Apache Kylin"></a>Apache Kylin</h2><p>中文名麒（shen）麟（shou） 是Hadoop动物园的重要成员。Apache Kylin是一个开源的分布式分析引擎，最初由eBay开发贡献至开源社区。它提供Hadoop之上的SQL查询接口及多维分析（OLAP）能力以支持大规模数据，能够处理TB乃至PB级别的分析任务，能够在亚秒级查询巨大的Hive表，并支持高并发。</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><ul>
<li>CDH 5.10.0</li>
<li>apache-kylin-1.6.0-cdh5.7-bin</li>
</ul>
<p><em>官网建议 CDH 5.10 安装 Kylin 2.0 ，尝试后发现部分查询有问题，后又换成 1.6.0 版本</em></p>
<a id="more"></a>
<h3 id="下载并解压到-opt-目录"><a href="#下载并解压到-opt-目录" class="headerlink" title="下载并解压到 /opt 目录"></a>下载并解压到 /opt 目录</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">tar zvxf apache-kylin-1.5.2.1-cdh5.7-bin.tar -C /opt</div><div class="line"></div><div class="line">mv /opt/apache-kylin-1.6.0-cdh5.7-bin /opt/kylin-1.6.0</div></pre></td></tr></table></figure>
<h3 id="赋予权限"><a href="#赋予权限" class="headerlink" title="赋予权限"></a>赋予权限</h3><ul>
<li>kylin 运行用户必须有，hdfs,hive,hbase 操作权限</li>
<li>/opt/kylin-1.6.0 以下目录，当前用户必须有读写修改权限</li>
</ul>
<h3 id="环境变量-etc-profile"><a href="#环境变量-etc-profile" class="headerlink" title="环境变量 /etc/profile"></a>环境变量 /etc/profile</h3><p>添加以下变量<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">export KYLIN_HOME=/opt/kylin-1.6.0</div><div class="line">export HCAT_HOME=/opt/cloudera/parcels/CDH/lib/hive-hcatalog</div></pre></td></tr></table></figure></p>
<p>由于使用的是 CDH 集群，其它组件环境已经配置好，只需配以上变量即可</p>
<h3 id="配置-kylin-properties"><a href="#配置-kylin-properties" class="headerlink" title="配置 kylin.properties"></a>配置 kylin.properties</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"># 修改</div><div class="line">kylin.hive.client=beeline</div><div class="line">kylin.hive.beeline.params=-n hive --hiveconf hive.security.authorization.sqlstd.confwhitelist.append=&apos;mapreduce.job.*|dfs.*&apos; -u &apos;jdbc:hive2://master:10000&apos;</div><div class="line"></div><div class="line"># 增加</div><div class="line">kylin.job.jar=/opt/kylin-1.6.0/lib/kylin-job-1.6.0.jar</div><div class="line">kylin.coprocessor.local.jar=/opt/kylin-1.6.0/lib/kylin-coprocessor-1.6.0.jar</div><div class="line">kylin.job.yarn.app.rest.check.status.url=http://master:8088/ws/v1/cluster/apps/$&#123;job_id&#125;?anonymous=true</div><div class="line"># kylin.job.mr.lib.dir=/opt/cloudera/parcels/CDH/lib/sentry/lib</div></pre></td></tr></table></figure>
<h3 id="环境检查"><a href="#环境检查" class="headerlink" title="环境检查"></a>环境检查</h3><p><code>/opt/kylin-1.6.0/bin</code> 目录下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">./find-hive-dependency.sh</div><div class="line"></div><div class="line">./find-hbase-dependency.sh</div><div class="line"></div><div class="line">./check-env.sh</div></pre></td></tr></table></figure></p>
<h3 id="导入测试数据"><a href="#导入测试数据" class="headerlink" title="导入测试数据"></a>导入测试数据</h3><p><code>./sample.sh</code></p>
<h3 id="启动-Kylin"><a href="#启动-Kylin" class="headerlink" title="启动 Kylin"></a>启动 Kylin</h3><p><code>./kylin.sh start</code></p>
<h3 id="访问-web-界面"><a href="#访问-web-界面" class="headerlink" title="访问 web 界面"></a>访问 web 界面</h3><p>登录后台：<a href="http://xxxxx:7070/kylin" target="_blank" rel="external">http://xxxxx:7070/kylin</a><br>账号密码：ADMIN/KYLIN</p>
<h2 id="问题解决"><a href="#问题解决" class="headerlink" title="问题解决"></a>问题解决</h2><h3 id="HDFS-权限"><a href="#HDFS-权限" class="headerlink" title="HDFS 权限"></a>HDFS 权限</h3><ul>
<li><code>dfs.permissions</code> 设置为 false</li>
<li>目录权限可使用，<code>hdfs dfs -chmod -R 777 /</code></li>
</ul>
<h3 id="kylin-2-0-版本中查询问题"><a href="#kylin-2-0-版本中查询问题" class="headerlink" title="kylin 2.0 版本中查询问题"></a>kylin 2.0 版本中查询问题</h3><p><code>./kylin.sh org.apache.kylin.storage.hbase.util.DeployCoprocessorCLI /opt/kylin-1.6.0/lib/kylin-coprocessor-1.6.0.jar all</code></p>
<h3 id="构建-Cube-出错"><a href="#构建-Cube-出错" class="headerlink" title="构建 Cube 出错"></a>构建 Cube 出错</h3><p><img src="http://i.imgur.com/7579dPy.png" alt=""></p>
<p>如图，一直卡在构建 cube 的第三步，相应 mapreduce 任务在 map 阶段出错<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Error: java.lang.ClassNotFoundException: org.apache.hadoop.hive.serde2.typeinfo.TypeInfo at java.net.URLClassLoader$1.run(URLClassLoader.java:366) at java.net.URLClassLoader$1.run(URLClassLoader.java:355) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:354) at java.lang.ClassLoader.loadClass(ClassLoader.java:425) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308) at java.lang.ClassLoader.loadClass(ClassLoader.java:358) at java.lang.Class.forName0(Native Method) at java.lang.Class.forName(Class.java:270) at org.apache.hadoop.conf.Configuration.getClassByNameOrNull(Configuration.java:2138) at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2103) at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2197) at org.apache.hadoop.mapreduce.task.JobContextImpl.getInputFormatClass(JobContextImpl.java:184) at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:749) at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341) at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1796) at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)</div></pre></td></tr></table></figure></p>
<p>google 一番后,发现如下解决方案</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">I can still confirm this issue with kylin version 2.0 on cloudera CDH 5.11. I tried the exports (setting them to the parcel directory), but the error </div><div class="line">still appeared.</div><div class="line">Adding kylin.job.mr.lib.dir=/opt/cloudera/parcels/CDH/lib/sentry/lib to the kylin.properties helped though.</div><div class="line">Thanks for the workaround and help</div><div class="line"></div><div class="line"></div><div class="line">Since 2.0, another workaround other than the &quot;kylin.engine.mr.lib-dir&quot; is set the below env vars.</div><div class="line">export HADOOP_CONF_DIR=/etc/hadoop/conf</div><div class="line">export HIVE_LIB=/usr/lib/hive</div><div class="line">export HIVE_CONF=/etc/hive/conf</div><div class="line">export HCAT_HOME=/usr/lib/hive-hcatalog</div><div class="line">Then &quot;bin/find-hive-dependencies.sh&quot; should pick up the right hive jars.</div></pre></td></tr></table></figure>
<p>最后在 kylin.properties 中添加 <code>kylin.job.mr.lib.dir=/opt/cloudera/parcels/CDH/lib/sentry/lib</code> 解决</p>
]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Kylin </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Centos虚拟机克隆后的ip、mac、uuid 修改]]></title>
      <url>http://yoursite.com/2017/05/19/Centos%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%85%8B%E9%9A%86%E5%90%8E%E7%9A%84%20ip%E3%80%81mac%20%E4%BF%AE%E6%94%B9/</url>
      <content type="html"><![CDATA[<h2 id="方法一："><a href="#方法一：" class="headerlink" title="方法一："></a>方法一：</h2><h3 id="修改ip-mac地址（HWADDR），删除UUID项"><a href="#修改ip-mac地址（HWADDR），删除UUID项" class="headerlink" title="修改ip,mac地址（HWADDR），删除UUID项"></a>修改ip,mac地址（HWADDR），删除UUID项</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">vi /etc/sysconfig/network-scripts/ifcfg-eth0</div><div class="line"></div><div class="line">DEVICE=eth0 </div><div class="line">TYPE=Ethernet</div><div class="line">ONBOOT=yes</div><div class="line">NM_CONTROLLED=yes</div><div class="line">BOOTPROTO=static</div><div class="line">IPADDR=10.1.18.212</div><div class="line">DNS1=your dns</div><div class="line">DNS2=8.8.8.8</div><div class="line">GATEWAY=10.1.18.254</div></pre></td></tr></table></figure>
<h3 id="删除旧网卡"><a href="#删除旧网卡" class="headerlink" title="删除旧网卡"></a>删除旧网卡</h3><p><code>vi /etc/udev/rules.d/70-persistent-net.rules</code><br>可以看到会有2张PCI device网卡，删除eth0那行，再把eth1的那行里的”eh1”改成”eth0”。</p>
<a id="more"></a>
<h2 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h2><p>造成这样的原因，是因为在虚拟机（Vmware）中移动了Centos系统对应的文件，导致重新配置时，网卡的MAC地址变了，输入<code>ifconfig -a</code>,找不到eth0</p>
<p>安装完一个centos虚拟机，又拷贝一份，开机后网卡无法正常启动，报错：Device eth0 does not seem to be present,<br>delaying initialization</p>
<p>解决：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mv /etc/sysconfig/network-scripts/ifcfg-eth0 </div><div class="line">sysconfig/network-scripts/ifcfg-eth1</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vim  sysconfig/network-scripts/ifcfg-eth1</div></pre></td></tr></table></figure>
<p>修改DEVICE=”eth0”<br>为DEVICE=”eth1”<br>修改IP地址，删除mac地址（HWADDR），删除UUID项。<br>然后重启启动网卡尝试下</p>
<h2 id="方法三"><a href="#方法三" class="headerlink" title="方法三"></a>方法三</h2><p>###获取HWaddr</p>
<p>步骤1.：<code>vi /etc/udev/rules.d/70-persistent-net.rules</code> 显示为：</p>
<pre><code># PCI device 0x8086:0x100f (e1000)
SUBSYSTEM==&quot;net&quot;, ACTION==&quot;add&quot;, DRIVERS==&quot;?*&quot;, ATTR{address}==&quot;00:0c:29:27:a7:ab&quot;, ATTR{type}==&quot;1&quot;,    KERNEL==&quot;eth*&quot;, NAME=&quot;eth0&quot;

 # PCI device 0x8086:0x100f (e1000)
 SUBSYSTEM==&quot;net&quot;, ACTION==&quot;add&quot;, DRIVERS==&quot;?*&quot;, ATTR{address}==&quot;00:0c:29:73:84:7f&quot;, ATTR{type}==&quot;1&quot;, KERNEL==&quot;eth*&quot;, NAME=&quot;eth1&quot;
</code></pre><p>步骤2 ：vi /etc/sysconfig/network-scripts/</p>
<pre><code> 如果里面是ifcfg-eth0:

        那么将步骤1的NAME=&quot;eth1&quot;对应的ATTR{address}==&quot;00:0c:29:73:84:7f&quot;赋值给HWaddr；

反之，则是将ATTR{address}==&quot;00:0c:29:27:a7:ab&quot;赋值给HWaddr。
</code></pre><p>这样我们就得到了HWaddr的值</p>
<h3 id="获取UUID"><a href="#获取UUID" class="headerlink" title="获取UUID"></a>获取UUID</h3><p>在克隆时，会设置</p>
<p>在该位置设置的文件夹下会找到564d9b3a-a4b0-08bd-046f-af70789026cc.vmem.lck类似这样的文件夹，那么564d9b3a-a4b0-08bd-046f-af70789026cc就是所谓的UUID。</p>
<p>最后就是将ifcfg-eth0改成ifcfg-eth1或者相反。</p>
]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hexo 更换电脑重新部署]]></title>
      <url>http://yoursite.com/2017/05/17/Hexo%20%E6%9B%B4%E6%8D%A2%E7%94%B5%E8%84%91%E9%87%8D%E6%96%B0%E9%83%A8%E7%BD%B2/</url>
      <content type="html"><![CDATA[<h2 id="拷贝原博客文件"><a href="#拷贝原博客文件" class="headerlink" title="拷贝原博客文件"></a>拷贝原博客文件</h2><p>必须拷贝文件：<br>├──_config.yml<br>├── theme<br>├── scaffolds #文章模板<br>├── package.json #说明使用哪些包<br>├── .gitignore #限定在提交的时候哪些文件可以忽略<br>└── source</p>
<a id="more"></a>
<p>（1）讨论下哪些文件是必须拷贝的：首先是之前自己修改的文件，像站点配置_config.yml，theme文件夹里面的主题，以及source里面自己写的博客文件，这些肯定要拷贝的。除此之外，还有三个文件需要有，就是scaffolds文件夹（文章的模板）、package.json（说明使用哪些包）和.gitignore（限定在提交的时候哪些文件可以忽略）。其实，这三个文件不是我们修改的，所以即使丢失了，也没有关系，我们可以建立一个新的文件夹，然后在里面执行hexo init，就会生成这三个文件，我们只需要将它们拷贝过来使用即可。总结：_config.yml，theme/，source/，scaffolds/，package.json，.gitignore，是需要拷贝的。</p>
<p>（2）再讨论下哪些文件是不必拷贝的，或者说可以删除的：首先是.git文件，无论是在站点根目录下，还是主题目录下的.git文件，都可以删掉。然后是文件夹node_modules（在用npm install会重新生成），public（这个在用hexo g时会重新生成），.deploy_git文件夹（在使用hexo d时也会重新生成），db.json文件。其实上面这些文件也就是是.gitignore文件里面记载的可以忽略的内容。总结：.git/，node_modules/，public/，.deploy_git/，db.json文件需要删除。</p>
<h2 id="环境部署"><a href="#环境部署" class="headerlink" title="环境部署"></a>环境部署</h2><h3 id="安装-Git"><a href="#安装-Git" class="headerlink" title="安装 Git"></a>安装 Git</h3><p>从官网Git下载git，在新电脑上安装，因为https速度慢，而且每次都要输入口令，常用的是使用ssh。使用下面方法创建：</p>
<ol>
<li><p>打开git bash，设置用户名称和邮件地址</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ git config --global user.name &quot;username&quot;</div><div class="line">$ git config --global user.email &quot;username@example.com&quot;</div></pre></td></tr></table></figure>
</li>
<li><p>在用户主目录下运行：ssh-keygen -t rsa -C “youremail@example.com” 把其中的邮件地址换成自己的邮件地址，然后一路回车</p>
</li>
<li><p>最后完成后，会在用户主目录下生成.ssh目录，里面有id_rsa和id_rsa.pub两个文件，这两个就是SSH key密钥对，id_rsa是私钥，千万不能泄露出去，id_rsa.pub是公钥，可以放心地告诉任何人。</p>
</li>
<li><p>登陆GitHub，打开「Settings」-&gt;「SSH and GPG keys」，然后点击「new SSH key」，填上任意Title，在Key文本框里粘贴公钥id_rsa.pub文件的内容（千万不要粘贴成私钥了！），最后点击「Add SSH Key」，你就应该看到已经添加的Key。</p>
</li>
</ol>
<h3 id="安装Node-JS"><a href="#安装Node-JS" class="headerlink" title="安装Node.JS"></a>安装Node.JS</h3><h3 id="安装-Hexo"><a href="#安装-Hexo" class="headerlink" title="安装 Hexo"></a>安装 Hexo</h3><p>打开git bash客户端，输入 <code>npm install hexo-cli -g</code>，开始安装hexo<br>由于之前我是用 <code>npm install hexo -g</code> 安装的，此处我使用这个命令。因为我用 <code>npm install hexo-cli -g</code>命令安装后出现无法提交的情况，可能版本问题。</p>
<h3 id="安装模块"><a href="#安装模块" class="headerlink" title="安装模块"></a>安装模块</h3><p>在git bash中切换目录到新拷贝的文件夹里，使用 <code>npm install</code> 命令，进行模块安装。</p>
<p><strong>不要用hexo init初始化，部分文件已经拷贝生成，如果不慎使用，则站点配置文件_config.yml会被初始化为默认值</strong></p>
<h3 id="同步至Github"><a href="#同步至Github" class="headerlink" title="同步至Github"></a>同步至Github</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hexo g</div><div class="line">hexo d</div></pre></td></tr></table></figure>
<h3 id="其它组件"><a href="#其它组件" class="headerlink" title="其它组件"></a>其它组件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ npm install npm install hexo-deployer-git --save #同步内容至github，若前面同步不成功就安装这个</div><div class="line">$ npm install hexo-generator-feed --save #RSS订阅</div><div class="line">$ npm install hexo-generator-sitemap --save #站点地图</div></pre></td></tr></table></figure>
<p>参考</p>
<blockquote>
<p><a href="https://www.zhihu.com/question/21193762/answer/103097754" target="_blank" rel="external">https://www.zhihu.com/question/21193762/answer/103097754</a><br><a href="http://puhemo.xyz/2016/06/03/hexo-change-pc/" target="_blank" rel="external">http://puhemo.xyz/2016/06/03/hexo-change-pc/</a><br><a href="https://hexo.io/zh-cn/docs/index.html" target="_blank" rel="external">Hexo 官方文档</a></p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> Geek </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 博客 </tag>
            
            <tag> Geek </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[「The Outline」It's for you]]></title>
      <url>http://yoursite.com/2017/05/17/The%20Outline/</url>
      <content type="html"><![CDATA[<p><img src="http://ojpgmz933.bkt.clouddn.com/17-5-17/61127451-file_1494983597169_6898.png" alt=""><br><em><a href="https://theoutline.com/" target="_blank" rel="external">https://theoutline.com/</a></em></p>
<p><strong>每日早上来实验室习惯性的会打开一些咨询类网站看看进来世界都发生了什么。今天无意间发现了这样一个网站，让我幸喜若狂。</strong></p>
<a id="more"></a>
<p><img src="http://ojpgmz933.bkt.clouddn.com/17-5-17/15069412-file_1494983795201_afc7.png" alt=""></p>
<p>以上是其官网的介绍。</p>
<p>The Outline 是一种给新人类的新型出版物。我们做这件事情是因为我们<strong>相信正确的故事以正确的方式告诉别人，能改变他的人生。</strong>但是以有意义和现代化的方式阐述正确的故事，这件事情本身不会发生。我们必须让其发生。</p>
<p>我们成立 The Outline 的初衷是把一些没有出现过的东西放到这个世界上，这让我们的非常激动。我们的报道集中在三个主题，这些主题越来越趋于以奇怪和重要的方式报道：权力（谁拥有它，谁想得到它，当他面得到时做了什么？），文化（我们生活和交流的方式），未来（我们下一步该往哪儿走？）</p>
<p>我们没有说任何这些故事，只因为这里有空间填补你的一天。我们正在诉说这些事情，是因为我们认为这个世界上还有一个值得叙述的事情是一个看不见的，没有报道的，或完全被错过的。</p>
<p>如果我们有一个主要的目标，就是尽可能地用尊敬和真实去喂饱你的好奇心与智慧。<strong>没有游戏，只有 TMD 有趣的每一天</strong>。</p>
<p>如果你真的想看看我们的事情，去探索我们的故事。并记得：迷路也是好的。</p>
<blockquote>
<p>看完这些，且不管内容Ruhr，我已经被这个网站，深深吸引了。</p>
</blockquote>
<h2 id="Wiki"><a href="#Wiki" class="headerlink" title="Wiki"></a>Wiki</h2><h3 id="The-Outline-website"><a href="#The-Outline-website" class="headerlink" title="The Outline (website)"></a>The Outline (website)</h3><p>The Outline is a New York based digital news company focused on power (as it relates to politics and business), culture and the future. It was founded by Joshua Topolsky in 2016 who raised $5 million from several venture capitalists to start the company. <strong>The company does not want to be too reliant on social media distribution, but instead aims to reach a “smart, influential” readership who visit its website directly.</strong> The articles are visually interactive, and highly optimised for mobile.The interface contains articles represented as a stack of cards that users can swipe through. <strong>The company earns income by virtue of its partnerships with 10 to 12 companies a year, as opposed to reliance on a format employing traditional banner ads.</strong></p>
<h3 id="History"><a href="#History" class="headerlink" title="History"></a>History</h3><p>The Outline was founded in 2016 under a holding company named Independent Media with funding from RRE Ventures, Advancit Capital, Boat Rocker Ventures and Nextview Ventures. The company initially hired 10 employees and launched its website on December 5th, 2016. It currently has 26 employees, having recruited people from Vox Media, Vice and Buzzfeed.[7] In April 2017, The Outline introduced The Outline World Dispatch, a short daily podcast with news roundups.</p>
]]></content>
      
        <categories>
            
            <category> 好奇心英语 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 猎奇 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[经典推荐算法之 Slope one]]></title>
      <url>http://yoursite.com/2017/05/16/%E7%BB%8F%E5%85%B8%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E4%B9%8B%20Slope%20one%20/</url>
      <content type="html"><![CDATA[<p>Slope One 是一系列应用于协同过滤的算法的统称。由 Daniel Lemire和Anna Maclachlan于2005年发表的论文中提出。 有争议的是，该算法堪称基于项目评价的non-trivial 协同过滤算法最简洁的形式。该系列算法的简洁特性使它们的实现简单而高效，而且其精确度与其它复杂费时的算法相比也不相上下。 该系列算法也被用来改进其它算法。</p>
<a id="more"></a>
<h2 id="协同过滤简介及其主要优缺点"><a href="#协同过滤简介及其主要优缺点" class="headerlink" title="协同过滤简介及其主要优缺点"></a>协同过滤简介及其主要优缺点</h2><p>协同过滤推荐（Collaborative Filtering recommendation）在信息过滤和信息系统中正迅速成为一项很受欢迎的技术。与传统的基于内容过滤直接分析内容进行推荐不同，协同过滤分析用户兴趣，在用户群中找到指定用户的相似（兴趣）用户，综合这些相似用户对某一信息的评价，形成系统对该指定用户对此信息的喜好程度预测。 与传统文本过滤相比，协同过滤有下列优点:</p>
<ol>
<li>能够过滤难以进行机器自动基于内容分析的信息。如艺术品、音乐。</li>
<li>能够基于一些复杂的，难以表达的概念（信息质量、品位)进行过滤。</li>
<li>推荐的新颖性。<br>尽管协同过滤技术在个性化推荐系统中获得了极大的成功，但随着站点结构、内容的复杂度和用户人数的不断增加，协同过滤技术的一些缺点逐渐暴露出来。 主要有以下三点:</li>
<li>稀疏性(sparsity)：在许多推荐系统中，每个用户涉及的信息量相当有限，在一些大的系统如亚马逊网站中，用户最多不过就评估了上百万本书的1%~2%。造成评估矩阵数据相当稀疏，难以找到相似用户集，导致推荐效果大大降低。</li>
<li>扩展性(scalability)：“最近邻居”算法的计算量随着用户和项的增加而大大增加，对于上百万之巨的数目，通常的算法将遭遇到严重的扩展性问题。</li>
<li>精确性(accuracy)：通过寻找相近用户来产生推荐集，在数量较大的情况下，推荐的可信度随之降低。</li>
</ol>
<h2 id="Item-based协同过滤-和-过拟合"><a href="#Item-based协同过滤-和-过拟合" class="headerlink" title="Item-based协同过滤 和 过拟合"></a>Item-based协同过滤 和 过拟合</h2><p>当可以对一些项目评分的时候，比如人们可以对一些东西给出1到5星的评价的时候，协同过滤意图基于一个个体过去对某些项目的评分和（庞大的）由其他用户的评价构成的数据库，来预测该用户对未评价项目的评分。 例如: 如果一个人给披头士的评分为5（总分5）的话，我们能否预测他对席琳狄翁新专辑的评分呢？</p>
<p>这种情形下, item-based 协同过滤系统根据其它项目的评分来预测某项目的分值，一般方法为 线性回归 (<img src="http://ojpgmz933.bkt.clouddn.com/17-5-16/14934628-file_1494922545267_d4ed.png" alt="">). 于是，需要列出x^2个线性回归方程和2x^2个回归量，例如：当有1000个项目时，需要列多达1,000,000个线性回归方程， 以及多达2,000,000个回归量。除非我们只选择某些用户共同评价过的项目对，否则协同过滤会遇到过拟合问题。</p>
<p>另外一种更好的方法是使用更简单一些的式子，比如<br><img src="http://ojpgmz933.bkt.clouddn.com/17-5-16/94152457-file_1494922526225_12071.png" alt=""> 实验证明当使用一半的回归量的时候，该式子（称为Slope One）的表现有时优于线性回归方程。该简化方法也不需要那么多存储空间和延迟。</p>
<p>Item-based 协同过滤只是协同过滤的一种形式.其它还有像 user-based 协同过滤一样研究用户间的联系的过滤系统。但是，考虑到其他用户数量庞大，item-based协同过滤更可行一些。</p>
<h2 id="电子商务中的Item-based协同过滤"><a href="#电子商务中的Item-based协同过滤" class="headerlink" title="电子商务中的Item-based协同过滤"></a>电子商务中的Item-based协同过滤</h2><p>人们并不总是能给出评分，当用户只提供二进制数据（购买与否）的时候，就无法应用Slope One 和其它基于评分的算法。 二进制 item-based协同过滤应用的例子之一就是Amazon的 item-to-item 专利算法，该算法中用二进制向量表示用户-项目购买关系的矩阵，并计算二进制向量间的cosine相关系数。</p>
<p>有人认为Item-to-Item 算法甚至比Slope One 还简单，例如：</p>
<p><img src="http://ojpgmz933.bkt.clouddn.com/17-5-16/34705852-file_1494922441402_16b6a.png" alt=""></p>
<p>在本例当中，项目1和项目2间的cosine相关系数为：<br><img src="http://ojpgmz933.bkt.clouddn.com/17-5-16/97742951-file_1494922364483_15f16.png" alt=""></p>
<p>项目1和项目3间的cosine相关系数为：</p>
<p><img src="http://ojpgmz933.bkt.clouddn.com/17-5-16/19597120-file_1494922474593_2237.png" alt=""></p>
<p>而项目2和项目3的cosine相关系数为：</p>
<p><img src="http://ojpgmz933.bkt.clouddn.com/17-5-16/77027907-file_1494922476411_10795.png" alt=""></p>
<p>于是，浏览项目1的顾客会被推荐买项目3(两者相关系数最大),而浏览项目2的顾客会被推荐买项目3,浏览了项目3的会首先被推荐买项目1（再然后是项目2,因为2和3的相关系数小于1和3）。该模型只使用了每对项目间的一个参数（cosine相关系数）来产生推荐。因此，如果有n个项目，则需要计算和存储 n（n-1）/2 个cosine相关系数。</p>
<h2 id="Slope-One-协同过滤"><a href="#Slope-One-协同过滤" class="headerlink" title="Slope One 协同过滤"></a>Slope One 协同过滤</h2><p>为了大大减少过适(过拟合)的发生，提升算法简化实现， Slope One 系列易实现的Item-based协同过滤算法被提了出来。本质上，该方法运用更简单形式的回归表达式 <img src="http://ojpgmz933.bkt.clouddn.com/17-5-16/94152457-file_1494922526225_12071.png" alt=""> 和单一的自由参数，而不是一个项目评分和另一个项目评分间的线性回归 <img src="http://ojpgmz933.bkt.clouddn.com/17-5-16/14934628-file_1494922545267_d4ed.png" alt="">。 该自由参数只不过就是两个项目评分间的平均差值。甚至在某些实例当中，它比线性回归的方法更准确[2]，而且该算法只需要一半（甚至更少）的存储量。</p>
<p><img src="http://ojpgmz933.bkt.clouddn.com/17-5-16/55071870-file_1494922635481_1705b.png" alt=""></p>
<p>例:</p>
<ol>
<li>User A 对 Item I 评分为1 对Item J.评分为1.5</li>
<li>User B 对 Item I 评分为2.</li>
<li>你认为 User B 会给 Item J 打几分?</li>
<li>Slope One 的答案是：2.5 (1.5-1+2=2.5).</li>
</ol>
<p>举个更实际的例子，考虑下表：<br><img src="http://ojpgmz933.bkt.clouddn.com/17-5-16/7276847-file_1494922675503_74a9.png" alt=""></p>
<p>在本例中，项目2和1之间的平均评分差值为 (2+(-1))/2=0.5. 因此，item1的评分平均比item2高0.5。同样的，项目3和1之间的平均评分差值为3。因此，如果我们试图根据Lucy 对项目2的评分来预测她对项目1的评分的时候，我们可以得到 2+0.5 = 2.5。同样，如果我们想要根据她对项目3的评分来预测她对项目1的评分的话，我们得到 5+3=8.</p>
<p>如果一个用户已经评价了一些项目，可以这样做出预测：简单地把各个项目的预测通过加权平均值结合起来。当用户两个项目都评价过的时候，权值就高。在上面的例子中，项目1和项目2都评价了的用户数为2,项目1和项目3 都评价了的用户数为1,因此权重分别为2和1. 我们可以这样预测Lucy对项目1的评价：<br><img src="http://ojpgmz933.bkt.clouddn.com/17-5-16/23906090-file_1494922787864_b562.png" alt=""><br>于是，对“n”个项目，想要实现 Slope One，只需要计算并存储“n”对评分间的平均差值和评价数目即可。</p>
<h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><h3 id="计算物品之间的评分差的均值，记为物品间的评分偏差-两物品同时被评分"><a href="#计算物品之间的评分差的均值，记为物品间的评分偏差-两物品同时被评分" class="headerlink" title="计算物品之间的评分差的均值，记为物品间的评分偏差(两物品同时被评分)"></a>计算物品之间的评分差的均值，记为物品间的评分偏差(两物品同时被评分)</h3><p><img src="http://ojpgmz933.bkt.clouddn.com/17-5-16/26255605-file_1494923034887_662b.png" alt=""></p>
<h3 id="根据物品间的评分偏差和用户的历史评分，预测用户对未评分的物品的评分。"><a href="#根据物品间的评分偏差和用户的历史评分，预测用户对未评分的物品的评分。" class="headerlink" title="根据物品间的评分偏差和用户的历史评分，预测用户对未评分的物品的评分。"></a>根据物品间的评分偏差和用户的历史评分，预测用户对未评分的物品的评分。</h3><p><img src="http://ojpgmz933.bkt.clouddn.com/17-5-16/58270130-file_1494923042952_6c5a.png" alt=""></p>
<h3 id="将预测评分排序，取topN对应的物品推荐给用户。"><a href="#将预测评分排序，取topN对应的物品推荐给用户。" class="headerlink" title="将预测评分排序，取topN对应的物品推荐给用户。"></a>将预测评分排序，取topN对应的物品推荐给用户。</h3><p>举例</p>
<p>假设有100个人对物品A和物品B打分了，R(AB)表示这100个人对A和B打分的平均偏差;有1000个人对物品B和物品C打分了， R(CB)表示这1000个人对C和B打分的平均偏差；</p>
<p><img src="http://ojpgmz933.bkt.clouddn.com/17-5-16/91222042-file_1494923055994_10d65.png" alt=""></p>
<h2 id="应用Slope-One的推荐系统"><a href="#应用Slope-One的推荐系统" class="headerlink" title="应用Slope One的推荐系统"></a>应用Slope One的推荐系统</h2><p>  ● hitflip DVD推荐系统<br>  ● How Happy<br>  ● inDiscover MP3推荐系统<br>  ● RACOFI Composer<br>  ● Value Investing News 股票新闻网站<br>  ● AllTheBests 购物推荐引擎</p>
<h2 id="Python-实现"><a href="#Python-实现" class="headerlink" title="Python 实现"></a>Python 实现</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div></pre></td><td class="code"><pre><div class="line">def loadData():</div><div class="line">    items=&#123;&apos;A&apos;:&#123;1:5,2:3&#125;,</div><div class="line">           &apos;B&apos;:&#123;1:3,2:4,3:2&#125;,</div><div class="line">           &apos;C&apos;:&#123;1:2,3:5&#125;&#125;</div><div class="line">    users=&#123;1:&#123;&apos;A&apos;:5,&apos;B&apos;:3,&apos;C&apos;:2&#125;,</div><div class="line">           2:&#123;&apos;A&apos;:3,&apos;B&apos;:4&#125;,</div><div class="line">           3:&#123;&apos;B&apos;:2,&apos;C&apos;:5&#125;&#125;</div><div class="line">    return items,users</div><div class="line"></div><div class="line">#***计算物品之间的评分差</div><div class="line">#items:从物品角度，考虑评分</div><div class="line">#users:从用户角度，考虑评分</div><div class="line">def buildAverageDiffs(items,users,averages):</div><div class="line">    #遍历每条物品-用户评分数据</div><div class="line">    for itemId in items:</div><div class="line">        for otherItemId in items:</div><div class="line">            average=0.0 #物品间的评分偏差均值</div><div class="line">            userRatingPairCount=0 #两件物品均评过分的用户数</div><div class="line">            if itemId!=otherItemId: #若无不同的物品项</div><div class="line">                for userId in users: #遍历用户-物品评分数</div><div class="line">                    userRatings=users[userId] #每条数据为用户对物品的评分</div><div class="line">                    #当前物品项在用户的评分数据中，且用户也对其他物品由评分</div><div class="line">                    if itemId in userRatings and otherItemId in userRatings:</div><div class="line">                        #两件物品均评过分的用户数加1</div><div class="line">                        userRatingPairCount+=1</div><div class="line">                        #评分偏差为每项当前物品评分-其他物品评分求和</div><div class="line">                        average+=(userRatings[otherItemId]-userRatings[itemId])</div><div class="line">                averages[(itemId,otherItemId)]=average/userRatingPairCount</div><div class="line"></div><div class="line">#***预测评分</div><div class="line">#users:用户对物品的评分数据</div><div class="line">#items：物品由哪些用户评分的数据</div><div class="line">#averages：计算的评分偏差</div><div class="line">#targetUserId：被推荐的用户</div><div class="line">#targetItemId：被推荐的物品</div><div class="line">def suggestedRating(users,items,averages,targetUserId,targetItemId):</div><div class="line">    runningRatingCount=0 #预测评分的分母</div><div class="line">    weightedRatingTotal=0.0 #分子</div><div class="line">    for i in users[targetUserId]:</div><div class="line">        #物品i和物品targetItemId共同评分的用户数</div><div class="line">        ratingCount=userWhoRatedBoth(users,i,targetItemId)</div><div class="line">        #分子</div><div class="line">        weightedRatingTotal+=(users[targetUserId][i]-averages[(targetItemId,i)])\</div><div class="line">        *ratingCount</div><div class="line">        #分母</div><div class="line">        runningRatingCount+=ratingCount</div><div class="line">    #返回预测评分</div><div class="line">    return weightedRatingTotal/runningRatingCount</div><div class="line"></div><div class="line"># 物品itemId1与itemId2共同有多少用户评分</div><div class="line">def userWhoRatedBoth(users,itemId1,itemId2):</div><div class="line">    count=0</div><div class="line">    #用户-物品评分数据</div><div class="line">    for userId in users:</div><div class="line">        #用户对物品itemId1与itemId2都评过分则计数加1</div><div class="line">        if itemId1 in users[userId] and itemId2 in users[userId]:</div><div class="line">            count+=1</div><div class="line">    return count</div><div class="line"></div><div class="line">if __name__==&apos;__main__&apos;:</div><div class="line">    items,users=loadData()</div><div class="line">    averages=&#123;&#125;</div><div class="line">    #计算物品之间的评分差</div><div class="line">    buildAverageDiffs(items,users,averages)</div><div class="line">    #预测评分:用户2对物品C的评分</div><div class="line">    predictRating=suggestedRating(users,items,averages,2,&apos;C&apos;)</div><div class="line">    print &apos;Guess the user will rate the score :&apos;,predictRating</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">结果：用户2对物品C的预测分值为 </div><div class="line">Guess the user will rate the score : 3.33333333333</div></pre></td></tr></table></figure>
<h2 id="Slop-one-增量更新"><a href="#Slop-one-增量更新" class="headerlink" title="Slop one 增量更新"></a>Slop one 增量更新</h2><p>在于根据新的评分项，更新偏差表与共同评分项个数</p>
<p><img src="http://ojpgmz933.bkt.clouddn.com/17-5-17/82668471-file_1494987245826_11a10.png" alt=""></p>
<p><img src="http://ojpgmz933.bkt.clouddn.com/17-5-17/98005549-file_1494987285672_10e32.png" alt=""></p>
<blockquote>
<p><a href="https://zh.wikipedia.org/wiki/Slope_one" target="_blank" rel="external">维基百科</a><br><a href="http://blog.csdn.net/xidianliutingting/article/details/51916578" target="_blank" rel="external">推荐算法之 slope one 算法</a><br>黄明波. 基于Slope One算法的增量音乐推荐系统的设计与实现[D].重庆大学,2016</p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> 推荐系统 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 推荐系统 </tag>
            
            <tag> Machine Learning </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Ubuntu16.04下设置静态IP]]></title>
      <url>http://yoursite.com/2017/05/09/Ubuntu16.04%E4%B8%8B%E8%AE%BE%E7%BD%AE%E9%9D%99%E6%80%81IP/</url>
      <content type="html"><![CDATA[<h3 id="vi-etc-network-interfaces"><a href="#vi-etc-network-interfaces" class="headerlink" title="vi /etc/network/interfaces"></a>vi /etc/network/interfaces</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"># This file describes the network interfaces available on your system</div><div class="line"># and how to activate them. For more information, see interfaces(5).</div><div class="line"></div><div class="line">source /etc/network/interfaces.d/*</div><div class="line"></div><div class="line"># The loopback network interface</div><div class="line">auto lo</div><div class="line">iface lo inet loopback</div><div class="line"></div><div class="line"># The primary network interface</div><div class="line">auto ens160    #设置自动启动ens160接口</div><div class="line">#iface ens160 inet dhcp  </div><div class="line"></div><div class="line">iface ens160 inet static   #配置静态IP</div><div class="line">address 10.1.18.200  #IP地址</div><div class="line">netmask 255.255.255.0  #子网掩码</div><div class="line">gateway 10.1.18.254    #默认网关</div><div class="line">dns-nameserver 210.32.32.10</div></pre></td></tr></table></figure>
<p>dns-nameserver 210.32.32.10 这句一定需要有，<br>因为以前是DHCP解析，所以会自动分配DNS 服务器地址。<br>而一旦设置为静态IP后就没有自动获取到DNS服务器了</p>
<h3 id="设置完重启电脑"><a href="#设置完重启电脑" class="headerlink" title="设置完重启电脑"></a>设置完重启电脑</h3><p><code>/etc/resolv.conf</code> 文件中会自动添加<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">nameserver 210.32.32.10</div></pre></td></tr></table></figure></p>
<p>(或者nameserver 8.8.8.8)可以根据访问速度，选择合适的公共DNS </p>
]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[KNN (k-nearest neighbor classification)]]></title>
      <url>http://yoursite.com/2017/03/16/KNN/</url>
      <content type="html"><![CDATA[<h2 id="K-近邻算法（KNN）概述"><a href="#K-近邻算法（KNN）概述" class="headerlink" title="K-近邻算法（KNN）概述"></a>K-近邻算法（KNN）概述</h2><p>最简单最初级的分类器是将全部的训练数据所对应的类别都记录下来，当测试对象的属性和某个训练对象的属性完全匹配时，便可以对其进行分类。但是怎么可能所有测试对象都会找到与之完全匹配的训练对象呢，其次就是存在一个测试对象同时与多个训练对象匹配，导致一个训练对象被分到了多个类的问题，基于这些问题呢，就产生了KNN。</p>
<p>KNN是通过测量不同特征值之间的距离进行分类。它的的思路是：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。K通常是不大于20的整数。KNN算法中，所选择的邻居都是已经正确分类的对象。该方法在定类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。</p>
<p>下面通过一个简单的例子说明一下：如下图，绿色圆要被决定赋予哪个类，是红色三角形还是蓝色四方形？如果K=3，由于红色三角形所占比例为2/3，绿色圆将被赋予红色三角形那个类，如果K=5，由于蓝色四方形比例为3/5，因此绿色圆被赋予蓝色四方形类。</p>
<p><img src="http://ojpgmz933.bkt.clouddn.com/17-3-16/78557648-file_1489668012349_14fab.jpg" alt=""></p>
<a id="more"></a>
<p>由此也说明了KNN算法的结果很大程度取决于K的选择。</p>
<p>在KNN中，通过计算对象间距离来作为各个对象之间的非相似性指标，避免了对象之间的匹配问题，在这里距离一般使用欧氏距离或曼哈顿距离：</p>
<p><img src="http://ojpgmz933.bkt.clouddn.com/17-3-16/14903128-file_1489668010375_10ae2.jpg" alt="">                      </p>
<p>同时，KNN通过依据k个对象中占优的类别进行决策，而不是单一的对象类别决策。这两点就是KNN算法的优势。</p>
<p>接下来对KNN算法的思想总结一下：就是在训练集中数据和标签已知的情况下，输入测试数据，将测试数据的特征与训练集中对应的特征进行相互比较，找到训练集中与之最为相似的前K个数据，则该测试数据对应的类别就是K个数据中出现次数最多的那个分类，其算法的描述为：</p>
<p>1）计算测试数据与各个训练数据之间的距离；</p>
<p>2）按照距离的递增关系进行排序；</p>
<p>3）选取距离最小的K个点；</p>
<p>4）确定前K个点所在类别的出现频率；</p>
<p>5）返回前K个点中出现频率最高的类别作为测试数据的预测分类。</p>
<h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><p>1、优点</p>
<p>简单，易于理解，易于实现，无需估计参数，无需训练</p>
<p>适合对稀有事件进行分类（例如当流失率很低时，比如低于0.5%，构造流失预测模型）</p>
<p>特别适合于多分类问题(multi-modal,对象具有多个类别标签)，例如根据基因特征来判断其功能分类，kNN比SVM的表现要好</p>
<p>2、缺点</p>
<p>懒惰算法，对测试样本分类时的计算量大，内存开销大，评分慢</p>
<p>可解释性较差，无法给出决策树那样的规则。</p>
<h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><p>1、k值设定为多大？</p>
<p>k太小，分类结果易受噪声点影响；k太大，近邻中又可能包含太多的其它类别的点。（对距离加权，可以降低k值设定的影响）</p>
<p>k值通常是采用交叉检验来确定（以k=1为基准）</p>
<p>经验规则：k一般低于训练样本数的平方根</p>
<p>2、类别如何判定最合适？</p>
<p>投票法没有考虑近邻的距离的远近，距离更近的近邻也许更应该决定最终的分类，所以加权投票法更恰当一些。</p>
<p>3、如何选择合适的距离衡量？</p>
<p>高维度对距离衡量的影响：众所周知当变量数越多，欧式距离的区分能力就越差。</p>
<p>变量值域对距离的影响：值域越大的变量常常会在距离计算中占据主导作用，因此应先对变量进行标准化。</p>
<p>4、训练样本是否要一视同仁？</p>
<p>在训练集中，有些样本可能是更值得依赖的。</p>
<p>可以给不同的样本施加不同的权重，加强依赖样本的权重，降低不可信赖样本的影响。</p>
<p>5、性能问题？</p>
<p>kNN是一种懒惰算法，平时不好好学习，考试（对测试样本分类）时才临阵磨枪（临时去找k个近邻）。</p>
<p>懒惰的后果：构造模型很简单，但在对测试样本分类地的系统开销大，因为要扫描全部训练样本并计算距离。</p>
<p>已经有一些方法提高计算的效率，例如压缩训练样本量等。</p>
<p>6、能否大幅减少训练样本量，同时又保持分类精度？</p>
<p>浓缩技术(condensing)</p>
<p>编辑技术(editing)</p>
<h2 id="使用-sklearn-进行算法使用"><a href="#使用-sklearn-进行算法使用" class="headerlink" title="使用 sklearn 进行算法使用"></a>使用 sklearn 进行算法使用</h2><p>对地形进行分类</p>
<p><strong>knn.py</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div></pre></td><td class="code"><pre><div class="line">#!/usr/bin/python</div><div class="line"></div><div class="line">import matplotlib.pyplot as plt</div><div class="line">from prep_terrain_data import makeTerrainData</div><div class="line">from class_vis import prettyPicture</div><div class="line">from time import time</div><div class="line"></div><div class="line">features_train, labels_train, features_test, labels_test = makeTerrainData()</div><div class="line"></div><div class="line"></div><div class="line">### the training data (features_train, labels_train) have both &quot;fast&quot; and &quot;slow&quot;</div><div class="line">### points mixed together--separate them so we can give them different colors</div><div class="line">### in the scatterplot and identify them visually</div><div class="line">grade_fast = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==0]</div><div class="line">bumpy_fast = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==0]</div><div class="line">grade_slow = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==1]</div><div class="line">bumpy_slow = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==1]</div><div class="line"></div><div class="line"></div><div class="line">#### initial visualization</div><div class="line">plt.xlim(0.0, 1.0)</div><div class="line">plt.ylim(0.0, 1.0)</div><div class="line">plt.scatter(bumpy_fast, grade_fast, color = &quot;b&quot;, label=&quot;fast&quot;)</div><div class="line">plt.scatter(grade_slow, bumpy_slow, color = &quot;r&quot;, label=&quot;slow&quot;)</div><div class="line">plt.legend()</div><div class="line">plt.xlabel(&quot;bumpiness&quot;)</div><div class="line">plt.ylabel(&quot;grade&quot;)</div><div class="line">plt.show()</div><div class="line">################################################################################</div><div class="line"></div><div class="line"></div><div class="line">### your code here!  name your classifier object clf if you want the </div><div class="line">### visualization code (prettyPicture) to show you the decision boundary</div><div class="line"></div><div class="line"></div><div class="line">from sklearn.neighbors import KNeighborsClassifier</div><div class="line">clf = KNeighborsClassifier(n_neighbors=10,weights=&apos;distance&apos;)</div><div class="line">t0 = time()</div><div class="line"></div><div class="line">clf.fit(features_train,labels_train)</div><div class="line">print &quot;training time : &quot; ,round(time()-t0,3),&quot;s&quot;</div><div class="line"></div><div class="line">t1 = time()</div><div class="line"></div><div class="line">pred = clf.predict(features_test)</div><div class="line"></div><div class="line">print &quot;predicting time : &quot; ,round(time()-t1,3),&quot;s&quot;</div><div class="line"></div><div class="line">from sklearn.metrics import accuracy_score</div><div class="line"></div><div class="line">acc = accuracy_score(pred,labels_test)</div><div class="line"></div><div class="line">print &apos;accuracy_score :&apos;,acc</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">try:</div><div class="line">    prettyPicture(clf, features_test, labels_test)</div><div class="line">except NameError:</div><div class="line">    pass</div></pre></td></tr></table></figure>
<p><strong>prep_terrain_data.py</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line">#!/usr/bin/python</div><div class="line">import random</div><div class="line"></div><div class="line"></div><div class="line">def makeTerrainData(n_points=1000):</div><div class="line">###############################################################################</div><div class="line">### make the toy dataset</div><div class="line">    random.seed(42)</div><div class="line">    grade = [random.random() for ii in range(0,n_points)]</div><div class="line">    bumpy = [random.random() for ii in range(0,n_points)]</div><div class="line">    error = [random.random() for ii in range(0,n_points)]</div><div class="line">    y = [round(grade[ii]*bumpy[ii]+0.3+0.1*error[ii]) for ii in range(0,n_points)]</div><div class="line">    for ii in range(0, len(y)):</div><div class="line">        if grade[ii]&gt;0.8 or bumpy[ii]&gt;0.8:</div><div class="line">            y[ii] = 1.0</div><div class="line"></div><div class="line">### split into train/test sets</div><div class="line">    X = [[gg, ss] for gg, ss in zip(grade, bumpy)]</div><div class="line">    split = int(0.75*n_points)</div><div class="line">    X_train = X[0:split]</div><div class="line">    X_test  = X[split:]</div><div class="line">    y_train = y[0:split]</div><div class="line">    y_test  = y[split:]</div><div class="line"></div><div class="line">    grade_sig = [X_train[ii][0] for ii in range(0, len(X_train)) if y_train[ii]==0]</div><div class="line">    bumpy_sig = [X_train[ii][1] for ii in range(0, len(X_train)) if y_train[ii]==0]</div><div class="line">    grade_bkg = [X_train[ii][0] for ii in range(0, len(X_train)) if y_train[ii]==1]</div><div class="line">    bumpy_bkg = [X_train[ii][1] for ii in range(0, len(X_train)) if y_train[ii]==1]</div><div class="line"></div><div class="line">    training_data = &#123;&quot;fast&quot;:&#123;&quot;grade&quot;:grade_sig, &quot;bumpiness&quot;:bumpy_sig&#125;</div><div class="line">            , &quot;slow&quot;:&#123;&quot;grade&quot;:grade_bkg, &quot;bumpiness&quot;:bumpy_bkg&#125;&#125;</div><div class="line"></div><div class="line"></div><div class="line">    grade_sig = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==0]</div><div class="line">    bumpy_sig = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==0]</div><div class="line">    grade_bkg = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==1]</div><div class="line">    bumpy_bkg = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==1]</div><div class="line"></div><div class="line">    test_data = &#123;&quot;fast&quot;:&#123;&quot;grade&quot;:grade_sig, &quot;bumpiness&quot;:bumpy_sig&#125;</div><div class="line">            , &quot;slow&quot;:&#123;&quot;grade&quot;:grade_bkg, &quot;bumpiness&quot;:bumpy_bkg&#125;&#125;</div><div class="line"></div><div class="line">    return X_train, y_train, X_test, y_test</div></pre></td></tr></table></figure>
<p>训练数据分布图</p>
<p><img src="http://ojpgmz933.bkt.clouddn.com/17-3-16/20809293-file_1489669205458_1d8b.png" alt=""></p>
<p>测试数据分类结果及决策面</p>
<p><img src="http://ojpgmz933.bkt.clouddn.com/17-3-16/18850860-file_1489669208051_3a0f.png" alt=""></p>
<p>计算结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">training time :  0.002 s</div><div class="line">predicting time :  0.005 s</div><div class="line">accuracy_score : 0.94</div></pre></td></tr></table></figure>
<p><strong>参考转载</strong></p>
<blockquote>
<p><a href="http://www.cnblogs.com/ybjourney/p/4702562.html" target="_blank" rel="external">http://www.cnblogs.com/ybjourney/p/4702562.html</a><br><a href="http://blog.csdn.net/lx85416281/article/details/40656877" target="_blank" rel="external">http://blog.csdn.net/lx85416281/article/details/40656877</a></p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> Machine learning </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Machine learning </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[支持向量机 Support Vector Machine]]></title>
      <url>http://yoursite.com/2017/03/13/Support%20Vector%20Machine/</url>
      <content type="html"><![CDATA[<p>支持向量机（SVM）是90年代中期发展起来的基于统计学习理论的一种机器学习方法，通过寻求结构化风险最小来提高学习机泛化能力，实现经验风险和置信范围的最小化，从而达到在统计样本量较少的情况下，亦能获得良好统计规律的目的。</p>
<p>通俗来讲，它是一种二类分类模型，其基本模型定义为特征空间上的间隔最大的线性分类器，即支持向量机的学习策略便是间隔最大化，最终可转化为一个凸二次规划问题的求解。</p>
<ul>
<li>线性分割</li>
<li>kernel trick 核技巧，多特征，将x,y映射到多维空间进行特征分割，之后再返回二维空间形成非线性分割线</li>
</ul>
<p><img src="http://ojpgmz933.bkt.clouddn.com/17-3-13/56429398-file_1489401775120_16d40.png" alt=""></p>
<h2 id="使用-sklearn-实战"><a href="#使用-sklearn-实战" class="headerlink" title="使用 sklearn 实战"></a>使用 sklearn 实战</h2><a id="more"></a>
<p>###调参</p>
<p>在 rbf 核下，分别使用10、100、1000、10000的C参数进行调整输出准确率。<br>使用1%的数据集。</p>
<p><strong>C参数</strong>： 低C使决策表面平滑，而高C旨在通过给予模型自由选择更多样本作为支持向量来正确地分类所有训练样本。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">features_train = features_train[:len(features_train)/100]</div><div class="line">labels_train = labels_train[:len(labels_train)/100]</div></pre></td></tr></table></figure>
<p>结果如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">C=10.0 accuracy=0.616040955631</div><div class="line">C=100.0 accuracy=0.616040955631</div><div class="line">C=1000. accuracy=0.821387940842</div><div class="line">C=10000. accuracy=0.892491467577</div></pre></td></tr></table></figure></p>
<h3 id="结果计算"><a href="#结果计算" class="headerlink" title="结果计算"></a>结果计算</h3><p>在全数据集下，进行准确度计算，并计算预测为Chris邮件的个数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div></pre></td><td class="code"><pre><div class="line">#!/usr/bin/python</div><div class="line"></div><div class="line">&quot;&quot;&quot; </div><div class="line">    This is the code to accompany the Lesson 2 (SVM) mini-project.</div><div class="line"></div><div class="line">    Use a SVM to identify emails from the Enron corpus by their authors:    </div><div class="line">    Sara has label 0</div><div class="line">    Chris has label 1</div><div class="line">&quot;&quot;&quot;</div><div class="line">    </div><div class="line">import sys</div><div class="line">from time import time</div><div class="line">sys.path.append(&quot;../tools/&quot;)</div><div class="line">from email_preprocess import preprocess</div><div class="line"></div><div class="line"></div><div class="line">### features_train and features_test are the features for the training</div><div class="line">### and testing datasets, respectively</div><div class="line">### labels_train and labels_test are the corresponding item labels</div><div class="line">features_train, features_test, labels_train, labels_test = preprocess()</div><div class="line"></div><div class="line"># reduce training data</div><div class="line">#features_train = features_train[:len(features_train)/100]</div><div class="line">#labels_train = labels_train[:len(labels_train)/100]</div><div class="line"></div><div class="line"></div><div class="line">#########################################################</div><div class="line">### your code goes here ###</div><div class="line">from sklearn.svm import SVC</div><div class="line">clf = SVC(kernel=&apos;rbf&apos;,C=10000.)</div><div class="line"></div><div class="line"></div><div class="line">#### now your job is to fit the classifier</div><div class="line">#### using the training features/labels, and to</div><div class="line">#### make a set of predictions on the test data</div><div class="line">t0 = time()</div><div class="line">clf.fit(features_train,labels_train)</div><div class="line">print &quot;training time : &quot; ,round(time()-t0,3),&quot;s&quot;</div><div class="line"></div><div class="line">#### store your predictions in a list named pred</div><div class="line">t1 = time()</div><div class="line">pred = clf.predict(features_test)</div><div class="line">print &quot;predicting time : &quot; ,round(time()-t1,3),&quot;s&quot;</div><div class="line"></div><div class="line">from sklearn.metrics import accuracy_score</div><div class="line">acc = accuracy_score(pred, labels_test)</div><div class="line">print &quot;accuracy: &quot;, acc</div><div class="line"></div><div class="line"># answer1=pred[10]</div><div class="line"># answer2=pred[26]</div><div class="line"># answer3=pred[50]</div><div class="line"></div><div class="line">num = 0</div><div class="line">for n in pred:</div><div class="line">    if n == 1:</div><div class="line">        num = num + 1</div><div class="line"></div><div class="line">print &quot;total Chris(1): &quot;, num</div><div class="line">#########################################################</div></pre></td></tr></table></figure>
<p>结果如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">no. of Chris training emails: 7936</div><div class="line">no. of Sara training emails: 7884</div><div class="line">training time :  159.096 s</div><div class="line">predicting time :  19.393 s</div><div class="line">accuracy:  0.990898748578</div><div class="line">total Chris(1):  877</div></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> Machine learning </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Machine learning </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[朴素贝叶斯 naive bayes]]></title>
      <url>http://yoursite.com/2017/03/09/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%20naive%20bayes/</url>
      <content type="html"><![CDATA[<h2 id="背景案例"><a href="#背景案例" class="headerlink" title="背景案例"></a>背景案例</h2><p>几年前，J.K. 罗琳（凭借《哈利波特》出名）试着做了件有趣的事。她以 Robert Galbraith 的化名写了本名叫《The Cuckoo’s Calling》的书。尽管该书得到一些不错的评论，但是大家都不太重视它，直到 Twitter 上一个匿名的知情人士说那是 J.K. Rowling 写的。《伦敦周日泰晤士报》找来两名专家对《杜鹃在呼唤》和 Rowling 的《偶发空缺》以及其他几名作者的书进行了比较。分析结果强有力地指出罗琳就是作者，《泰晤士报》直接询问出版商情况是否属实，而出版商也证实了这一说法，该书在此后一夜成名。</p>
<p>这就是一个文本分类预测的例子，接下来我们看看朴素贝叶斯是怎么做的。</p>
<h2 id="贝叶斯定理"><a href="#贝叶斯定理" class="headerlink" title="贝叶斯定理"></a>贝叶斯定理</h2><p>贝叶斯分类是一类分类算法的总称，这类算法均以贝叶斯定理为基础，故统称为贝叶斯分类。<br>这个定理解决了现实生活里经常遇到的问题：已知某条件概率，如何得到两个事件交换后的概率，也就是在已知P(A|B)的情况下如何求得P(B|A)。</p>
<p>条件概率：<br><img src="http://ojpgmz933.bkt.clouddn.com/17-3-9/85793005-file_1489047935966_6fe5.gif" alt=""></p>
<p>贝叶斯定理之所以有用，是因为我们在生活中经常遇到这种情况：我们可以很容易直接得出P(A|B)，P(B|A)则很难直接得出，但我们更关心P(B|A)，贝叶斯定理就为我们打通从P(A|B)获得P(B|A)的道路。</p>
<p>贝叶斯定理：</p>
<p><img src="http://ojpgmz933.bkt.clouddn.com/17-3-9/62455373-file_1489047937711_f0f1.gif" alt=""></p>
<a id="more"></a>
<h2 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h2><p>朴素贝叶斯之所以朴素，是因为其思想很朴素，英文 naive …..（不禁想到某位长者）。在文本分类上，其忽略了词序，记录词频。朴素贝叶斯的思想基础是这样的：对于给出的待分类项，求解在此项出现的条件下各个类别出现的概率，哪个最大，就认为此待分类项属于哪个类别。</p>
<p>优点：</p>
<ul>
<li>易执行</li>
<li>特征空间大</li>
<li>有效</li>
</ul>
<p>缺点：</p>
<ul>
<li>无语义分析</li>
</ul>
<p><strong>朴素贝叶斯分类的正式定义如下</strong>：</p>
<ol>
<li><p>设 <img src="http://ojpgmz933.bkt.clouddn.com/17-3-15/31414174-file_1489567475281_12d1f.gif" alt=""> 为一个待分类项，而每个a为x的一个特征属性。</p>
</li>
<li><p>有类别集合 <img src="http://ojpgmz933.bkt.clouddn.com/17-3-15/27703555-file_1489567478908_1817.gif" alt="">。</p>
</li>
<li><p>计算 <img src="http://ojpgmz933.bkt.clouddn.com/17-3-15/13289446-file_1489567481109_181b3.gif" alt="">。</p>
</li>
<li><p>如果 <img src="http://ojpgmz933.bkt.clouddn.com/17-3-15/67126205-file_1489567483162_46bf.gif" alt="">，则 <img src="http://ojpgmz933.bkt.clouddn.com/17-3-15/3446927-file_1489567529279_178.gif" alt="">。</p>
</li>
</ol>
<p>那么现在的关键就是如何计算第3步中的各个条件概率。我们可以这么做：</p>
<ul>
<li><p>找到一个已知分类的待分类项集合，这个集合叫做训练样本集。</p>
</li>
<li><p>统计得到在各类别下各个特征属性的条件概率估计。即</p>
<p><img src="http://ojpgmz933.bkt.clouddn.com/17-3-15/20543956-file_1489567485051_1536c.gif" alt=""></p>
</li>
<li><p>如果各个特征属性是条件独立的，则根据贝叶斯定理有如下推导：</p>
<p><img src="http://ojpgmz933.bkt.clouddn.com/17-3-15/41049611-file_1489567487061_feda.gif" alt=""></p>
</li>
<li><p>因为分母对于所有类别为常数，因为我们只要将分子最大化皆可。又因为各特征属性是条件独立的，所以有：<br><img src="http://ojpgmz933.bkt.clouddn.com/17-3-15/95532572-file_1489567489141_14f3e.gif" alt=""></p>
</li>
</ul>
<h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><p><img src="http://ojpgmz933.bkt.clouddn.com/17-3-9/57644114-file_1489048162753_127b5.png" alt=""></p>
<p>第一阶段——准备工作阶段，这个阶段的任务是为朴素贝叶斯分类做必要的准备，主要工作是根据具体情况确定特征属性，并对每个特征属性进行适当划分，然后由人工对一部分待分类项进行分类，形成训练样本集合。这一阶段的输入是所有待分类数据，输出是特征属性和训练样本。这一阶段是整个朴素贝叶斯分类中唯一需要人工完成的阶段，其质量对整个过程将有重要影响，分类器的质量很大程度上由特征属性、特征属性划分及训练样本质量决定。</p>
<p>第二阶段——分类器训练阶段，这个阶段的任务就是生成分类器，主要工作是计算每个类别在训练样本中的出现频率及每个特征属性划分对每个类别的条件概率估计，并将结果记录。其输入是特征属性和训练样本，输出是分类器。这一阶段是机械性阶段，根据前面讨论的公式可以由程序自动计算完成。</p>
<p>第三阶段——应用阶段。这个阶段的任务是使用分类器对待分类项进行分类，其输入是分类器和待分类项，输出是待分类项与类别的映射关系。这一阶段也是机械性阶段，由程序完成。</p>
<h2 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h2><h3 id="病人分类的例子"><a href="#病人分类的例子" class="headerlink" title="病人分类的例子"></a>病人分类的例子</h3><p>让我从一个例子开始讲起，你会看到贝叶斯分类器很好懂，一点都不难。<br>某个医院早上收了六个门诊病人，如下表。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">症状　　职业　　　疾病</div><div class="line">　　打喷嚏　护士　　　感冒 </div><div class="line">　　打喷嚏　农夫　　　过敏 </div><div class="line">　　头痛　　建筑工人　脑震荡 </div><div class="line">　　头痛　　建筑工人　感冒 </div><div class="line">　　打喷嚏　教师　　　感冒 </div><div class="line">　　头痛　　教师　　　脑震荡</div></pre></td></tr></table></figure>
<p>现在又来了第七个病人，是一个打喷嚏的建筑工人。请问他患上感冒的概率有多大？</p>
<p>根据贝叶斯定理：<br><code>P(A|B) = P(B|A) P(A) / P(B)</code></p>
<p>可得<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">P(感冒|打喷嚏x建筑工人) </div><div class="line">　　　　= P(打喷嚏x建筑工人|感冒) x P(感冒) </div><div class="line">　　　　/ P(打喷嚏x建筑工人)</div></pre></td></tr></table></figure></p>
<p>假定”打喷嚏”和”建筑工人”这两个特征是独立的，因此，上面的等式就变成了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">P(感冒|打喷嚏x建筑工人) </div><div class="line">　　　　= P(打喷嚏|感冒) x P(建筑工人|感冒) x P(感冒) </div><div class="line">　　　　/ P(打喷嚏) x P(建筑工人)</div></pre></td></tr></table></figure>
<p>这是可以计算的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">P(感冒|打喷嚏x建筑工人) </div><div class="line">　　　　= 0.66 x 0.33 x 0.5 / 0.5 x 0.33 </div><div class="line">　　　　= 0.66</div></pre></td></tr></table></figure>
<p>因此，这个打喷嚏的建筑工人，有66%的概率是得了感冒。同理，可以计算这个病人患上过敏或脑震荡的概率。比较这几个概率，就可以知道他最可能得什么病。<br>这就是贝叶斯分类器的基本方法：在统计资料的基础上，依据某些特征，计算各个类别的概率，从而实现分类。</p>
<h3 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h3><p>我们有一组邮件，分别由同一家公司的两个人撰写其中半数的邮件。我们的目标是仅根据邮件正文区分每个人写的邮件。</p>
<p>先给你一个字符串列表。每个字符串代表一封经过预处理的邮件的正文；提供代码，用来将数据集分解为训练集和测试集。</p>
<p>朴素贝叶斯特殊的一点在于，这种算法非常适合文本分类。在处理文本时，常见的做法是将每个单词看作一个特征，这样就会有大量的特征。此算法的相对简单性和朴素贝叶斯独立特征的这一假设，使其能够出色完成文本的分类。此项目使用 python 的 sklearn包，然后使用朴素贝叶斯根据作者对邮件进行分类。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line">#!/usr/bin/python</div><div class="line"></div><div class="line">    </div><div class="line">import sys</div><div class="line">from time import time</div><div class="line">sys.path.append(&quot;../tools/&quot;)</div><div class="line">from email_preprocess import preprocess</div><div class="line">from sklearn.metrics import accuracy_score</div><div class="line"></div><div class="line">### features_train and features_test are the features for the training</div><div class="line">### and testing datasets, respectively</div><div class="line">### labels_train and labels_test are the corresponding item labels</div><div class="line">features_train, features_test, labels_train, labels_test = preprocess()</div><div class="line"></div><div class="line">#########################################################</div><div class="line">### main code ###</div><div class="line">from sklearn.naive_bayes import GaussianNB</div><div class="line"></div><div class="line"># 创建分类器</div><div class="line">clf = GaussianNB()</div><div class="line">t0 = time()</div><div class="line">clf.fit(features_train, labels_train)</div><div class="line">print &quot;training time:&quot;, round(time()-t0, 3), &quot;s&quot;</div><div class="line"></div><div class="line">t1 = time()</div><div class="line"># 进行预测</div><div class="line">pred = clf.predict(features_test)</div><div class="line">print &quot;predicting time:&quot;, round(time()-t1, 3), &quot;s&quot;</div><div class="line"></div><div class="line"># 输出预测准确率</div><div class="line">print accuracy_score(pred,labels_test)</div><div class="line"></div><div class="line">#########################################################</div></pre></td></tr></table></figure>
<h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">no. of Chris training emails: 7936</div><div class="line">no. of Sara training emails: 7884</div><div class="line">training time: 2.396 s</div><div class="line">predicting time: 0.464 s</div><div class="line"></div><div class="line">accuracy: 0.973265073948</div></pre></td></tr></table></figure>
<p><strong>参考文章</strong></p>
<blockquote>
<p><a href="http://www.cnblogs.com/leoo2sk/archive/2010/09/17/naive-bayesian-classifier.html" target="_blank" rel="external">算法杂货铺——分类算法之朴素贝叶斯分类(Naive Bayesian classification)</a>)<br><a href="http://www.ruanyifeng.com/blog/2013/12/naive_bayes_classifier.html" target="_blank" rel="external">朴素贝叶斯分类器的应用</a><br><a href="https://classroom.udacity.com/courses/ud120" target="_blank" rel="external">Intro to machine learning</a></p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> Machine learning </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Machine learning </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[有监督学习和无监督学习]]></title>
      <url>http://yoursite.com/2017/03/06/%E6%9C%89%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/</url>
      <content type="html"><![CDATA[<h3 id="有监督学习-supervised-learning"><a href="#有监督学习-supervised-learning" class="headerlink" title="有监督学习 supervised learning"></a>有监督学习 supervised learning</h3><p>对具有概念标记（分类）的训练样本进行学习，以尽可能对训练样本集外的数据进行标记（分类）预测。这里，所有的标记（分类）是已知的。因此，训练样本的岐义性低。监督学习的典型例子就是决策树、神经网络以及疾病监测.</p>
<p>监督学习是训练神经网络和决策树的最常见技术。这两种技术（神经网络和决策树）高度依赖于事先确定的分类系统给出的信息。对于神经网络来说，分类系统用于判断网络的错误，然后调整网络适应它；对于决策树，分类系统用来判断哪些属性提供了最多的信息，如此一来可以用它解决分类系统的问题。我们将会看到这两者（神经网络和决策树）更多的细节，但在目前，它们用预先确定分类方法的形式来“监督”就足够了。</p>
<h3 id="无监督学习-unsupervised-learning"><a href="#无监督学习-unsupervised-learning" class="headerlink" title="无监督学习 unsupervised learning"></a>无监督学习 unsupervised learning</h3><p>对没有概念标记（分类）的训练样本进行学习，以发现训练样本集中的结构性知识。这里，所有的标记（分类）是未知的。因此，训练样本的岐义性高。聚类就是典型的无监督学习.</p>
<p>在这方面一个突出的例子是Backgammon（西洋双陆棋）游戏，有一系列计算机程序（例如neuro-gammon和TD-gammon）通过非监督学习自己一遍又一遍的玩这个游戏，变得比最强的人类棋手还要出色。这些程序发现的一些原则甚至令双陆棋专家都感到惊讶，并且它们比那些使用预分类样本训练的双陆棋程序工作得更出色。</p>
<p>一种次要的非监督学习类型称之为聚类（原文为clustering）。这类学习类型的目标不是让效用函数最大化，而是找到训练数据中的近似点。聚类常常能发现那些与假设匹配的相当好的直观分类。例如，基于人口统计的聚合个体可能会在一个群体中形成一个富有的聚类，以及其他的贫穷的聚合。</p>
<a id="more"></a>
<h3 id="举例"><a href="#举例" class="headerlink" title="举例"></a>举例</h3><p>本例来自，Udacity 的 Intro to Machine Learning 课程</p>
<p><img src="http://ojpgmz933.bkt.clouddn.com/17-3-2/75414001-file_1488451350923_17ade.png" alt=""></p>
<ol>
<li>从一个加了标签的相册中找出某个人。</li>
<li>分析银行诈骗交易。<br> 其中并没有给出异常交易的明确定义，没有例子来说明，所以属于无监督学习。</li>
<li>通过某人的音乐选择及标签特征，推荐音乐。</li>
<li>通过学习风格将优达学城的学生分类。<br> 学生类型不是已知的，不属于监督学习。</li>
</ol>
]]></content>
      
        <categories>
            
            <category> Machine learning </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Machine learning </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[「China Daily」Online fantasy novel hits the small screen]]></title>
      <url>http://yoursite.com/2017/02/24/Online%20fantasy%20novel%20hits%20the%20small%20screen/</url>
      <content type="html"><![CDATA[<blockquote>
<p><a href="http://www.chinadaily.com.cn/culture/2017-02/17/content_28244549.htm#Content" target="_blank" rel="external">http://www.chinadaily.com.cn/culture/2017-02/17/content_28244549.htm#Content</a></p>
</blockquote>
<p><img src="http://ojpgmz933.bkt.clouddn.com/17-2-24/19994832-file_1487900110056_47c9.png" alt=""><br><em>A Ten Miles of Peach Blossom poster [Photo provided to chinadaily.com.cn]</em></p>
<h1 id="News-text"><a href="#News-text" class="headerlink" title="News text"></a>News text</h1><p>Adapted from a popular online novel of the same name, a TV series called Ten Miles of Peach Blossom has hit the small screen during the Spring Festival.</p>
<p>Set in a fantasy world where monsters, gods and humans coexist, the story tells a love story between a 140,000-year-old fox princess and a 50,000-year-old dragon prince.</p>
<p>The story has won many fans for its beautiful scenes, poetic dialogues and popular stars.</p>
<p>The most important reason for turning the online novel into the TV series is the strong demand from fans.</p>
<p>The novel was published by Shenyang Press in 2009 and has sold 1.1 million copies.</p>
<p>According to an industry insider, the online popularity and potential for market earnings from the online novels could propel the TV series or film to be the next blockbuster.</p>
<p>Here are some beautiful scenes from the TV series.</p>
<a id="more"></a>
<h1 id="Words"><a href="#Words" class="headerlink" title="Words:"></a>Words:</h1><ul>
<li>hit the small screen : 在电视上热映， hit the screen 在这里指“搬上荧幕”，big screen为电影</li>
<li>TV series：电视剧</li>
<li>propel: 推进；驱使；激励；驱策</li>
<li>blockbuster：轰动；巨型炸弹；一鸣惊人者</li>
</ul>
<h1 id="Translation"><a href="#Translation" class="headerlink" title="Translation"></a>Translation</h1><p>根据同名流行的网络小说改编的电视连续剧十里桃花，在春节期间火热播出。</p>
<p>怪兽，神和人类共存在一个虚幻的世界中，其讲述了一个关于14万岁的狐狸公主和5万岁的龙王子的爱情故事。</p>
<p>美丽的场景，诗意的对话和明星给故事赢得了很多粉丝。</p>
<p>把网络小说拍成电视剧的主要原因是粉丝的强烈要求。</p>
<p>小说于2009年在沈阳出版社出版，并且已经售出110万本。</p>
<p>据业内人士透露，在线小说的在线流行度和市场收益的潜力可能推动电视剧或电影成为下一个大片。</p>
<h1 id="Thought"><a href="#Thought" class="headerlink" title="Thought"></a>Thought</h1>]]></content>
      
        <categories>
            
            <category> 好奇心英语 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> ChinaDaily </tag>
            
            <tag> News </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Java读取properties配置文件]]></title>
      <url>http://yoursite.com/2017/02/20/java%E8%AF%BB%E5%8F%96properties%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/</url>
      <content type="html"><![CDATA[<p>读取.properties配置文件在实际的开发中使用的很多，总结了一下，有以下几种方法（仅仅是我知道的）：</p>
<h3 id="通过jdk提供的java-util-Properties类"><a href="#通过jdk提供的java-util-Properties类" class="headerlink" title="通过jdk提供的java.util.Properties类"></a>通过jdk提供的java.util.Properties类</h3><p>此类继承自java.util.HashTable，即实现了Map接口，所以，可使用相应的方法来操作属性文件，但不建议使用像put、putAll这两个方法，因为put方法不仅允许存入String类型的value，还可以存入Object类型的。因此java.util.Properties类提供了getProperty()和setProperty()方法来操作属性文件，同时使用store或save(已过时)来保存属性值（把属性值写入.properties配置文件）。在使用之前，还需要加载属性文件，它提供了两个方法：load和loadFromXML。load有两个方法的重载：load(InputStream inStream)、load(Reader reader)，所以，可根据不同的方式来加载属性文件。可根据不同的方式来获取InputStream，如：</p>
<ol>
<li><p>通过当前类加载器的getResourceAsStream方法获取</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">InputStream inStream = TestProperties.class.getClassLoader().getResourceAsStream(&quot;test.properties&quot;);</div></pre></td></tr></table></figure>
</li>
<li><p>从文件获取</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">InputStream inStream = new FileInputStream(new File(&quot;filePath&quot;));</div></pre></td></tr></table></figure>
</li>
</ol>
<a id="more"></a>
<ol>
<li><p>也是通过类加载器来获取，和第一种一样</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">InputStream in = ClassLoader.getSystemResourceAsStream(&quot;filePath&quot;);</div></pre></td></tr></table></figure>
</li>
<li><p>在servlet中，还可以通过context来获取InputStream</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">InputStream in = context.getResourceAsStream(&quot;filePath&quot;);</div></pre></td></tr></table></figure>
</li>
<li><p>通过URL来获取</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">URL url = new URL(&quot;path&quot;);  </div><div class="line">InputStream inStream = url.openStream();</div></pre></td></tr></table></figure>
</li>
</ol>
<p>读取方法如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">Properties prop = new Properties();  </div><div class="line">prop.load(inStream);  </div><div class="line">String key = prop.getProperty(&quot;username&quot;);  </div><div class="line">//String key = (String) prop.get(&quot;username&quot;);</div></pre></td></tr></table></figure></p>
<h3 id="通过java-util-ResourceBundle类来读取"><a href="#通过java-util-ResourceBundle类来读取" class="headerlink" title="通过java.util.ResourceBundle类来读取"></a>通过java.util.ResourceBundle类来读取</h3><p>这种方式比使用Properties要方便一些。</p>
<ol>
<li>通过ResourceBundle.getBundle()静态方法来获取（ResourceBundle是一个抽象类），这种方式来获取properties属性文件不需要加.properties后缀名，只需要文件名即可。<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ResourceBundle resource = ResourceBundle.getBundle(&quot;com/mmq/test&quot;);</div><div class="line">// test为属性文件名，放在包com.mmq下，如果是放在src下，直接用test即可</div></pre></td></tr></table></figure>
</li>
</ol>
<p>String key = resource.getString(“username”);  </p>
<ol>
<li>从InputStream中读取，获取InputStream的方法和上面一样，不再赘述。<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ResourceBundle resource = new PropertyResourceBundle(inStream);</div></pre></td></tr></table></figure>
</li>
</ol>
<p>注意：在使用中遇到的最大的问题可能是配置文件的路径问题，如果配置文件入在当前类所在的包下，那么需要使用包名限定，如：test.properties入在com.mmq包下，则要使用com/mmq/test.properties（通过Properties来获取）或com/mmq/test（通过ResourceBundle来获取）；属性文件在src根目录下，则直接使用test.properties或test即可。</p>
<blockquote>
<p>本文转载自 <a href="http://blog.csdn.net/mhmyqn/article/details/7683909" target="_blank" rel="external">http://blog.csdn.net/mhmyqn/article/details/7683909</a></p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[台湾清华大学彭明辉教授的研究生手册]]></title>
      <url>http://yoursite.com/2017/01/15/%E5%8F%B0%E6%B9%BE%E6%B8%85%E5%8D%8E%E5%A4%A7%E5%AD%A6%E5%BD%AD%E6%98%8E%E8%BE%89%E6%95%99%E6%8E%88%E7%9A%84%E7%A0%94%E7%A9%B6%E7%94%9F%E6%89%8B%E5%86%8C/</url>
      <content type="html"><![CDATA[<p>一、论文的要求<br>　　我对硕士论文的基本要求是：<br>　　（1）论文的主要内容，是叙述一套方法在一个特定场合中的应用。<br>　　（2）这套方法必须要有所创新或突破，并因而对学术界有所贡献。因此，它或者是解决既有问题的新方法，或者是既有方法的新应用，或者是以一个新的方法开启一整片新的应用领域。<br>　　（3）在论文中，你必须要有能力提出足够的证据来让读者信服说：针对这个应用场合，你所提出来的方法确实有比文献中一切既有方法更优越之处。<br>　　（4）此外，你必须要能清楚指出这个方法在应用上的限制，并且提出充分证据来说服读者：任何应用场合，只要能够满足你所提出来的假设（前提）条件，你的方法就一定适用，而且你所描述的优点就一定会存在。<br>　　（5）你还必须要在论文中清楚指出这个方法的限制和可能的缺点（相对于其它文献上的既有方法，或者在其它应用场合里）假如这个方法有任何重大缺点，在口试时才被口试委员指出来，其后果有可能是论文无法通过。<br>　　（6）行文风格上，它是一篇论证严谨，逻辑关系清晰，而且结构有条理的专业论述。也就是说，在叙述你的方法的过程，你必须要清清楚楚地交代这个方法的应用程序以及所有仿真或实验结果的过程，使得这个专业领域内的任何读者，都有办法根据你的描述，在他的实验室下复制出你的研究成果，以便确定你的结论确实是可以「在任何时间、任何地点、任何人」都具有可重复性（可重复性是「科学」的根本要求）。<br>　　（7）而且，你对这个方法的每一个步骤都必须要提供充分的理由说明「为什么非如此不可」。<br><a id="more"></a><br>　　（ 8）最后，你的论文必须要在适当位置清楚注明所有和你所研究之题目相关的文献。而且，你必须要记得：只要是和你所研究的问题相关的学术文献（尤其是学术期刊论文），你都有必要全部找出来（如果漏掉就是你的过失），仔细读过。假如你在学位论文口试时，有口试委员指出有一篇既有文献，在你所讨论的问题中处理得比你的方法还好，这就构成你论文无法及格的充分理由。<br>　　（9）第（2）款所谓「对学术界的贡献」，指的是：把你的所有研究成果扣除掉学术界已经发表过的所有成果（不管你实际上有没有参考过，没有参考过也算是你的重大过失），剩下的就是你的贡献。假如这个贡献太少，也构成你论文无法及格的充分理由。<br>　　上面所叙述的九款要件中，除第（2）款之外，通通都是必须要做到的，因此没有好坏之分。一篇硕士论文的好坏（以及成绩的评定标准），主要是看第（2）款所谓「对学术界的贡献」的多寡与重要性而定。假如你要申请国外的博士班，最重要的也是看你的硕士论文有什么「贡献」而定（这往往比TOFEL、GRE、GPA还重要）。<br>　　一个判断硕士论文的好坏有一个粗浅办法：假如你的研究成果可以在国外著名学术期刊（journals，而非 magazines）上发表，通常就比一篇只能在国外学术会议（conferences）上发表的硕士论文贡献多；一篇国外学术会议的论文又通常比无法发表的论文贡献多；在国际顶尖学术期刊上发表的论文通常比一篇二流的学术期刊论文贡献多。SCI有一种叫做 Impact Factor 的指数，统计一个期刊每篇论文被引述的次数。通常这个次数（或指数）愈高，对学术界的影响力就愈大。以机械视觉相关领域的期刊而言，Impact Factor 在 1.0 以上的期刊，都算是顶尖的期刊。这些期刊论文的作者，通常是国外顶尖学府的著名教授指导全球一流的博士生做出来的研究成果。 </p>
<p>二、完成硕士论文所需要的能力<br>　　从前面的叙述可以归纳出来，完成硕士论文所需要的能力包括以下数项，依它们的培养先后次序逐项讨论。<br>　　（1）资料检索的能力：在给定（或自己拟定）的题目范围内，你必须有能力利用文资料索引系统，查出所有相关的论文，而无任何遗漏（否则你可能在论文口试时才发现同一个题目已经有人发表过了）。你到底要用什么样的关键词和查所程序去保证你已经找出所有相关的文献？这是第一个大的挑战。每一组关键词（包含联集与交集）代表一个论文所构成的集合，假如你用的关键词不恰当，你可能找到的集合太小，没有涵盖所有的相关文献；假如你用的关键词太一般化（譬如「image」），通常你找到的集合会太大，除了所有相关文献之外还加上好几十倍的毫不相关的文献。<br>　　（2）资料筛选的能力：即使你使用了恰当的搜寻策略，通常找到的文献集合都还是明显地比你所需要的集合大，而且通常文献比数大概在一两百篇或数百篇之间，而其中会和你的的研究子题直接且密切相关的论文，通常只有廿、卅篇左右。你如何可以只读论文的题目、摘要、简介和结论，而还没有完全看懂内文，就准确地判断出这篇论文中是否有值得你进一步参考的内容，以便快速地把需要仔细读完的论文从数百篇降低到廿、卅篇？这考验着你从事资料筛选的能力。<br>　　（3）期刊论文的阅读能力：期刊论文和大学部的课本截然不同。大学部的课本是寻次渐进地从最基本的知识背景逐步交代出整套有系统的知识，中间没有任何的跳跃，只要你逐页读下去，就可以整本都读懂，不需要在去别的地方找参考资料。但是期刊论文是没头没尾的十几页文献，只交代最核心的创意，并援引许多其它论文的研究成果（但只注明文献出处，而完全没有交代其内容）。因此，要读懂一篇论文，一定要同时读懂数篇或十数篇被援引的其它论文。偏偏，这十几篇被援引的论文又各自援引十数篇其它论文。因此，相对于大学部的教科书而言，期刊论文是一个极端没有系统的知识，必须要靠读者自己从几十篇论文中撷取出相关的片段，自己组织成一个有系统的知识，然后才有办法开始阅读与吸收。要培养出这种自己组织知识的能力，需要在学校靠着大量而持续的时间去摸索、体会，而不可能只利用业余的零星时间去培养。因此，一个大学毕业后就不再念研究所的学生，不管他在毕业生和大学毕业生最大的差别，就是：学士只学习过吸收系统知识的能力（也就是读别人整理、组织好的知识，典型的就是课本）；但硕士则学习过自己从无组织的知识中检索、筛选、组织知识的能力。<br>　　（4）期刊论文的分析能力：为了确定你的学位论文研究成果确实比所有相关的学术期刊论文都更适合处理你所拟定的应用场域，首先你必须要有能力逐篇分析出所有相关期刊论文的优点与缺点，以及自己的研究成果的优点与缺点，然后再拿他们来做比较，总结出你的论文的优点和缺点（限制）。但是，好的期刊论文往往是国外著名学府的名师和一流的博士生共同的研究成果，假如你要在锁定的应用场域上「打败」他们，突出自己的优点，这基本上是一个极端困难的挑战。即使只是要找出他们的缺点，都已经是一个相当困难的工作了。一个大学毕业生，四年下来都是假定「课本是对的」这样地学下来的，从来没有学习如何分析课本知识的优缺点，也就是「只有理解的能力，而没有批判的能力」。硕士生则必须要有「对一切既有进行精确批判」的能力。但是，这个批判并非个人好恶或情绪化的批判，而是真的找得到充分理由去支持的批判。这个批判的能力，让你有能力自己找到自己的优、缺点，因此也有机会自己精益求精。所以，一个大学毕业生在业界做事的时候，需要有人指导他（从事批判性检验），帮他找出缺点和建议改进的可能性。但是，一个严格训练过的合格硕士，他做事的时候应该是不需要有人在背后替他做检证，他自己就应该要有能力分析自己的优、缺点，主动向上级或平行单位要求支持。其实，至少要能够完成这个能力，才勉强可以说你是有「独立自主的判断能力」。<br>　　（5）创新的能力：许多大学毕业的工程师也能创新，但是硕士的创新是和全世界同一个学术团体内所有的名师和博士生挑战。因此，两者是站在不同的比较基础上在进行的：前者往往是一个企业内部的「闭门造车」，后者是一个全球的开放性竞争。其次，工程师的创新往往是无法加以明确证明其适用条件，但是学术的创新却必须要能够在创新的同时厘清这个创新的有效条件。因此，大学毕业生的主要能力是吸收既有知识，但硕士毕业生却应该要有能力创造知识。此外，台湾历年来工业产品的价位偏低，这一部分是因为国际大厂的打压以及国际消费者的信任不易建立。但是，另一方面，这是因为台湾的产品在品质上无法控制，因此只好被当作最粗糙的商品来贩卖。台湾的产品之所以无法有稳定的品质，背后的技术原因就是：各种创新都是只凭一时偶然的巧思，却没有办法进一步有系统地厘清这些巧思背后可以成立的条件。但是，创新其实是可以有一套「有迹可寻」的程序的，这是我最得意的心得，也是我最想教的。 </p>
<p>三、为什么要坚持培养阅读与分析期刊论文的能力<br>　　我所以一直坚持要训练研究生阅读与分析期刊论文的能力，主要是为了学生毕业后中长期的竞争力着想。<br>　　台湾从来都只生产国外已经有的产品，而不事创新。假如国外企业界比国外学术的技术落后三年，而台湾的技术比国外技术落后五年，则台湾业界所需要的所有技术都可以在国外学术期刊上找到主要的理论依据和技术核心构想（除了一些技术的细节和 know how 之外）。因此，阅读期刊的能力是台湾想要保持领先大陆技术的必备条件。<br>　　此外，只要能够充分掌握阅读与分析期刊论文的技巧，就可以水到渠成地轻松进行「创新」的工作。所以，只要深入掌握到阅读与分析期刊论文的技巧，就可以掌握到大学生不曾研习过的三种能力：（1）自己从无组织的知识中检索、筛选、组织知识的能力、（2）对一切既有进行精确批判的独立自主判断能力、（3）创造新知识的能力。<br>　　创新的能力在台湾一直很少被需要（因为台湾只会从国外买整套设备、制程和设计与制造的技术）。但是，大陆已经成为全球廉价品制造中心，而台商为了降低成本也主动带技术到大陆设厂（包括现在的晶元代工），因此整个不具关键性技术的制造业都会持续往大陆移动；甚至 IC 的设计（尤其数字的部分）也无可避免地会迅速朝向「台湾开系统规格，进行系统整合，大陆在前述架构下开发特定数位模块」的设计代工发展。因此，未来台湾将必然会被逼着朝愈来愈创意密集的创意中心走（包括商务创意、经营创意、产品创意、与技术创新）。因此，不能因为今天台湾的业界不需要创新的能力，就误以为自己一辈子都不需要拥有创新的能力。<br>　　我在协助民间企业发展技术研发的过程中，碰到过一位三十多岁的厂长。他很聪明，但从小家穷，被环境逼着去念高工，然后上夜校读完工专。和动态性能（ bandwidth、response speed等）无关的技术他都很深入，也因为产品升级的需要而认真向我求教有关动态性能的基本观念。但是，怎么教他都不懂，就只因为他不懂工程数学。偏偏，工程数学不是可以在工厂里靠自修读会的。一个那么聪明的人，只因为不懂工数，就注定从三十岁以后一辈子无法在专业上继续成长！他高工毕业后没几年，廿多岁就当课长，家人与师长都以他为荣；卅岁当厂长，公司还给他技术股，前途无量；谁想得到他会在卅岁以后被逼着「或者升级，或者去大陆，或者失业」？<br>　　每次想起这位厂长，看着迫不急待地要到台积电去「七年赚两千万退休金」的学生，或者只想学现成可用的技术而不想学研究方法的学生，我总忍禁不住地要想：十年后，我教过的学生里，会不会有一堆人就只因为不会读期刊论文而被逼提前退休？<br>　　再者，技术的创新并不是全靠聪明。我熟谙一套技术创新的方法，只要学会分析期刊论文的优缺点，就可拿这套方法分析竞争对手产品的优缺点；而且，只要再稍微加工，就可以从这套优缺点的清单里找到突破瓶颈所需的关键性创意。这套创新程序，可以把「创新」变成不需要太多天分便可以完成的事，从而减轻创意的不定性与风险性。因此，只要会分析论文，几乎就可以轻易地组合出你所需要的绝大部分创意。聪明是不可能教的，但这套技巧却是可以教的；而且只要用心，绝大部分硕士生都可以学会。<br>　　就是因为这个原因，我的实验室整个训练的重心只有一个：通过每周一次的 group meeting，培养学生深入掌握阅读与分析期刊论文的技巧，进而培养他们在关键问题上突破与创新的能力。 </p>
<p>四、期刊论文的分析技巧与程序<br>　　一般来讲，好的期刊论文有较多的创意。虽然读起来较累，但收获较多而深入，因此比较值得花心思去分析。读论文之前，参考SCI Impact Factor 及学长的意见是必要的。<br>　　一篇期刊论文，主要分成四个部分。<br>　　（1）Abstract：<br>　　说明这篇论文的主要贡献、方法特色与主要内容。最慢硕二上学期必须要学会只看 Abstract 和Introduction便可以判断出这篇论文的重点和你的研究有没有直接关连，从而决定要不要把它给读完。假如你有能力每三十篇论文只根据摘要和简介便能筛选出其中最密切相关的五篇论文，你就比别人的效率高五倍以上。以后不管是做事或做学术研究，都比别人有能力从更广泛的文献中挑出最值得参考的资料。<br>　　（2）Introduction：<br>　　Introduction 的功能是介绍问题的背景和起源，交代前人在这个题目上已经有过的主要贡献，说清楚前人留下来的未解问题，以及在这个背景下这篇论文的想解决的问题和它的重要性。对初学的学生而言，从这里可以了解以前研究的概况。通常我会建议初学的学生，对你的题目不熟时，先把跟你题目可能相关的论文收集个 30～40篇，每篇都只读Abstract 和 Introduction，而不要读 Main Body（本文），只在必要时稍微参考一下后面的 Illustrative examples和 Conclusions，直到你能回答下面这三个问题：（2A）在这领域内最常被引述的方法有哪些？（2B）这些方法可以分成哪些主要派别？（2C）每个派别的主要特色（含优点和缺点）是什么？<br>　　问题是，你怎么去找到这最初的30～40篇论文？有一种期刊论文叫做「review paper」，专门在一个题目下面整理出所有相关的论文，并且做简单的回顾。你可以在搜寻 Compendex 时在 keywords 中加一个「review」而筛选出这类论文。然后从相关的数篇review paper 开始，从中根据 title 与 Abstract 找出你认为跟你研究题目较相关的30～40篇论文。<br>　　通常只要你反复读过该领域内30～40篇论文的Abstract 和 Introduction，你就应该可以从Introduction的评论中回答（2A）和（2B）这两个问题。尤其要记得，当你阅读的目的是要回答（2A）和（2B）这两个问题时，你一定要先挑那些 Introduction写得比较有观念的论文念（很多论文的Introduction 写得像流水帐，没有观念，这种论文刚开始时不要去读它）。假如你读过假如30～40篇论文的 Abstract 和 Introduction之后，还是回答不了（2C），先做下述的工作。<br>　　你先根据（2A）的答案，把这领域内最常被引述的论文找齐，再把他们根据（2B）的答案分成派别，每个派别按日期先后次序排好。然后，你每次只重新读一派的 Abstract 和 Introduction（必要时简略参考内文，但目的只是读懂Introduction内与这派有关的陈述，而不需要真的看懂所有内文），照日期先后读 ，读的时候只企图回答一个问题：这一派的创意与主要诉求是什么？这样，你逐派逐派地把每一派的Abstract 和 Introduction 给读完，总结出这一派主要的诉求 、方法特色和优点（每一篇论文都会说出自己的优点，仔细读就不会漏掉）。<br>　　其次，你再把这些论文拿出来，但是只读Introduction，认真回答下述问题：「每篇论文对其它派别有什么批评？」然后你把读到的重点逐一记录到各派别的「缺点」栏内。<br>　　通过以上程序，你就应该可以掌握到（2A）、（2B）、和（2C）三个问题的答案。这时你对该领域内主要方法、文献之间的关系算是相当熟捻了，但是你还是只仔细 读完Abstract 和 Introduction而已，内文则只是笼统读过。<br>　　这时候，你已经掌握到这领域主要的论文，你可以用这些论文测试看看你用来搜寻这领域论文的 keywords 到底恰不恰当，并且用修正过的 keywords 再搜寻一次论文，把这领域的主要文献补齐，也把原来30～40篇论文中后来发现关系较远的论文给筛选掉，只保留大概20篇左右确定跟你关系较近的文献。如果有把握，可以甚至删除一两个你不想用的派别（要有充分的理由），只保留两、三个派别（也要有充分的理由）继续做完以下工作。<br>　　然后你应该利用（2C）的答案，再进一步回答一个问题（2D）：「这个领域内大家认为重要的关键问题有哪些？有哪些特性是大家重视的优点？有哪些特性是大家在意的缺点？这些优点与缺点通常在哪些应用场合时会比较被重视？在哪些应用场合时比较不会被重视？」然后，你就可以整理出这个领域（研究题目）主要的应用场合，以及这些应用场合上该注意的事项。<br>　　最后，在你真正开始念论文的 main body 之前，你应该要先根据（2A）和（2C的答案，把各派别内的论文整理在同一个档案夹里，并照时间先后次序排好。然后依照这些派别与你的研究方向的关系远近，一个派别一个派别地逐一把各派一次念完一派的 main bodies。 （3）Main body（含simulation and/or experimental examples）：<br>　　在你第一次有系统地念某派别的论文 main bodies 时，你只需要念懂：（3A）这篇论文的主要假设是什么（在什么条件下它是有效的），并且评估一下这些假设在现实条件下有多容易（或多难）成立。愈难成立的假设，愈不好用，参考价值也愈低。（3B）在这些假设下，这篇论文主要有什么好处。（3C）这些好处主要表现在哪些公式的哪些项目的简化上。至于整篇论文详细的推导过程，你不需要懂。除了三、五个关键的公式（最后在应用上要使用的公式，你可以从这里评估出这个方法使用上的方便程度或计算效率，以及在非理想情境下这些公式使用起来的可靠度或稳定性）之外，其它公式都不懂也没关系，公式之间的恒等式推导过程可以完全略过去。假如你要看公式，重点是看公式推导过程中引入的假设条件，而不是恒等式的转换。 </p>
<p>但是，在你开始根据前述问题念论文之前，你应该先把这派别所有的论文都拿出来，逐篇粗略地浏览过去（不要勉强自己每篇或每行都弄到懂，而是轻松地读，能懂就懂，不懂就不懂），从中挑出容易念懂的 papers，以及经常被引述的论文。然后把这些论文照时间先后次序依序念下去。记得：你念的时候只要回答（3A）、（ 3B）、（3C）三个问题就好，不要念太细。<br>　　这样念完以后，你应该把这一派的主要发展过程，主要假设、主要理论依据、以及主要的成果做一个完整的整理。其次，你还要在根据（2D）的答案以及这一派的主要假设，进一步回答下一个问题：（3D）这一派主要的缺点有哪些。最后，根据（ 3A）、（3B）、（3C）、（3D）的答案综合整理出：这一派最适合什么时候使用，最不适合什么场合使用。<br>　　记住：回答完这些问题时，你还是不应该知道恒等式是怎么导出来的！<br>　　当你是生手的时候，你要评估一个方法的优缺点时，往往必须要参考它Examples。但是，要记得：老练的论文写作高手会故意只 present 成功的案例而遮掩失败的案例。所以，simulation examples and/or experiments 很棒不一定表示这方法真的很好。你必须要回到这个方法的基本假设上去，以及他在应用时所使用的主要公式（resultant equations）去，凭自己的思考能力， 并且参考（2C）和（2D）的答案，自己问问看：当某某假设在某些实用场合上无法成立时，这个方法会不会出什么状况？猜一猜，预测一下这个方法应该会在哪些条件下（应用场合）表现优异，又会在哪些条件下（应用场合）出状况？根据这个猜测再检验一次simulation examples and/or experiments，看它的长处与短处是不是确实在这些examples 中充分被检验，且充分表现出来。<br>　　那么，你什么时候才需要弄懂一篇论文所有的恒等式推导过程，或者把整篇论文细细读完？NEVER！你只需要把确定会用到的部分给完全搞懂就好，不确定会不会用到的部分，只需要了解它主要的点子就够了。<br>　　硕士生和大学生最主要的差别：大学生读什么都必须要从头到尾都懂，硕士生只需要懂他用得着的部分就好了！大学生因为面对的知识是有固定的范围，所以他那样念。硕士生面对的知识是没有范围的，因此他只需要懂他所需要的细腻度就够了。硕士生必须学会选择性的阅读，而且必须锻炼出他选择时的准确度以及选择的速度，不要浪费时间在学用不着的细节知识！多吸收「点子」比较重要，而不是细部的知识。 </p>
<p>五、方法与应用场合特性表（有迹可寻的创意程序）<br>　　试着想象说你从上图中论文阅读步骤的第（4）与（5）步骤分别获得以下两张表：譬如，当你的题目是「如何标定fiducial mark 之中心位置」，你就必须要仔细搜寻出文献上所有可能可以用来做这一个工作的方法。或许你找到的方法一共有四种，依序如下。譬如（随便乱举例），「方法一」可能表示：「以面积形心标定 fiducial mark 之中心位置」，「方法二」可能表示「以 Hugh transform标定 fiducial mark 之中心位置」，「方法三」可能表示：「以局部弧形 matching 的方法标定fiducial mark 之中心位置」，「方法四」可能表示：「以 ring code标定fiducial mark 之中心位置」。<br>　　这些方法各有它的特色（优缺点），譬如（随便乱举例），特性1可能表示「计算速度」（因此，根据上表左边第一个 row，可以发现：方法一的计算速度很快，方法二与方法三的计算速度很慢，而方法四的计算速度普通。其次，特性2可能代表「光源亮度不稳定时计算位置的误差大小」，特性3可能代表「噪声对计算出的位置干扰多大」，特性4可能代表「图形边缘有破损时计算的可靠度」，特性5可能代表「对象有彼此的遮蔽时方法的适用性」等等。所以，以上左图中第五个row为例，可以发现：当对象有彼此的遮蔽时，除方法二之外其它三个方法的适用性都很好。<br>　　但是，同样一个方法可能有许多不同的应用场合，而不同应用场合可能会对适用（或最佳）的方法有不同要求。所以，让我们来看右边的「问题特性分析表」。譬如（随便乱举例），应用甲可能是「标定fiducial mark 之中心位置」的方法在「电路插件组装（SMT）」里的应用，应用乙可能是「标定fiducial mark 之中心位置」的方法在「生物检验自动化影像处理」里的应用，而应用丙则可能是「标定 fiducial mark 之中心位置」的方法在「巡乂飞弹目标搜寻」里的应用。这三种应用场合更有其关注的特性。譬如，根据上面右表第二个 row 的资料，三种应用场合对特性2（光源亮度不稳定时计算位置的误差大小）都很在意。再譬如，根据上面右表第四个 row 的资料，三种应用场合中除了应用甲（电路插件组装（SMT））之外，其它两种应用场合对特性4（图形边缘有破损时计算的可靠度）都很在意。<br>　　那么，四个方法中哪个方法最好？你可能会回答说：「方法二！因为它的优点最多，缺点最少。」但是，这样的回答是错的！一个方法只有优缺点，而没有好坏。当它被用在一个适合表现其优点而不在乎其缺点的场合里，它就显得很好；但是，当它被用在一个不适合表现其优点而很在乎其缺点的场合里，它就显得很糟。譬如，方法二在应用场合乙，它的表现会非常出色（因为所有的优点刚好那个应用场合都在意，而所有的缺点刚好那个应用场合都不在意）；但是，方法二在应用场合甲里它的表现却会非常糟糕（它所有的缺点刚好那个应用场合都很在意，而它大部分的优点刚好那个应用场合却都不在意）。所以，必须要学会的第一件是就是：方法没有好坏，只有相对优缺点点；只有当方法的特性与应用场合的特性不合时，才能下结论说这方法「不适用」；二当当方法的特性与应用场合的特性吻合时，则下结论说这方法「很适用」。因此，一定要同时有方法特性表与应用场合特性分析表放在一起后，才能判断一个方法的适用性。<br>　　更重要的是：上面的方法与问题分析对照表还可以用来把「突破瓶颈所需的创意」简化成一种「有迹可寻」的工作。譬如，假定我们要针对应用甲发展一套适用的方法，首先我们要先从上右表中标定这个应用场合关心哪些问题特性。根据上右表第一个 column，甲应用场合只关心四个特性：特性1、2、3、5（即「计算速度」、「光源亮度不稳定时计算位置的误差大小」、「噪声对计算出的位置的干扰」、「对象有彼此的遮蔽时方法的适用性」）。那么，哪个方法最适用呢？看起来是方法<br>　　一，它除了特性2表现普通之外，其它三个特性的表现都很出色。但是，假如我们对方法一的表现仍不够满意，怎么去改善它？最简单的办法就是从上左表找现成的方法和方法一结合，产生出一个更适用的方法。因为方法一只有在特性2上面表现不够令人满意，所以我们就优先针对在特性2上面表现出色的其它方法加以研究。根据上左表，在特性2上面表现出色的方法有方法二和方法四，所以我们就去研究这两个方法和方法一结合的可能性。或许（随便举例）方法四的创意刚好可以被结合进方法一而改善方法一在特性2上面的表现，那么，我们就可以因此轻易地获得一个方法一的改良，从而突破甲应用场合没有适用方法的瓶颈。<br>　　有没有可能说单纯常识结合既有方法优点仍无法突破技术瓶颈的状况？可能有。这时候真的需要完全新颖的创意了。但是，这种时候很罕见。多半时候只要应用上一段的分析技巧就可以产生足以解决实用问题的创意了。至少，要产生出一篇学术期刊论文并非那么困难。 </p>
<p>六、论文阅读的补充说明<br>　　硕士生开始学读期刊论文时，就容易犯的毛病就是戒除不掉大学部的习惯：（1）老是想逐行读懂，有一行读不懂就受不了。（2）不敢发挥自己的想象，读论文像在读教科书，论文没写的就不会，瘫痪在那里；被我逼着去自己猜测或想象时，老怕弄错作者的意思，神经绷紧，脑筋根本动不了。<br>　　大学毕业后（不管是念硕、博士或工作），可以参考的资料都没有秩序地交错成一团，而且永远都读不完。用大学生的心态读书，结果一定时间永远不够用。因此，每次读论文都一定要带着问题去读，每次读的时候都只是图回答你要回答的问题。因此，一定是选择性地阅读，一定要逐渐由粗而细地一层一层去了解。上面所规划的读论文的次序，就是由粗而细，每读完一轮，你对这问题的知识就增加一层。根据这一层知识就可以问出下一层更细致的问题，再根据这些更细致的问题去重读，就可以理解到更多的内容。因此，一定是一整批一起读懂到某个层次，而不是逐篇逐篇地整篇一次读懂。<br>　　这样读还有一个好处：第一轮读完后，可以根据第一轮所获得的知识判断出哪些论文与你的议题不相关，不相关的就不需要再读下去了。这样才可以从广泛的论文里逐层准确地筛选出你真正非懂不可的部分。不要读不会用到的东西，白费的力气必须被极小化！其实，绝大部分论文都只需要了解它的主要观念（这往往比较容易），而不需要了解它的详细推导过程（这反而比较费时）。<br>　　其次，一整批一起读还有一个好处：同一派的观念，有的作者说得较易懂，有的说得不清楚。整批读略过一次之后，就可以规划出一个你以为比较容易懂的阅读次序，而不要硬碰硬地在那里撞墙壁。你可以从甲论文帮你弄懂以论文的一个段落，没人说读懂甲论文只能靠甲论文的信息。所以，整批阅读很像在玩跳棋，你要去规划出你自己阅读时的「最省力路径」。<br>　　大学部学生读东西一定要循规蹈矩，你还没修过机械视觉相关课程之前可能也只好循规蹈矩地逐行去念。但是一旦修过机械视觉相关课程，许多论文中没被交代的段落你也已经可以有一些属于你的想象（虽然有可能猜错，尤其刚开始时经常猜错，但没关系，下面详述）。这些想象往往补足论文跳跃处最快速的解决方案。其实，一个大学毕业生所学已经很多了，对许多是都可以有一个不太离谱的想象能力。但是大部分学生却根本不敢去想象。我读论文远比学生快，分析远比学生深入，主要的是我敢想象与猜测，而且多年训练下来想象与猜测的准确度很高。所以，许多论文我根本不是「读懂」的，而是「猜对」了！<br>　　假如猜错了怎么办？不用怕！猜完一后要根据你的猜测在论文里找证据，用以判断你的猜测对不对。猜对了，就用你的猜测（其实是你的推理架构）去吸收作者的资讯与创意（这会比从头硬生生地去迁就作者的思路轻松而容易）；猜错了，论文理会有一些信息告诉你说你错了，而且因为猜错所以你读到对的答案时反而印象更深刻。 </p>
<p>七、论文报告的要求与技巧<br>　　报告一篇论文，我要求做到以下部分（依报告次序排列）：<br>　　（1） 投影片第一页必须列出论文的题目、作者、论文出处与年份。<br>　　（2） 以下每一页投影片只能讲一个观念，不可以在一张投影片里讲两个观念。<br>　　（3） 说明这篇论文所研究的问题的重点，以及这个问题可能和工业界的哪些应用相关。<br>　　（4） 清楚交代这篇论文的主要假设，主要公式，与主要应用方式（以及应用上可能的解题流程）。<br>　　（5） 说明这篇论文的范例（simulation examples and/or experiments），预测这个方法在不同场合时可能会有的准确度或好用的程度<br>　　（6） 你个人的分析、评价与批评，包括：（6A）这篇论文最主要的创意是什么？（6B）这些创意在应用上有什么好处？（6C）这些创意和应用上的好处是在哪些条件下才能成立？（6D）这篇论文最主要的缺点或局限是什么？（6E）这些缺点或局限在应用上有什么坏处？（6F）这些缺点和应用上的坏处是因为哪些因素而引入的？（6G）你建议学长学弟什么时候参考这篇论文的哪些部分（点子）？<br>　　一般来讲，刚开始报告论文（硕一上学期）时只要做到能把前四项要素说清楚就好了，但是硕一结束后（暑假开始）必须要设法做到六项要素都能触及。硕二下学期开始的时候，必须要做到六项都能说清楚。<br>　　注意：读论文和报告论文时，最重要的是它的创意和观念架构，而不是数学上恒等式推导过程的细节（顶多只要抓出关键的 equation 去弩懂以及说明清楚即可）。你报告观念与分析创意，别人容易听懂又觉得有趣；你讲恒等式，大家不耐烦又浪费时间。</p>
]]></content>
      
        <categories>
            
            <category> paper </category>
            
        </categories>
        
        
        <tags>
            
            <tag> paper </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[决策树(Decision Tree) && ID3 Algorithm]]></title>
      <url>http://yoursite.com/2017/01/13/Decision%20Tree%20&amp;&%20ID3%20Algorithm%20/</url>
      <content type="html"><![CDATA[<h1 id="分类与预测"><a href="#分类与预测" class="headerlink" title="分类与预测"></a>分类与预测</h1><p>餐饮企业经常会碰到下面的问题：</p>
<ol>
<li>如何预测未来一段时间内，哪些顾客会流失，哪些顾客最有可能成为VIP客户？</li>
<li>如何预测一种心产品的销售量，以及在哪种类型的客户中会较受欢迎？</li>
</ol>
<p>除此之外，餐厅经理需要通过数据分析来了解具有某些特征的顾客的消费习惯/这些都是分类与预测的例子。<br><a id="more"></a></p>
<h2 id="常见的分类预测算法"><a href="#常见的分类预测算法" class="headerlink" title="常见的分类预测算法"></a>常见的分类预测算法</h2><h3 id="贝叶斯"><a href="#贝叶斯" class="headerlink" title="贝叶斯"></a>贝叶斯</h3><p>贝叶斯（Bayes）分类算法是一类利用概率统计知识进行分类的算法，如朴素贝叶斯（Naive Bayes）算法。这些算法主要利用Bayes定理来预测一个未知类别的样本属于各个类别的可能性，选择其中可能性最大的一个类别作为该样本的最终类别。</p>
<h3 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h3><p>决策树是用于分类和预测的主要技术之一，决策树学习是以实例为基础的归纳学习算法，它着眼于从一组无次序、无规则的实例中推理出以决策树表示的分类规则。</p>
<h3 id="人工神经网络"><a href="#人工神经网络" class="headerlink" title="人工神经网络"></a>人工神经网络</h3><p>人工神经网络（Artificial Neural Networks，ANN）是一种应用类似于大脑神经突触联接的结构进行信息处理的数学模型。在这种模型中，大量的节点（或称”神经元”，或”单元”）之间相互联接构成网络，即”神经网络”，以达到处理信息的目的。</p>
<h3 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h3><p>支持向量机（SVM，Support Vector Machine）是Vapnik根据统计学习理论提出的一种新的学习方法，它的最大特点是根据结构风险最小化准则，以最大化分类间隔构造最优分类超平面来提高学习机的泛化能力，较好地解决了非线性、高维数、局部极小点等问题。</p>
<h1 id="决策树简介"><a href="#决策树简介" class="headerlink" title="决策树简介"></a>决策树简介</h1><p>决策树(Decision Tree)是一个预测模型，他代表的是对象属性与对象值之间的一种映射关系。树中每个节点表示某个对象，而每个分叉路径则代表的某个可能的属性值，而每个叶结点则对应从根节点到该叶节点所经历的路径所表示的对象的值。决策树仅有单一输出，若欲有复数输出，可以建立独立的决策树以处理不同输出。 数据挖掘中决策树是一种经常要用到的技术，可以用于分析数据，同样也可以用来作预测。</p>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>记录<br><img src="http://ojpgmz933.bkt.clouddn.com/17-1-15/51314537-file_1484471322544_ab94.png" alt=""></p>
<p>根据上述数据构造出如下决策树<br><img src="http://ojpgmz933.bkt.clouddn.com/17-1-15/54649081-file_1484471333776_17eac.png" alt=""></p>
<h1 id="信息熵、条件熵和信息增益"><a href="#信息熵、条件熵和信息增益" class="headerlink" title="信息熵、条件熵和信息增益"></a>信息熵、条件熵和信息增益</h1><h2 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h2><p>信息熵也称为香农熵，是随机变量的期望。度量信息的不确定程度。信息的熵越大，信息就越不容易搞清楚。处理信息就是为了把信息搞清楚，就是熵减少的过程。决定信息的不确定性或者说复杂程度主要因素是概率。</p>
<p> 我们要获得随机变量 D 的取值结果至少要进行1次试验，试验次数与随机变量 D 可能的取值数量(2种)的对数函数Log有联系。Log2=1(以2为底)。因此熵的计算公式是：</p>
<p><img src="http://images0.cnblogs.com/blog/46139/201507/241728079433989.gif" alt=""></p>
<h2 id="条件熵"><a href="#条件熵" class="headerlink" title="条件熵"></a>条件熵</h2><p>条件熵是通过获得更多的信息来消除一元模型中的不确定性。也就是通过二元或多元模型来降低一元模型的熵。我们知道的信息越多，信息的不确定性越小。例如，只使用一元模型时我们无法根据用户历史数据中的购买频率来判断这个用户本次是否也会购买。因为不确定性太大。在加入了促销活动，商品价格等信息后，在二元模型中我们可以发现用户购买与促销活动，或者商品价格变化之间的联系。并通过购买与促销活动一起出现的概率，和不同促销活动时购买出现的概率来降低不确定性。以下公式为属性A的信息条件熵。</p>
<p><img src="http://images0.cnblogs.com/blog/46139/201507/241728092875245.gif" alt=""></p>
<p>用属性A出现的概率乘以属性A确定的情况下，相应分类的信息熵。</p>
<h2 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h2><p>信息增益用来衡量信息之间相关性的指标。用于度量属性A降低样本集合X熵的贡献大小。信息增益越大，不确定性越小，越适于对X分类。具体的计算方法就熵与条件熵之间的差。公式如下：</p>
<p><img src="http://images0.cnblogs.com/blog/46139/201507/241728131317071.gif" alt=""></p>
<h1 id="ID3-算法原理"><a href="#ID3-算法原理" class="headerlink" title="ID3 算法原理"></a>ID3 算法原理</h1><blockquote>
<p>奥卡姆剃刀（Occam’s Razor, Ockham’s Razor），又称“奥坎的剃刀”，是由14世纪逻辑学家、圣方济各会修士奥卡姆的威廉（William of Occam，约1285年至1349年）提出，他在《箴言书注》2卷15题说“切勿浪费较多东西，去做‘用较少的东西，同样可以做好的事情’。简单点说，便是：be simple。</p>
</blockquote>
<p>ID3算法（Iterative Dichotomiser 3 迭代二叉树3代）是一个由Ross Quinlan发明的用于决策树的算法。这个算法便是建立在上述所介绍的奥卡姆剃刀的基础上：越是小型的决策树越优于大的决策树（be simple 简单理论）。尽管如此，该算法也不是总是生成最小的树形结构，而是一个启发式算法。</p>
<p>OK，从信息论知识中我们知道，期望信息越小，信息增益越大，从而纯度越高。ID3算法的核心思想就是以信息增益度量属性选择，选择分裂后信息增益(很快，由下文你就会知道信息增益又是怎么一回事)最大的属性进行分裂。该算法采用自顶向下的贪婪搜索遍历可能的决策树空间。</p>
<p>算法流程：</p>
<ol>
<li>对当前样本集合计算所有属性的信息增益；</li>
<li>选择信息增益最大的属性作为测试属性，把测试属性取值相同的样本划为同一个子样本集；</li>
<li>若子样本集的类别属性只含有单个属性，则分支为叶子节点，判断其属性之并标上相应的符号，然后返回调用处；否则对子样本集递归调用本算法。</li>
</ol>
<h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><p>由于ID3决策树算法采用信息增益作为选择测试属性的标准，会偏向于选择取值较多的，即所谓的高度分支属性，而这类属性并不一定是最优属性。并且其只能处理离散属性，对于连续类型属性需要对其进行离散化。为了解决倾向于选择高度分支属性的问题，采用信息增益率作为选择测试属性的标准，这样便有了C4.5决策树算法。常用的还有 CART,SLIQ,SPRINT,PUBLIC等。</p>
<h1 id="决策树实例"><a href="#决策树实例" class="headerlink" title="决策树实例"></a>决策树实例</h1><p>这是一家高尔夫球俱乐部的历史数据，里面记录了不同天气状况用户来打高尔夫球的历史记录。我们要做的是通过构建决策树来预测用户是否会来打高尔夫球。这里用户是否来打球是一个一元模型，具有不确定性，熵值很高。我们无法仅通过Yes和No的频率来判断用户明天是否会来。因此，需要借助天气的信息来减少不确定性。下面分别记录到了4种天气情况，我们通过计算条件熵和互信息来开始构建决策树的第一步：构建根决策点。<br><img src="http://ojpgmz933.bkt.clouddn.com/17-1-14/12057450-file_1484368445392_1304.png" alt=""></p>
<h2 id="构建根决策节点"><a href="#构建根决策节点" class="headerlink" title="构建根决策节点"></a>构建根决策节点</h2><p>构建根决策点的方法就是寻找4种天气情况中与打高尔夫球相关性最高的一个。首先我们来看Play Golf这个一元模型的熵，来看看这件事的不确定性有多高.</p>
<h3 id="一元模型的熵即信息熵"><a href="#一元模型的熵即信息熵" class="headerlink" title="一元模型的熵即信息熵"></a>一元模型的熵即信息熵</h3><p>在一元模型中，仅通过历史数据的概率来看预测Play Golf是一件非常不确定的事情，在14条历史数据中，打球的概率为64%，不打球的概率为36%。熵值达到了0.940。这与之前抛硬币的例子很像。在无法改变历史数据的概率时，我们需要借助更多的信息来降低不确定性。也就是计算条件熵。<br><img src="http://ojpgmz933.bkt.clouddn.com/17-1-14/88660281-file_1484368589678_1418d.png" alt=""></p>
<h3 id="二元模型条件熵"><a href="#二元模型条件熵" class="headerlink" title="二元模型条件熵"></a>二元模型条件熵</h3><p>计算二元模型的条件熵需要知道Play Golf与4种天气情况一起出现的概率，以及在不同天气情况下Play Golf出现的条件概率。下面我们分别来计算这两类概率。</p>
<p>出现概率<br><img src="http://ojpgmz933.bkt.clouddn.com/17-1-14/16481236-file_1484368665443_9e5a.png" alt=""></p>
<p>条件概率<br><img src="http://ojpgmz933.bkt.clouddn.com/17-1-14/10038807-file_1484368678860_b99e.png" alt=""></p>
<p>条件熵<br><img src="http://ojpgmz933.bkt.clouddn.com/17-1-14/30903876-file_1484368712279_a685.png" alt=""></p>
<h3 id="信息增益-1"><a href="#信息增益-1" class="headerlink" title="信息增益"></a>信息增益</h3><p>在已知Play Golf的一元模型熵和不同天气条件下的二元模型熵后。我们就可以通过信息增益来度量哪种天气与Play Golf的相关性最高了。<br><img src="http://ojpgmz933.bkt.clouddn.com/17-1-14/7604661-file_1484368761620_fe7b.png" alt=""></p>
<h3 id="构建根节点"><a href="#构建根节点" class="headerlink" title="构建根节点"></a>构建根节点</h3><p>在整个决策树中，Outlook因为与Play Golf的相关性最高，所以作为决策树的根节点。以Outlook作为根节点后，决策树出现了三个分支，分别是Outlook的三个不同的取值Sunny，Overcast和Rainy。其中Overcast所对应的Play Golf都是Yes，因此这个分支的叶子节点为Yes。<br><img src="http://ojpgmz933.bkt.clouddn.com/17-1-14/32657150-file_1484368828842_d411.png" alt=""></p>
<h2 id="构建分支节点"><a href="#构建分支节点" class="headerlink" title="构建分支节点"></a>构建分支节点</h2><p>另外两个分支我们将使用和前面一样的方法，通过计算熵，条件熵和信息增益来挑选下一个分支的决策节点。<br>通过将决策树中每个决策点还原为原始数据表可以发现，每一个决策点都对应了一张数据表。从根决策节点开始，我们通过计算熵寻找与Play Golf最相关的天气信息，来建立决策点及分支，并反复迭代这一过程。直到最终构建完整的决策树。<br><img src="http://ojpgmz933.bkt.clouddn.com/17-1-14/20779378-file_1484369378883_2419.png" alt=""><br><img src="http://ojpgmz933.bkt.clouddn.com/17-1-14/99229625-file_1484368967065_909c.png" alt=""></p>
<h2 id="使用决策树进行预测"><a href="#使用决策树进行预测" class="headerlink" title="使用决策树进行预测"></a>使用决策树进行预测</h2><p>文章开始的时候我们说过，决策树是用来进行分类和预测的。具体过程如下。当我们构建好决策树后，当有新的信息发送时，我们利用已有的决策树逻辑对新的信息结构进行判断。当信息的内容与决策树一致时，就进入下一分支进行判断，并通过叶子节点获得分类的结果。例如，当新的一天开始时，我们就可以通过4个天气特征来判断用户是否会来打高尔夫球。以下是具体预测流程的示意图，首先寻找新信息中的根决策节点Outlook，根据Outlook的取值进入到Sunny分支，在Sunny分支中继续判断下一决策点Windy的取值，新的信息中Windy的取值为FALSE，根据决策树中的逻辑返回Yes。因此在新信息中通过对天气情况的判断预测用户会来打高尔夫球。<br><img src="http://ojpgmz933.bkt.clouddn.com/17-1-14/56003626-file_1484369065520_9d04.png" alt=""></p>
<h1 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h1><p>决策树是建立在已知的历史数据及概率上的，一课决策树的预测可能会不太准确，提高准确率最好的方法是构建随机森林(Random Forest)。所谓随机森林就是通过随机抽样的方式从历史数据表中生成多张抽样的历史表，对每个抽样的历史表生成一棵决策树。由于每次生成抽样表后数据都会放回到总表中，因此每一棵决策树之间都是独立的没有关联。将多颗决策树组成一个随机森林。当有一条新的数据产生时，让森林里的每一颗决策树分别进行判断，以投票最多的结果作为最终的判断结果。以此来提高正确的概率。</p>
<h2 id="使用-Mahout-进行-Random-Forests-实现"><a href="#使用-Mahout-进行-Random-Forests-实现" class="headerlink" title="使用 Mahout 进行 Random Forests 实现"></a>使用 Mahout 进行 Random Forests 实现</h2><p>数据集示例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">1,1.52101,13.64,4.49,1.10,71.78,0.06,8.75,0.00,0.00,1</div><div class="line">2,1.51761,13.89,3.60,1.36,72.73,0.48,7.83,0.00,0.00,1</div><div class="line">3,1.51618,13.53,3.55,1.54,72.99,0.39,7.78,0.00,0.00,1</div><div class="line">4,1.51766,13.21,3.69,1.29,72.61,0.57,8.22,0.00,0.00,1</div><div class="line">5,1.51742,13.27,3.62,1.24,73.08,0.55,8.07,0.00,0.00,1</div><div class="line">6,1.51596,12.79,3.61,1.62,72.97,0.64,8.07,0.00,0.26,1</div><div class="line">7,1.51743,13.30,3.60,1.14,73.09,0.58,8.17,0.00,0.00,1</div><div class="line">8,1.51756,13.15,3.61,1.05,73.24,0.57,8.24,0.00,0.00,1</div><div class="line">9,1.51918,14.04,3.58,1.37,72.08,0.56,8.30,0.00,0.00,1</div><div class="line">10,1.51755,13.00,3.60,1.36,72.99,0.57,8.40,0.00,0.11,1</div><div class="line">...</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div></pre></td><td class="code"><pre><div class="line">//上传数据集</div><div class="line">$ hadoop fs -put glass.txt /user/ubuntu/glass.txt</div><div class="line"></div><div class="line">//生成描述文件</div><div class="line">ubuntu@master:~/algorithm$ mahout describe -p /user/ubuntu/glass.txt -f glass.info -d I 9 N L</div><div class="line">MAHOUT_LOCAL is not set; adding HADOOP_CONF_DIR to classpath.</div><div class="line">Running on hadoop, using /home/ubuntu/cloud/hadoop-2.7.2/bin/hadoop and HADOOP_CONF_DIR=/home/ubuntu/cloud/hadoop-2.7.2/etc/hadoop</div><div class="line">MAHOUT-JOB: /home/ubuntu/cloud/mahout-0.10.1/mahout-examples-0.10.1-job.jar</div><div class="line">17/01/14 02:53:49 WARN MahoutDriver: No describe.props found on classpath, will use command-line arguments only</div><div class="line">17/01/14 02:53:49 INFO Describe: Generating the descriptor...</div><div class="line">17/01/14 02:53:50 INFO Describe: generating the dataset...</div><div class="line">17/01/14 02:53:51 INFO Describe: storing the dataset description</div><div class="line">17/01/14 02:53:51 INFO MahoutDriver: Program took 1584 ms (Minutes: 0.0264)</div><div class="line"></div><div class="line">// 生成随机森林</div><div class="line">$ mahout buildforest -d /user/ubuntu/glass.txt -ds glass.info -sl 3 -ms 3 -p -t 5 -o output</div><div class="line"></div><div class="line">....</div><div class="line"></div><div class="line">17/01/14 03:05:50 INFO HadoopUtil: Deleting hdfs://master:9000/user/ubuntu/output</div><div class="line">17/01/14 03:05:50 INFO BuildForest: Build Time: 0h 0m 15s 86</div><div class="line">17/01/14 03:05:50 INFO BuildForest: Forest num Nodes: 203</div><div class="line">17/01/14 03:05:50 INFO BuildForest: Forest mean num Nodes: 40</div><div class="line">17/01/14 03:05:50 INFO BuildForest: Forest mean max Depth: 9</div><div class="line">17/01/14 03:05:50 INFO BuildForest: Storing the forest in: output/forest.seq</div><div class="line">17/01/14 03:05:50 INFO MahoutDriver: Program took 16124 ms (Minutes: 0.2687333333333333)</div><div class="line"></div><div class="line">// 对随机森林进行评估</div><div class="line">$ mahout testforest -i /user/ubuntu/glass.txt -ds glass.info -m output -mr -a -o test</div><div class="line">...</div><div class="line"></div><div class="line">17/01/14 03:09:48 INFO TestForest: </div><div class="line">=======================================================</div><div class="line">Summary</div><div class="line">-------------------------------------------------------</div><div class="line">Correctly Classified Instances          :        191	   89.2523%</div><div class="line">Incorrectly Classified Instances        :         23	   10.7477%</div><div class="line">Total Classified Instances              :        214</div><div class="line"></div><div class="line">=======================================================</div><div class="line">Confusion Matrix</div><div class="line">-------------------------------------------------------</div><div class="line">a    	b    	c    	d    	e    	f    	&lt;--Classified as</div><div class="line">68   	1    	1    	0    	0    	0    	 |  70    	a     = 1</div><div class="line">6    	68   	1    	0    	0    	1    	 |  76    	b     = 2</div><div class="line">5    	1    	11   	0    	0    	0    	 |  17    	c     = 3</div><div class="line">0    	0    	0    	10   	0    	3    	 |  13    	d     = 5</div><div class="line">0    	0    	0    	0    	8    	1    	 |  9     	e     = 6</div><div class="line">1    	1    	1    	0    	0    	26   	 |  29    	f     = 7</div><div class="line"></div><div class="line">=======================================================</div><div class="line">Statistics</div><div class="line">-------------------------------------------------------</div><div class="line">Kappa                                       0.7707</div><div class="line">Accuracy                                   89.2523%</div><div class="line">Reliability                                72.3985%</div><div class="line">Reliability (standard deviation)            0.3365</div><div class="line">Weighted precision                           0.897</div><div class="line">Weighted recall                             0.8925</div><div class="line">Weighted F1 score                           0.8914</div><div class="line"></div><div class="line">17/01/14 03:09:48 INFO MahoutDriver: Program took 18829 ms (Minutes: 0.3138166666666667)</div></pre></td></tr></table></figure>
<p>参考文章</p>
<blockquote>
<p>张良均等.Hadoop大数据分析与挖掘实战.机械工业出版社.2016.10<br><a href="http://blog.csdn.net/mikefei007/article/details/53895015" target="_blank" rel="external">决策树分类和预测算法的原理及实现</a><br><a href="http://www.cnblogs.com/hantan2008/archive/2015/07/27/4674097.html" target="_blank" rel="external">数据挖掘之决策树</a><br><a href="http://www.cnblogs.com/leoo2sk/archive/2010/09/19/decision-tree.html" title="算法杂货铺——分类算法之决策树(Decision tree)" target="_blank" rel="external">算法杂货铺——分类算法之决策树</a><br><a href="http://www.cnblogs.com/wentingtu/archive/2012/03/24/2416235.html" target="_blank" rel="external">了解信息增益和决策树</a></p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> Machine learning </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Algorithm </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[「China Daily」Tencent launches WeChat 'mini apps']]></title>
      <url>http://yoursite.com/2017/01/10/Tencent%20launches%20WeChat%20mini%20app/</url>
      <content type="html"><![CDATA[<p><em>By Fan Feifei | China Daily | Updated: 2017-01-10 07:10</em></p>
<blockquote>
<p><a href="http://www.chinadaily.com.cn/business/tech/2017-01/10/content_27906217.htm" target="_blank" rel="external">http://www.chinadaily.com.cn/business/tech/2017-01/10/content_27906217.htm</a></p>
</blockquote>
<p><img src="http://www.chinadaily.com.cn/business/tech/img/attachement/jpg/site1/20170110/a41f726b084119de5d5d01.jpg" alt=""><br><em>Chinese people check their WeChat 14.5 times on average and spend 48 minutes on social media per day. [Photo/IC]</em></p>
<h1 id="News-text"><a href="#News-text" class="headerlink" title="News text"></a>News text</h1><p>Chinese internet giant Tencent Holdings Ltd launched “mini apps” on Monday, which let users interact with app-like services within its instant messaging app WeChat, without having to download and install them.</p>
<a id="more"></a>
<p>Users just need to scan the QR code or search from their WeChat accounts to open these apps, where they could book tickets or do shopping, Tencent said.</p>
<p>They can exit the apps easily without downloading them, these apps won’t disturb users, such as by sending notifications and subscription messages, according to Tencent.</p>
<p>This is an important step in Tencent’s commercialization of its messaging service. WeChat now has 846 million users worldwide, according to Tencent’s fiscal 2016 third-quarter earnings report.</p>
<p>Lu Zhenwang, CEO of Shanghai-based Wanqing Consultancy, said: “The launch of mini apps can solve some of the problems caused by apps, but it won’t take the place of AppStore or Android Market.”</p>
<p>“Some ‘lightweight’ apps, which possess fewer functions and more simple algorithms, and apps that are not commonly used, are more suitable as WeChat’s mini apps. However, the commonly used ones should still be downloaded to your phone,” Lu added.</p>
<p>Dong Xu, an analyst with Beijing-based consultancy Analysis, said: “With the mini apps, users could find and use them whenever they need, and won’t receive any advertising when they stop using them.”</p>
<p>The aim is to ensure users spend more time on WeChat and extend Tencent’s lead as an app vendor. Mobile app developers are vying for users in the fiercely competitive and lucrative market.</p>
<p>Chinese people check their WeChat 14.5 times on average and spend 48 minutes on social media per day, according to a report released by Chinese tech startup Kika.</p>
<p>Wang Qian, an employee of an IT company, has tried the “mini apps” since they were launched on Monday.</p>
<p>“The design of these apps is very clear, and will increase the utilization rate of the WeChat wallet. Maybe it could replace some apps, but I still prefer to download apps from my app store.”</p>
<h1 id="Words"><a href="#Words" class="headerlink" title="Words:"></a>Words:</h1><ul>
<li>Tencent Holdings Ltd : 腾讯控股有限公司</li>
<li>Ltd : 有限责任公司（Limited）</li>
<li>QR-Code ：二维码 Quick Response(QR) code 快速响应矩阵码(QR)<br><em>a machine-readable code consisting of an array of black and white squares, typically used for storing URLs or other information for reading by the camera on a smartphone.</em></li>
<li>consultancy：咨询公司；顾问工作</li>
<li>lightweight：轻量级</li>
<li>fiercely：猛烈地；厉害地</li>
<li>lucrative： 有利可图的，赚钱的；合算的</li>
<li>vie : 争；竞争</li>
<li>vendor：卖主；小贩；供应商；[贸易] 自动售货机</li>
</ul>
<h1 id="Translation"><a href="#Translation" class="headerlink" title="Translation"></a>Translation</h1><p>中国互联网巨头腾讯控股有限公司在周一上线了“小程序”。用户可以在即时通讯软件微信中与类似App的服务交互，而不需要下载和安装它们。</p>
<p>腾讯说，用户只需要扫描二维码或者从他们的微信账号中搜索以打开这些App。在小程序中用户可以订票或者购物。</p>
<p>他们不用下载就可以轻松地退出App，这些小程序也不会通过发送通知和订阅消息来打扰用户，据腾讯所说。</p>
<p>这是腾讯将其信息服务商业化中非常重要的一步。据腾讯2016年第三季度财报显示，微信目前在世界范围内拥有8.46亿用户。</p>
<p>Lu Zhenwang，上海万青咨询公司CEO，说：“小程序的上线可以解决一些App的问题，但是其无法代替App Store 和 Android Market”。</p>
<p>“一些有少量方法和简单算法的轻应用，和一些不经常使用的应用非常适合与微信小程序。然而，经常使用的应用还是应该下载道你的手机上。”Lu 补充说。</p>
<p>Dong Xu，北京咨询分析公司的分析师，说：“有了小程序，用户可以在需要时找到并使用它们，并且在停止使用后不会受到任何广告。”</p>
<p>其目标是为了确保用户在微信上花费更多时间，并延伸腾讯作为应用程序供应商的领军地位。移动应用开发者正在竞争激烈和利益丰厚的市场上竞争用户。</p>
<p>根据中国科技创业公司KIka发布的一份报告，中国人每天平均查看微信14.5次，花费48分钟在社交媒体上。</p>
<p>Wang Qian，一个IT公司的职员，从周一小程序上线就开始试用。“Apps的设计非常清晰，并且会增加微信钱包的使用率。或许其可以代替某些App，但是我依然喜欢从app store下载App。”</p>
<h1 id="Thought"><a href="#Thought" class="headerlink" title="Thought"></a>Thought</h1><p>这是第一篇英文新闻的翻译，打算接下来按照这个模式，隔几天能翻译一篇新闻或者短文章，学习积累，并且在后面能够做自己的思考。</p>
<p>这两天微信小程序的上线，也是在各大科技媒体的首页上火了一番。好奇心使然，我也在上线第一天就尝试试用了几个小程序，比如有道词典、豆瓣评分、滴滴出行。使用下来，第一感受就是，确实如上China Daily的新闻中所说，小程序适合于轻应用。传统的类似图片处理、大型社交类应用还是应该下载App体验更加完善。</p>
<p>小程序是基于网页的，那么其功能性肯定受到限制。可以设想这样一些场景是比较适合的。一些你不常打开的小应用，比如豆瓣评分。在看电影前，通过微信小程序查询电影评分来决定是否要观看某一部影片；在餐厅通过点餐小程序进行点餐。目标是轻便、简单、直接。</p>
<p>微信小程序的入口是二维码，并且无推送，不能分享到朋友圈，这就决定了企业要通过小程序来赚取流量是一个相对困难的做法。订阅号解决了传统的短信推送问题，让用户的体验更好。我认为小程序解决的是工具问题，它不适合做媒体应用。类似于今日头条Lite这样的小程序，本质上还是把小程序当作第二个WEB新闻界面来做，我觉得用处并不大。我一直在想，目前二维码（QR Code）作为各种功能、页面的入口似乎有些不够便利，用户需要打开手机摄像头，扫码，再进入相应内容，并且很多页面由于微信的限制，还需要用手机浏览器中打开。这并不是我理想中的交互方式，觉得未来肯定会出现更加便利的解决方案。</p>
<p>小程序能够分享到微信群，微信好友，这是一个信息传递的过程，信息的分享、传递都在微信中就能实现，似乎微信想要把web搬到其中。知乎上一个回答说道，这就是在 Cosplay Web 。这似乎不无道理。</p>
<p>目前小程序的发布有严格限制，还不支持个人开发者，有点遗憾。兴趣使然，果断就找了个教程开始学起来，想要看看小程序的整个实现过程，才能深入理解它的精髓。</p>
<p>小程序到底会不会成功，拭目以待。</p>
]]></content>
      
        <categories>
            
            <category> 好奇心英语 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> ChinaDaily </tag>
            
            <tag> News </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[hive动态分区]]></title>
      <url>http://yoursite.com/2017/01/03/hive%E5%8A%A8%E6%80%81%E5%88%86%E5%8C%BA/</url>
      <content type="html"><![CDATA[<p>实际使用中需要对处理后的数据按照时间分开，后续有按照时间的插入和删除操作，所以用hive的分区表是一个很好的解决方案。<br>比较蛋疼的是，由于 hive 不支持使用 load 语句进行动态分区插入数据，所以要新建一个表，再用 insert 语句把表中数据导入到新建的分区表中。</p>
<a id="more"></a>
<h2 id="测试数据内容"><a href="#测试数据内容" class="headerlink" title="测试数据内容"></a>测试数据内容</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">103646	铁血皇城	3	2016-04-19	2016-04-19</div><div class="line">104046	铁骑三国	39	2016-04-19	2016-04-19</div><div class="line">1041	九阴绝学	2	2016-03-26	2016-03-26</div><div class="line">104238	传奇盛世	3	2016-04-28	2016-04-28</div><div class="line">104928	天问	1	2016-02-27	2016-02-27</div><div class="line">106417	神曲	2	2016-04-15	2016-04-15</div><div class="line">10883	灵域	1	2016-04-15	2016-04-15</div></pre></td></tr></table></figure>
<p><em>由于后续还需要使用分区后的数据进行MapReduce操作，所以在后面复制了一段时间字段（分区后，分区字段会变成hive中的文件夹名）</em></p>
<h2 id="创建表并导入数据"><a href="#创建表并导入数据" class="headerlink" title="创建表并导入数据"></a>创建表并导入数据</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">create table IGCT(id STRING,game STRING,count INT,time STRING,addtime  STRING)</div><div class="line">row format delimited</div><div class="line">fields terminated by &apos;\t&apos;</div><div class="line">stored as textfile;</div><div class="line"></div><div class="line">LOAD DATA INPATH &apos;/recommend/hive/partitionTest&apos; INTO TABLE IGCT_static;</div></pre></td></tr></table></figure>
<h2 id="建立分区表并导入数据"><a href="#建立分区表并导入数据" class="headerlink" title="建立分区表并导入数据"></a>建立分区表并导入数据</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">set hive.exec.dynamic.partition.mode=nonstrict; </div><div class="line">set hive.exec.dynamic.partition=true;</div><div class="line"></div><div class="line">CREATE  TABLE IGCT_dynamic(id STRING,game STRING,count INT,time STRING)                                                                            </div><div class="line">partitioned by(addtime  STRING)</div><div class="line">ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos;\t&apos;</div><div class="line">STORED AS TEXTFILE</div><div class="line"></div><div class="line"></div><div class="line">insert overwrite table IGCT_dynamic partition(addtime)      </div><div class="line">select * from   IGCT;     </div><div class="line">`</div></pre></td></tr></table></figure>
<h2 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">hive&gt; select * from IGCT_dynamic;</div><div class="line">OK</div><div class="line">104928	天问	1	2016-02-27	2016-02-27</div><div class="line">1041	九阴绝学	2	2016-03-26	2016-03-26</div><div class="line">106417	神曲	2	2016-04-15	2016-04-15</div><div class="line">10883	灵域	1	2016-04-15	2016-04-15</div><div class="line">103646	铁血皇城	3	2016-04-19	2016-04-19</div><div class="line">104046	铁骑三国	39	2016-04-19	2016-04-19</div><div class="line">104238	传奇盛世	3	2016-04-28	2016-04-28</div><div class="line">Time taken: 0.054 seconds, Fetched: 7 row(s)</div></pre></td></tr></table></figure>
<h2 id="删除分区"><a href="#删除分区" class="headerlink" title="删除分区"></a>删除分区</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ALTER TABLE IGCT_dynamic DROP IF EXISTS PARTITION (addtime=&apos;2016-02-27&apos;);</div></pre></td></tr></table></figure>
<h2 id="查看数据-1"><a href="#查看数据-1" class="headerlink" title="查看数据"></a>查看数据</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">hive&gt; select * from IGCT_dynamic2;</div><div class="line">OK</div><div class="line">1041	九阴绝学	2	2016-03-26	2016-03-26</div><div class="line">106417	神曲	2	2016-04-15	2016-04-15</div><div class="line">10883	灵域	1	2016-04-15	2016-04-15</div><div class="line">103646	铁血皇城	3	2016-04-19	2016-04-19</div><div class="line">104046	铁骑三国	39	2016-04-19	2016-04-19</div><div class="line">104238	传奇盛世	3	2016-04-28	2016-04-28</div><div class="line">Time taken: 0.062 seconds, Fetched: 6 row(s)</div></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Hive </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[2016 Summary]]></title>
      <url>http://yoursite.com/2017/01/02/2016%20Summary/</url>
      <content type="html"><![CDATA[<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=3&id=798411813&auto=0&height=66"></iframe>

<p>转眼已经过了一年，前些日子累的不行，元旦昏睡了两日养足精神。来到实验室发现几天前买的风信子意外地开花了，淡紫色。那就写一篇简短的年终总结吧。</p>
<a id="more"></a>
<h2 id="收获"><a href="#收获" class="headerlink" title="收获"></a>收获</h2><p>2016年没有什么意外地考上了研究生应该算是一个不小的收获。研究生确是完全不一样的学习时光，不禁想想本科真的是浪费生命。996的时间安排非常紧凑，好在实验室有一群有趣的小伙伴，生活也并不枯燥。<br>暑假就被拉过来做项目，虽然困难重重，现在还没有上线，但至少实实在在地开始干了。慢慢发现敲代码也并不是那么无聊，特别是功能实现的时候，还是充满喜悦。不过自己还是经验少，不太会变通，往往一个问题卡一大段时间。</p>
<h2 id="遗憾"><a href="#遗憾" class="headerlink" title="遗憾"></a>遗憾</h2><p>一个不小的遗憾应该就是没有去看成逼哥的跨年了吧。前几天看微博上看到跨年的信息还是满满的遗憾，今年还请了崔健当嘉宾，场馆也变成了奥体，看来真的是越来越出名了。谈了一场龙卷风似的恋爱，和歌里写的一模一样，也就对抢票不上心了，反正没人陪。</p>
<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=26523120&auto=0&height=66"></iframe>

<p>出去骑车的日子越来越少了。限于实验室的作息时间，休息日也只有一天，非常可惜。待在室内久了真的会压抑，希望接下来能多挤时间出去骑骑车，或者去别的地方看看也好。曾经脑子一热就骑车回家的做法真的太有趣了。</p>
<p>说好的周末抽时间学编曲荒废了实在可惜。本想做个爱好，偶尔能够写出一二首小歌，聊聊当下，多么快活。希望今年能够开始学。</p>
<p>之前考研的暑假有和小伙伴一起健身了一两个月。每天学习一天，抽一小时出来运动健身，这样的状态真的很不错。效果先撇开不说，自己的精神状态会好很多。多运动，少打游戏，做个阳光少年。</p>
<p>自己对于时间的合理安排还是欠缺，接下来需要好好得对自己的每周每日的时间做好规划。前些日子一个博主讲到自己的时间规划就是把当天的安排做完再休息，这也不失为一个好办法。对我这中拖延症患者，时间规划真的太重要了。</p>
<h2 id="展望"><a href="#展望" class="headerlink" title="展望"></a>展望</h2><p>前些天看了一个学长的面试经历视频，发现自己不足之处还很多。要用研究生的时间补上浪费的四年的本科时光。现在开始起码每周研究一个算法，做一道面试题。</p>
<p>学到的东西还是要多用。最近的王菲「幻乐一场」演唱会争议很大，又是走音又是天价票，台下十年功，并不无道理，三年后再重返舞台绝对不是一回事。</p>
<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=299644&auto=0&height=66"></iframe>

<p>2017让自己的生活丰富一点，对自己的规划明确一点。</p>
]]></content>
      
        <categories>
            
            <category> 生活感悟 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 总结 </tag>
            
            <tag> 日常 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MapReduce程序异常捕获存储]]></title>
      <url>http://yoursite.com/2016/12/16/MapReduce%E7%A8%8B%E5%BA%8F%E5%BC%82%E5%B8%B8%E6%8D%95%E8%8E%B7%E5%AD%98%E5%82%A8/</url>
      <content type="html"><![CDATA[<p>在Map或reduce中使用multipleOutput来进行异常存储：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">try&#123;</div><div class="line">	...</div><div class="line">	...</div><div class="line">	context.write(newKey,newValue);</div><div class="line"></div><div class="line">&#125;catch(Exception e)&#123;</div><div class="line">	multipleOutput.write(new Text( null == e.getMessage()? (&quot;error:&quot;): e.getMessage),new Text(value.toString()),&quot;_error/part&quot;);</div><div class="line">	e.printStackTrace();</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MapReduce </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MapReduce 递归子目录和合并小文件]]></title>
      <url>http://yoursite.com/2016/12/12/MapReduce%20%E9%80%92%E5%BD%92%E5%AD%90%E7%9B%AE%E5%BD%95%E5%92%8C%E5%90%88%E5%B9%B6%E5%B0%8F%E6%96%87%E4%BB%B6/</url>
      <content type="html"><![CDATA[<h2 id="递归子目录"><a href="#递归子目录" class="headerlink" title="递归子目录"></a>递归子目录</h2><p>设置<code>mapreduce.input.fileinputformat.input.dir.recursive=true</code>，这个参数是客户端参数，可以在MapReduce中设置，也可以在mapred-site.xml中设置.在mapreduce程序中如<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">// 递归子目录</div><div class="line">job.getConfiguration().setBoolean(&quot;mapreduce.input.fileinputformat.input.dir.recursive&quot;,true);</div></pre></td></tr></table></figure></p>
<h2 id="CombineTextInputFormat-合并小文件"><a href="#CombineTextInputFormat-合并小文件" class="headerlink" title="CombineTextInputFormat 合并小文件"></a>CombineTextInputFormat 合并小文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">//设置split大小</div><div class="line">job.getConfiguration().setLong(&quot;mapreduce.input.fileinputformat.split.maxsize&quot;, 128 * 1024 * 1024);</div><div class="line"></div><div class="line">//job.setInputFormatClass(TextInputFormat.class);</div><div class="line">		</div><div class="line">// 合并小文件</div><div class="line">job.setInputFormatClass(CombineTextInputFormat.class);</div></pre></td></tr></table></figure>]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MapReduce </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MapReduce应用中CombineFileInputFormat原理与用法]]></title>
      <url>http://yoursite.com/2016/12/12/MapReduce%E5%BA%94%E7%94%A8%E4%B8%ADCombineFileInputFormat%E5%8E%9F%E7%90%86%E4%B8%8E%E7%94%A8%E6%B3%95/</url>
      <content type="html"><![CDATA[<blockquote>
<p>转载自：<a href="http://ju.outofmemory.cn/entry/72024" target="_blank" rel="external">http://ju.outofmemory.cn/entry/72024</a></p>
</blockquote>
<p>HDFS本身被设计来存储大文件，但是有时难免会有小文件出现，有时很可能时大量的小文件。通过MapReduce处理大量小文件时会遇到些问题。</p>
<p>MapReduce程序会将输入的文件进行分片(Split)，每个分片对应一个map任务，而默认一个文件至少有一个分片，一个分片也只属于一个文件。这样大量的小文件会导致大量的map任务，导致资源过度消耗，且效率低下。Hadoop自身包含了CombineFileInputFormat，其功能是将多个小文件合并如一个分片，由一个map任务处理，这样就减少了不必要的map数量。</p>
<p>在了解CombineFileInputFormat之前，我们应了解其父类FileInputFormat的基本处理逻辑。注意这里的FileInputFormat的路径是<strong>org.apache.hadoop.mapreduce.lib.input.FileInputFormat</strong>，是新的MapReduce API。 mapred包下的FileInputFormat对应老的API，不再推荐使用。</p>
<a id="more"></a>
<p><a href="http://www.sqlparty.com/wp-content/uploads/2013/12/CombineFileInputFormat_type.png" target="_blank" rel="external"><img src="http://www.sqlparty.com/wp-content/uploads/2013/12/CombineFileInputFormat_type.png" alt="CombineFileInputFormat_type"></a></p>
<h2 id="FileInputFormat的基本处理逻辑"><a href="#FileInputFormat的基本处理逻辑" class="headerlink" title="FileInputFormat的基本处理逻辑"></a>FileInputFormat的基本处理逻辑</h2><p>FileInputFormat是基于文件的InputFormat的抽象基类，如上图所示，基于文件的衍生类有很多，如文本文件TextInputFormat，序列文件SequenceFileInputFormat等。</p>
<p>FileInputFormat提供了分片的基本实现getSplits(JobContext)，其子类可以重写isSplitable(JobContext, Path)方法，来使得输入的一个或多个文件是否不做分片，完整由被一个Map任务进行处理。</p>
<p>FileInputFormat有如下特点：</p>
<ol>
<li>将以下划线&#8221;_&#8221;或点&#8221;.&#8221;开头的文件作为隐藏文件，不做为输入文件。</li>
<li>所有文件isSplitable(JobContext, Path)都是true，但是针对如果输入文件时压缩的、流式的，那么子类中应重新该函数，判断是否真的可以分片。</li>
<li><p>由于每个文件块大小可能不一样，所以每个文件分别计算分片大小，计算规则如下：</p>
<ol>
<li><p>取值A：</p>
<ol>
<li>FormatMinSplitSize，本Format设置的最小Split大小，通过GetFormatMinSplitSize()获取，此类中定义为1个字节。</li>
<li>MinSplitSize，配置文件(配置键mapreduce.input.fileinputformat.split.minsize)或者直接设置，通过GetMinSplitSize()获取)，未设置则为0。</li>
<li>取两者较大值。</li>
</ol>
</li>
<li><p>取值B:</p>
<ol>
<li>MaxSplitSize，通过配置文件设置或者SetMaxSplitSize()设置，通过GetMaxSplitSize()获取，无设置则取LONG.MAXVALUE。</li>
<li>文件块大小BLOCKSIZE</li>
<li>取两者较小值</li>
</ol>
</li>
<li><p>再取A、B的较大值。</p>
</li>
<li>例：常用的TextInputFormat类中，没有对分片算法进行重写，那么我们可以认为，使用TextInputFormat时，在未做其他设置的情况下，默认分片大小等于BLOCKSIZE，如果设置了mapreduce.input.fileinputformat.split.minsize，则取其与BLOCK的较大值。</li>
</ol>
</li>
<li><p>分片大小确定后，就将文件进行依次划分。</p>
</li>
</ol>
<h2 id="文本类型TextInputFormat的使用"><a href="#文本类型TextInputFormat的使用" class="headerlink" title="文本类型TextInputFormat的使用"></a>文本类型TextInputFormat的使用</h2><p>如上我们知道TextInputFormat是FileInputFormat的子类，其自定义内容很少，通过它可以大致知道扩展FileInputFormat大致需要做些什么。整个类如下：</p>
<pre><code>public class TextInputFormat extends FileInputFormat&amp;lt;LongWritable, Text&amp;gt; {

  @Override
  public RecordReader&amp;lt;LongWritable, Text&amp;gt;
    createRecordReader(InputSplit split,
                       TaskAttemptContext context) {
    String delimiter = context.getConfiguration().get(
        &amp;quot;textinputformat.record.delimiter&amp;quot; );
    byte[] recordDelimiterBytes = null;
    if ( null != delimiter)
      recordDelimiterBytes = delimiter.getBytes(Charsets. UTF_8);
    return new LineRecordReader(recordDelimiterBytes);
  }

  @Override
  protected boolean isSplitable(JobContext context, Path file) {
    final CompressionCodec codec =
      new CompressionCodecFactory(context.getConfiguration()).getCodec(file);
    if ( null == codec) {
      return true;
    }
    return codec instanceof SplittableCompressionCodec;
  }
}
</code></pre><p>分片的方式采用的是父类FileInputFormat的逻辑，上文中已经说明。重写了isSplitable()，根据文本文件的压缩属性来判断是否可以进行分片。</p>
<p>而createRecorderReader()是定义文本文件的读取方式，实际文件读取是通过它返回的RecordReader&lt;LongWritable, Text&gt;类实现的。</p>
<p>这样，在整个输入文件读取过程，大致会涉及如下几个步骤：</p>
<ol>
<li>指定输入文件路径，如FileInputFormat.addInputPaths(job, args[0])</li>
<li>指定文件的处理类型，如job.setInputFormatClass(MyInputFormat. class)</li>
<li><p>在这个InputFormatClass内部，考虑:</p>
<ol>
<li>是否可以进行分片 isSplitable(JobContext context, Path file)</li>
<li>如何分片 List&lt;InputSplit&gt; getSplits(JobContext job)</li>
<li>如何读取分片中的记录 RecordReader&lt;LongWritable, Text&gt; createRecordReader(InputSplit split,TaskAttemptContext context)</li>
<li>以上确定后，用户开发的Map任务中就可以直接处理每一条记录KeyValue。</li>
</ol>
</li>
</ol>
<p>这些步骤下，我们基本就可以理解TextInputFormat如何被使用了。其他类型的InputFormat子类，其流程步骤也基本与上相同，可以重写相关的类方法来实现不同处理方式。</p>
<p>从TextInputFormat中的分片逻辑(FileInputFormat的getSplits)中可以确定，分片都是针对单个文件而言的，如果文件本身较小，没有达到一个分片大小，那么每个小文件都是一个分片。而一个分片就对应一个Map任务。如果有大量的小文件作为Map的输入，那么其会导致生成大量Map任务，造成处理的缓慢、资源的浪费，如何减少map任务的数量提高处理效率呢？CombineInputFormat就是为解决这样的问题。</p>
<h2 id="3-CombineInputFormat原理与用法"><a href="#3-CombineInputFormat原理与用法" class="headerlink" title="3.CombineInputFormat原理与用法"></a>3.CombineInputFormat原理与用法</h2><p>CombineInputFormat的功能，是将一个<strong>目录</strong>（可能包括多个小文件，不包括子目录）作为一个map的输入，而不是通常使用一个<strong>文件</strong>作为输入。</p>
<p>CombineInputFormat本身是个抽象类，要使用它，涉及：</p>
<p><strong> 1)CombineFileSplit </strong></p>
<p>我们的目标是使得一个split不是属于一个文件，而是可能包含多个文件，所以这里不再使用常用的FileSplit，而是CombineFileSplit，包括了各个文件的路径、长度、读的起始位置等信息。CombineFileSplit是CombineInputFormat中getSplits()的对象类型。</p>
<p><strong>2)CombineInputFormat 核心处理类</strong></p>
<p>2.1)其基本思想：</p>
<p>分片从指定路径下的多个文件构建，不同文件可以放入不同的pool，一个分片只能包含一个pool中的文件，可以包括多个文件的Block。pool其实是针对文件进行了逻辑划分，不同的pool中的文件分别进行分片。分片的逻辑如下文所示。</p>
<p>2.2)分片的逻辑：</p>
<ol>
<li>如果指定了maxSplitSize(&#8220;mapreduce.input.fileinputformat.split.maxsize&#8221;)，那么在同一个节点上的Blocks合并，一个超过maxSplitSize就生成新分片。如果没有指定，则只汇总本节点BLock，暂不分片。</li>
<li>如果指定了minSizeNode(&#8220;mapreduce.input.fileinputformat.split.minsize.per.node&#8221;),那么会把1.中处理剩余的Block，进行合并，如果超过minSizeNode，那么全部作为一个分片。否则这些Block与同一机架Rack上的块进行合并。</li>
<li>每个节点上如上同样的方式处理，然后针对整个Rack的所有Block，按照1.方式处理。剩余部分，如果指定了minSizeRack(&#8220;mapreduce.input.fileinputformat.split.minsize.per.rack&#8221;)，并且超过minSizeRack，则全部作为一个分片，否则这些Block保留，等待与所有机架上的剩余Block进行汇总处理。</li>
<li>每个机架上都按照1，2，3方式处理，汇总所有处理剩下的部分，再按照1的逻辑处理。再剩余的，作为一个分片。</li>
</ol>
<p>以上逻辑我们可以知道：</p>
<p>如果只设置maxSplitSize(如job.getConfiguration().set( &#8220;mapreduce.input.fileinputformat.split.maxsize&#8221; , &#8220;33554432&#8243;))，那么基本每个分片大小都需凑满maxSplitSize。</p>
<p><strong>如果maxSplitSize，minSizeNode，minSizeRack三个都没有设置，那是所有输入整合成一个分片！</strong></p>
<p><strong>3)CombineFileRecordReader </strong></p>
<p>针对一个CombineFileSplit分片的通用RecordReader。CombineFileSplit中包含多个文件的块信息，CombineFileRecordReader是文件层面的处理，例如何时切换到分片中的下一个文件，而单个文件的处理，则需要自定义RecordReader的子类，读取文件的记录。</p>
<p>hadoop自带的示例应用org.apache.hadoop.examples.MultiFileWordCount，用到了CombineInputFormat，其处理流程：</p>
<p><a href="http://www.sqlparty.com/wp-content/uploads/2013/12/MultiFileWordCount.png" target="_blank" rel="external"><img src="http://www.sqlparty.com/wp-content/uploads/2013/12/MultiFileWordCount.png" alt="MultiFileWordCount"></a></p>
<p>要使用CombineInputFormat进行应用开发，可以参考org.apache.hadoop.examples.MultiFileWordCount中使用方式，需要自行实现CombineFileInputFormat的子类与实际读取逐条记录的RecordReader子类。</p>
<p>而MultiFileWordCount的使用如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line">shell&amp;gt; hadoop fs -ls -h /tmp/carl/2013-07-12/</div><div class="line"></div><div class="line"> Found 4 items</div><div class="line"></div><div class="line"> -rw-r&amp;#8211;r&amp;#8211;   3 hdfs hadoop    246.6 M 2013-12-03 13:07 /tmp/carl/2013-07-12/000059_0</div><div class="line"></div><div class="line"> -rw-r&amp;#8211;r&amp;#8211;   3 hdfs hadoop    244.9 M 2013-12-03 13:11 /tmp/carl/2013-07-12/000124_0</div><div class="line"></div><div class="line"> -rw-r&amp;#8211;r&amp;#8211;   3 hdfs hadoop    244.9 M 2013-12-03 13:15 /tmp/carl/2013-07-12/000126_0</div><div class="line"></div><div class="line"> -rw-r&amp;#8211;r&amp;#8211;   3 hdfs hadoop     85.2 M 2013-12-03 13:17 /tmp/carl/2013-07-12/000218_0</div><div class="line"></div><div class="line">shell&amp;gt; hadoop jar hadoop-mapreduce-examples-2.0.0-cdh4.4.0.jar multifilewc /tmp/carl/2013-07-12/ /tmp/carl/c8/</div><div class="line"></div><div class="line"> &amp;#8230;</div><div class="line"></div><div class="line"> 13/12/24 19:31:23 INFO input.FileInputFormat: Total input paths to process : 4</div><div class="line"></div><div class="line"> 13/12/24 19:31:23 INFO mapreduce.JobSubmitter: number of splits:1</div><div class="line"></div><div class="line"> &amp;#8230;</div><div class="line"></div><div class="line"> Job Counters</div><div class="line"></div><div class="line"> Killed reduce tasks=1</div><div class="line"></div><div class="line"> Launched map tasks=1</div><div class="line"></div><div class="line"> Launched reduce tasks=17</div><div class="line"></div><div class="line"> Other local map tasks=1</div><div class="line"></div><div class="line"> Total time spent by all maps in occupied slots (ms)=37923</div><div class="line"></div><div class="line"> Total time spent by all reduces in occupied slots (ms)=1392681</div><div class="line"></div><div class="line"> ...</div></pre></td></tr></table></figure></p>
<p>因为MultiFileWordCount没有设置maxSplitSize，所以这里只有一个分片。</p>
<h2 id="4-CombineInputFormat应用"><a href="#4-CombineInputFormat应用" class="headerlink" title="4.CombineInputFormat应用"></a>4.CombineInputFormat应用</h2><h3 id="4-1-使用场景"><a href="#4-1-使用场景" class="headerlink" title="4.1.使用场景"></a>4.1.使用场景</h3><p>CombineInputFormat处理少量，较大的文件没有优势，相反，如果没有合理的设置maxSplitSize，minSizeNode，minSizeRack，则可能会导致一个map任务需要大量访问非本地的Block造成网络开销，反而比正常的非合并方式更慢。</p>
<p>而针对大量远小于块大小的小文件处理，CombineInputFormat的使用还是很有优势。</p>
<h3 id="4-2-测试"><a href="#4-2-测试" class="headerlink" title="4.2.测试"></a>4.2.测试</h3><p>我们以hadoop的示例程序WordCount和MulitFileWordCount来处理1000个小文件为例进行对比。</p>
<p>生成小文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div></pre></td><td class="code"><pre><div class="line">shell&amp;gt; cat file_gen.sh</div><div class="line"></div><div class="line"> #!/bin/sh</div><div class="line"></div><div class="line"> for i in $(seq 1000)</div><div class="line"></div><div class="line"> do</div><div class="line"></div><div class="line"> echo &amp;#8220;abc asdf as df asd f sadf  werweiro &amp;#8220;$i &amp;gt; file_$&#123;i&#125;</div><div class="line"></div><div class="line"> done</div><div class="line"></div><div class="line"> shell&amp;gt; ./file_gen.sh</div><div class="line"></div><div class="line"> shell&amp;gt; ls -lh</div><div class="line"></div><div class="line"> &amp;#8230;</div><div class="line"></div><div class="line"> -rw-r&amp;#8211;r&amp;#8211; 1 root root 40 Dec 25 10:14 file_962</div><div class="line"></div><div class="line"> -rw-r&amp;#8211;r&amp;#8211; 1 root root 40 Dec 25 10:14 file_963</div><div class="line"></div><div class="line"> -rw-r&amp;#8211;r&amp;#8211; 1 root root 40 Dec 25 10:14 file_964</div><div class="line"></div><div class="line"> -rw-r&amp;#8211;r&amp;#8211; 1 root root 40 Dec 25 10:14 file_965</div><div class="line"></div><div class="line"> -rw-r&amp;#8211;r&amp;#8211; 1 root root 40 Dec 25 10:14 file_966</div><div class="line"></div><div class="line"> -rw-r&amp;#8211;r&amp;#8211; 1 root root 40 Dec 25 10:14 file_967</div><div class="line"></div><div class="line"> &amp;#8230;</div><div class="line"></div><div class="line">上面生成大量小文件，上传这些小文件：</div><div class="line"></div><div class="line">shell&amp;gt; hadoop fs -put file* /tmp/carl2/</div><div class="line"></div><div class="line">**wordcount**使用TextInputFormat方式，小文件一个个处理：</div><div class="line"></div><div class="line">shell&amp;gt; hadoop jar hadoop-mapreduce-examples-2.0.0-cdh4.4.0.jar wordcount /tmp/carl2/ /tmp/carl_result3/</div><div class="line"></div><div class="line"> &amp;#8230;</div><div class="line"></div><div class="line"> 13/12/25 10:34:25 INFO input.FileInputFormat: Total input paths to process : 1000</div><div class="line"></div><div class="line"> 13/12/25 10:34:27 INFO mapreduce.JobSubmitter: number of splits:1000</div><div class="line"></div><div class="line"> &amp;#8230;</div><div class="line"></div><div class="line"> 13/12/25 10:34:33 INFO mapreduce.Job:  map 0% reduce 0%</div><div class="line"></div><div class="line"> 13/12/25 10:34:40 INFO mapreduce.Job:  map 1% reduce 0%</div><div class="line"></div><div class="line"> 13/12/25 10:34:41 INFO mapreduce.Job:  map 2% reduce 0%</div><div class="line"></div><div class="line"> &amp;#8230;</div><div class="line"></div><div class="line"> 13/12/25 10:40:56 INFO mapreduce.Job:  map 100% reduce 94%</div><div class="line"></div><div class="line"> 13/12/25 10:40:57 INFO mapreduce.Job:  map 100% reduce 100%</div><div class="line"></div><div class="line"> &amp;#8230;</div><div class="line"></div><div class="line">可以看到，生成了1000个map任务，总耗时超过6分钟!</div><div class="line"></div><div class="line">**multifilewc**使用CombineInputFormat方式，没有设置maxSplitSize的情况下，所有小文件会汇总成一个Split。</div><div class="line"></div><div class="line">shell&amp;gt; hadoop jar hadoop-mapreduce-examples-2.0.0-cdh4.4.0.jar multifilewc /tmp/carl2/ /tmp/carl_result4/</div><div class="line"></div><div class="line"> &amp;#8230;</div><div class="line"></div><div class="line"> 13/12/25 10:42:04 INFO input.FileInputFormat: Total input paths to process : 1000</div><div class="line"></div><div class="line"> 13/12/25 10:42:07 INFO mapreduce.JobSubmitter: number of splits:1</div><div class="line"></div><div class="line"> &amp;#8230;</div><div class="line"></div><div class="line"> 13/12/25 10:42:12 INFO mapreduce.Job:  map 0% reduce 0%</div><div class="line"></div><div class="line"> 13/12/25 10:42:19 INFO mapreduce.Job:  map 100% reduce 0%</div><div class="line"></div><div class="line"> 13/12/25 10:42:24 INFO mapreduce.Job:  map 100% reduce 25%</div><div class="line"></div><div class="line"> 13/12/25 10:42:25 INFO mapreduce.Job:  map 100% reduce 31%</div><div class="line"></div><div class="line"> 13/12/25 10:42:27 INFO mapreduce.Job:  map 100% reduce 38%</div><div class="line"></div><div class="line"> 13/12/25 10:42:28 INFO mapreduce.Job:  map 100% reduce 56%</div><div class="line"></div><div class="line"> 13/12/25 10:42:29 INFO mapreduce.Job:  map 100% reduce 63%</div><div class="line"></div><div class="line"> 13/12/25 10:42:30 INFO mapreduce.Job:  map 100% reduce 69%</div><div class="line"></div><div class="line"> 13/12/25 10:42:31 INFO mapreduce.Job:  map 100% reduce 81%</div><div class="line"></div><div class="line"> 13/12/25 10:42:32 INFO mapreduce.Job:  map 100% reduce 88%</div><div class="line"></div><div class="line"> 13/12/25 10:42:33 INFO mapreduce.Job:  map 100% reduce 100%</div></pre></td></tr></table></figure></p>
<p>可以看到，只用一个map任务进行处理，大量小文件可以使用网络迅速的汇总，总耗时不到30秒！</p>
<p>测试的结果可以大致看出，针对大量小文件，使用CombineInputFormat具有较大优势。</p>
<p>参考：</p>
<p><a href="http://stackoverflow.com/questions/14541759/how-can-i-work-with-large-number-of-small-files-in-hadoop" target="_blank" rel="external">http://stackoverflow.com/questions/14541759/how-can-i-work-with-large-number-of-small-files-in-hadoop</a></p>
]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MapReduce </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Java获取与当天相差几天的日期两种方式]]></title>
      <url>http://yoursite.com/2016/12/09/Java%E8%8E%B7%E5%8F%96%E4%B8%8E%E5%BD%93%E5%A4%A9%E7%9B%B8%E5%B7%AE%E5%87%A0%E5%A4%A9%E7%9A%84%E6%97%A5%E6%9C%9F%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F/</url>
      <content type="html"><![CDATA[<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">Date date=new Date();//取时间  </div><div class="line">Calendar calendar = new GregorianCalendar();  </div><div class="line">calendar.setTime(date);  </div><div class="line">calendar.add(calendar.DATE,1);//把日期往后增加一天.整数往后推,负数往前移动  </div><div class="line">date=calendar.getTime(); //这个时间就是日期往后推一天的结果   </div><div class="line">SimpleDateFormat formatter = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;);  </div><div class="line">String dateString = formatter.format(date);  </div><div class="line">System.out.println(dateString);</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">/** </div><div class="line">     *获取两日期之间天数 </div><div class="line">     */  </div><div class="line">    public String getDate(Date d,long i)&#123;  </div><div class="line">         SimpleDateFormat df=new SimpleDateFormat(&quot;yyyy-MM-dd&quot;);     </div><div class="line">         /*System.out.println(&quot;今天的日期：&quot;+df.format(d));    </div><div class="line">         System.out.println(&quot;两天前的日期：&quot; + df.format(new Date(d.getTime() - 2 * 24 * 60 * 60 * 1000)));   </div><div class="line">         System.out.println(&quot;三天后的日期：&quot; + df.format(new Date(d.getTime() + 3 * 24 * 60 * 60 * 1000)));*/  </div><div class="line">         return df.format(new Date(d.getTime() + i * 24 * 60 * 60 * 1000));  </div><div class="line">    &#125;</div></pre></td></tr></table></figure>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Log4j配置]]></title>
      <url>http://yoursite.com/2016/12/09/Log4j%E9%85%8D%E7%BD%AE/</url>
      <content type="html"><![CDATA[<ul>
<li><p>加入log4j-1.2.8.jar到lib下。</p>
</li>
<li><p>在CLASSPATH下建立log4j.properties。</p>
</li>
<li><p>在bin目录下加入  log4j.properties</p>
</li>
</ul>
<a id="more"></a>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">#①配置根Logger，其语法为： </div><div class="line"># </div><div class="line">#log4j.rootLogger = [level],appenderName,appenderName2,... </div><div class="line">#level是日志记录的优先级，分为OFF,TRACE,DEBUG,INFO,WARN,ERROR,FATAL,ALL </div><div class="line">##Log4j建议只使用四个级别，优先级从低到高分别是DEBUG,INFO,WARN,ERROR </div><div class="line">#通过在这里定义的级别，您可以控制到应用程序中相应级别的日志信息的开关 </div><div class="line">#比如在这里定义了INFO级别，则应用程序中所有DEBUG级别的日志信息将不被打印出来 </div><div class="line">#appenderName就是指定日志信息输出到哪个地方。可同时指定多个输出目的 </div><div class="line">################################################################################ </div><div class="line">################################################################################ </div><div class="line">#②配置日志信息输出目的地Appender，其语法为： </div><div class="line"># </div><div class="line">#log4j.appender.appenderName = fully.qualified.name.of.appender.class </div><div class="line">#log4j.appender.appenderName.optionN = valueN </div><div class="line"># </div><div class="line">#Log4j提供的appender有以下几种： </div><div class="line">#1)org.apache.log4j.ConsoleAppender(输出到控制台) </div><div class="line">#2)org.apache.log4j.FileAppender(输出到文件) </div><div class="line">#3)org.apache.log4j.DailyRollingFileAppender(每天产生一个日志文件) </div><div class="line">#4)org.apache.log4j.RollingFileAppender(文件大小到达指定尺寸的时候产生一个新的文件) </div><div class="line">#5)org.apache.log4j.WriterAppender(将日志信息以流格式发送到任意指定的地方) </div><div class="line"># </div><div class="line">#1)ConsoleAppender选项属性 </div><div class="line"># -Threshold = DEBUG:指定日志消息的输出最低层次 </div><div class="line"># -ImmediateFlush = TRUE:默认值是true,所有的消息都会被立即输出 </div><div class="line"># -Target = System.err:默认值System.out,输出到控制台(err为红色,out为黑色) </div><div class="line"># </div><div class="line">#2)FileAppender选项属性 </div><div class="line"># -Threshold = INFO:指定日志消息的输出最低层次 </div><div class="line"># -ImmediateFlush = TRUE:默认值是true,所有的消息都会被立即输出 </div><div class="line"># -File = C:\log4j.log:指定消息输出到C:\log4j.log文件 </div><div class="line"># -Append = FALSE:默认值true,将消息追加到指定文件中，false指将消息覆盖指定的文件内容 </div><div class="line"># -Encoding = UTF-8:可以指定文件编码格式 </div><div class="line"># </div><div class="line">#3)DailyRollingFileAppender选项属性 </div><div class="line"># -Threshold = WARN:指定日志消息的输出最低层次 </div><div class="line"># -ImmediateFlush = TRUE:默认值是true,所有的消息都会被立即输出 </div><div class="line"># -File = C:\log4j.log:指定消息输出到C:\log4j.log文件 </div><div class="line"># -Append = FALSE:默认值true,将消息追加到指定文件中，false指将消息覆盖指定的文件内容 </div><div class="line"># -DatePattern=&apos;.&apos;yyyy-ww:每周滚动一次文件,即每周产生一个新的文件。还可以按用以下参数: </div><div class="line">#              &apos;.&apos;yyyy-MM:每月 </div><div class="line">#              &apos;.&apos;yyyy-ww:每周 </div><div class="line">#              &apos;.&apos;yyyy-MM-dd:每天 </div><div class="line">#              &apos;.&apos;yyyy-MM-dd-a:每天两次 </div><div class="line">#              &apos;.&apos;yyyy-MM-dd-HH:每小时 </div><div class="line">#              &apos;.&apos;yyyy-MM-dd-HH-mm:每分钟 </div><div class="line"># -Encoding = UTF-8:可以指定文件编码格式 </div><div class="line"># </div><div class="line">#4)RollingFileAppender选项属性 </div><div class="line"># -Threshold = ERROR:指定日志消息的输出最低层次 </div><div class="line"># -ImmediateFlush = TRUE:默认值是true,所有的消息都会被立即输出 </div><div class="line"># -File = C:/log4j.log:指定消息输出到C:/log4j.log文件 </div><div class="line"># -Append = FALSE:默认值true,将消息追加到指定文件中，false指将消息覆盖指定的文件内容 </div><div class="line"># -MaxFileSize = 100KB:后缀可以是KB,MB,GB.在日志文件到达该大小时,将会自动滚动.如:log4j.log.1 </div><div class="line"># -MaxBackupIndex = 2:指定可以产生的滚动文件的最大数 </div><div class="line"># -Encoding = UTF-8:可以指定文件编码格式 </div><div class="line">################################################################################ </div><div class="line">################################################################################ </div><div class="line">#③配置日志信息的格式(布局)，其语法为： </div><div class="line"># </div><div class="line">#log4j.appender.appenderName.layout = fully.qualified.name.of.layout.class </div><div class="line">#log4j.appender.appenderName.layout.optionN = valueN </div><div class="line"># </div><div class="line">#Log4j提供的layout有以下几种： </div><div class="line">#5)org.apache.log4j.HTMLLayout(以HTML表格形式布局) </div><div class="line">#6)org.apache.log4j.PatternLayout(可以灵活地指定布局模式) </div><div class="line">#7)org.apache.log4j.SimpleLayout(包含日志信息的级别和信息字符串) </div><div class="line">#8)org.apache.log4j.TTCCLayout(包含日志产生的时间、线程、类别等等信息) </div><div class="line">#9)org.apache.log4j.xml.XMLLayout(以XML形式布局) </div><div class="line"># </div><div class="line">#5)HTMLLayout选项属性 </div><div class="line"># -LocationInfo = TRUE:默认值false,输出java文件名称和行号 </div><div class="line"># -Title=Struts Log Message:默认值 Log4J Log Messages </div><div class="line"># </div><div class="line">#6)PatternLayout选项属性 </div><div class="line"># -ConversionPattern = %m%n:格式化指定的消息(参数意思下面有) </div><div class="line"># </div><div class="line">#9)XMLLayout选项属性 </div><div class="line"># -LocationInfo = TRUE:默认值false,输出java文件名称和行号 </div><div class="line"># </div><div class="line">#Log4J采用类似C语言中的printf函数的打印格式格式化日志信息，打印参数如下： </div><div class="line"># %m 输出代码中指定的消息 </div><div class="line"># %p 输出优先级，即DEBUG,INFO,WARN,ERROR,FATAL </div><div class="line"># %r 输出自应用启动到输出该log信息耗费的毫秒数 </div><div class="line"># %c 输出所属的类目,通常就是所在类的全名 </div><div class="line"># %t 输出产生该日志事件的线程名 </div><div class="line"># %n 输出一个回车换行符，Windows平台为“\r\n”，Unix平台为“\n” </div><div class="line"># %d 输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式 </div><div class="line">#    如：%d&#123;yyyy年MM月dd日 HH:mm:ss,SSS&#125;，输出类似：2012年01月05日 22:10:28,921 </div><div class="line"># %l 输出日志事件的发生位置，包括类目名、发生的线程，以及在代码中的行数 </div><div class="line">#    如：Testlog.main(TestLog.java:10) </div><div class="line"># %F 输出日志消息产生时所在的文件名称 </div><div class="line"># %L 输出代码中的行号 </div><div class="line"># %x 输出和当前线程相关联的NDC(嵌套诊断环境),像java servlets多客户多线程的应用中 </div><div class="line"># %% 输出一个&quot;%&quot;字符 </div><div class="line"># </div><div class="line"># 可以在%与模式字符之间加上修饰符来控制其最小宽度、最大宽度、和文本的对齐方式。如： </div><div class="line">#  %5c: 输出category名称，最小宽度是5，category&lt;5，默认的情况下右对齐 </div><div class="line">#  %-5c:输出category名称，最小宽度是5，category&lt;5，&quot;-&quot;号指定左对齐,会有空格 </div><div class="line">#  %.5c:输出category名称，最大宽度是5，category&gt;5，就会将左边多出的字符截掉，&lt;5不会有空格 </div><div class="line">#  %20.30c:category名称&lt;20补空格，并且右对齐，&gt;30字符，就从左边交远销出的字符截掉 </div><div class="line">################################################################################ </div><div class="line">################################################################################ </div><div class="line">#④指定特定包的输出特定的级别 </div><div class="line">#log4j.logger.org.springframework=DEBUG </div><div class="line">################################################################################ </div><div class="line"></div><div class="line">#OFF,systemOut,logFile,logDailyFile,logRollingFile,logMail,logDB,ALL </div><div class="line">log4j.rootLogger =ALL,systemOut,logFile,logDailyFile,logRollingFile,logMail,logDB </div><div class="line"></div><div class="line">#输出到控制台 </div><div class="line">log4j.appender.systemOut = org.apache.log4j.ConsoleAppender </div><div class="line">log4j.appender.systemOut.layout = org.apache.log4j.PatternLayout </div><div class="line">log4j.appender.systemOut.layout.ConversionPattern = [%-5p][%-22d&#123;yyyy/MM/dd HH:mm:ssS&#125;][%l]%n%m%n </div><div class="line">log4j.appender.systemOut.Threshold = DEBUG </div><div class="line">log4j.appender.systemOut.ImmediateFlush = TRUE </div><div class="line">log4j.appender.systemOut.Target = System.out </div><div class="line"></div><div class="line">#输出到文件 </div><div class="line">log4j.appender.logFile = org.apache.log4j.FileAppender </div><div class="line">log4j.appender.logFile.layout = org.apache.log4j.PatternLayout </div><div class="line">log4j.appender.logFile.layout.ConversionPattern = [%-5p][%-22d&#123;yyyy/MM/dd HH:mm:ssS&#125;][%l]%n%m%n </div><div class="line">log4j.appender.logFile.Threshold = DEBUG </div><div class="line">log4j.appender.logFile.ImmediateFlush = TRUE </div><div class="line">log4j.appender.logFile.Append = TRUE </div><div class="line">log4j.appender.logFile.File = ../Struts2/WebRoot/log/File/log4j_Struts.log </div><div class="line">log4j.appender.logFile.Encoding = UTF-8 </div><div class="line"></div><div class="line">#按DatePattern输出到文件 </div><div class="line">log4j.appender.logDailyFile = org.apache.log4j.DailyRollingFileAppender </div><div class="line">log4j.appender.logDailyFile.layout = org.apache.log4j.PatternLayout </div><div class="line">log4j.appender.logDailyFile.layout.ConversionPattern = [%-5p][%-22d&#123;yyyy/MM/dd HH:mm:ssS&#125;][%l]%n%m%n </div><div class="line">log4j.appender.logDailyFile.Threshold = DEBUG </div><div class="line">log4j.appender.logDailyFile.ImmediateFlush = TRUE </div><div class="line">log4j.appender.logDailyFile.Append = TRUE </div><div class="line">log4j.appender.logDailyFile.File = ../Struts2/WebRoot/log/DailyFile/log4j_Struts </div><div class="line">log4j.appender.logDailyFile.DatePattern = &apos;.&apos;yyyy-MM-dd-HH-mm&apos;.log&apos; </div><div class="line">log4j.appender.logDailyFile.Encoding = UTF-8 </div><div class="line"></div><div class="line">#设定文件大小输出到文件 </div><div class="line">log4j.appender.logRollingFile = org.apache.log4j.RollingFileAppender </div><div class="line">log4j.appender.logRollingFile.layout = org.apache.log4j.PatternLayout </div><div class="line">log4j.appender.logRollingFile.layout.ConversionPattern = [%-5p][%-22d&#123;yyyy/MM/dd HH:mm:ssS&#125;][%l]%n%m%n </div><div class="line">log4j.appender.logRollingFile.Threshold = DEBUG </div><div class="line">log4j.appender.logRollingFile.ImmediateFlush = TRUE </div><div class="line">log4j.appender.logRollingFile.Append = TRUE </div><div class="line">log4j.appender.logRollingFile.File = ../Struts2/WebRoot/log/RollingFile/log4j_Struts.log </div><div class="line">log4j.appender.logRollingFile.MaxFileSize = 1MB </div><div class="line">log4j.appender.logRollingFile.MaxBackupIndex = 10 </div><div class="line">log4j.appender.logRollingFile.Encoding = UTF-8 </div><div class="line"></div><div class="line">#用Email发送日志 </div><div class="line">log4j.appender.logMail = org.apache.log4j.net.SMTPAppender </div><div class="line">log4j.appender.logMail.layout = org.apache.log4j.HTMLLayout </div><div class="line">log4j.appender.logMail.layout.LocationInfo = TRUE </div><div class="line">log4j.appender.logMail.layout.Title = Struts2 Mail LogFile </div><div class="line">log4j.appender.logMail.Threshold = DEBUG </div><div class="line">log4j.appender.logMail.SMTPDebug = FALSE </div><div class="line">log4j.appender.logMail.SMTPHost = SMTP.163.com </div><div class="line">log4j.appender.logMail.From = xly3000@163.com </div><div class="line">log4j.appender.logMail.To = xly3000@gmail.com </div><div class="line">#log4j.appender.logMail.Cc = xly3000@gmail.com </div><div class="line">#log4j.appender.logMail.Bcc = xly3000@gmail.com </div><div class="line">log4j.appender.logMail.SMTPUsername = xly3000 </div><div class="line">log4j.appender.logMail.SMTPPassword = 1234567 </div><div class="line">log4j.appender.logMail.Subject = Log4j Log Messages </div><div class="line">#log4j.appender.logMail.BufferSize = 1024 </div><div class="line">#log4j.appender.logMail.SMTPAuth = TRUE </div><div class="line"></div><div class="line">#将日志登录到MySQL数据库 </div><div class="line">log4j.appender.logDB = org.apache.log4j.jdbc.JDBCAppender </div><div class="line">log4j.appender.logDB.layout = org.apache.log4j.PatternLayout </div><div class="line">log4j.appender.logDB.Driver = com.mysql.jdbc.Driver </div><div class="line">log4j.appender.logDB.URL = jdbc:mysql://127.0.0.1:3306/xly </div><div class="line">log4j.appender.logDB.User = root </div><div class="line">log4j.appender.logDB.Password = 123456 </div><div class="line">log4j.appender.logDB.Sql = INSERT INTOT_log4j(project_name,create_date,level,category,file_name,thread_name,line,all_category,message)values(&apos;Struts2&apos;,&apos;%d&#123;yyyy-MM-ddHH:mm:ss&#125;&apos;,&apos;%p&apos;,&apos;%c&apos;,&apos;%F&apos;,&apos;%t&apos;,&apos;%L&apos;,&apos;%l&apos;,&apos;%m&apos;)</div></pre></td></tr></table></figure>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[mapreduce调优]]></title>
      <url>http://yoursite.com/2016/12/02/mapreduce%E8%B0%83%E4%BC%98/</url>
      <content type="html"><![CDATA[<h2 id="对应用程序进行调优"><a href="#对应用程序进行调优" class="headerlink" title="对应用程序进行调优"></a>对应用程序进行调优</h2><ol>
<li><p>避免输入大量小文件。大量的小文件(不足一个block大小)作为输入数据会产生很多的Map任务(默认一个分片对应一个Map任务)，而每个Map任务实际工作量又非常小，系统要花更多的时间来将这些Map任务的输出进行整合。如果将大量的小文件进行预处理合并成一个或几个大文件，任务执行的效率可能会提升几十倍。可手动将小文件合并成大文件，或通过Hadoop的SequenceFile、CombineFileInputFormat将多个文件打包到一个输入单元中，使得每个Map处理更多的数据，从而提高性能。</p>
</li>
<li><p>输入文件size巨大，但不是小文件。这种情况可以通过增大每个mapper的input size，即增大minSize或者增大blockSize来减少所需的mapper的数量。增大blockSize通常不可行，因为当HDFS被hadoop namenode -format之后，blockSize就已经确定了（由格式化时dfs.block.size决定），如果要更改blockSize，需要重新格式化HDFS，这样当然会丢失已有的数据。所以通常情况下只能通过增大minSize，即增大mapred.min.split.size的值。</p>
<a id="more"></a></li>
<li><p>预判并过滤无用数据。可以使用一些过滤工具，在作业执行之前将数据中无用的数据进行过滤，可极大提高MapReduce执行效率。Bloom Filter是一种功能强大的过滤器，执行效率高，时间复杂度为O(1)，缺点是存在一定的误判可能，详细参考《Bloom Filter概念和原理》。当将一个非常大的表和一个非常小的表进行表连接操作时，可以使用Bloom Filter将小表数据作为Bloom Filter的输入数据，将大表的原始数据进行过滤(过滤不通过的数据一定是不可用的，过滤通过的数据可能有用可能无用)，可提高程序执行的效率。</p>
</li>
<li><p>合理使用分布式缓存DistributedCache。DistributedCache可以将一些字典、jar包、配置文件等缓存到需要执行map任务的节点中，避免map任务多次重复读取这些资源，尤其在join操作时，使用DistributedCache缓存小表数据在map端进行join操作，可避免shuffle、reduce等操作，提高程序运行效率。</p>
</li>
<li><p>重用Writable类型。避免大量多次new这些Writable对象，这会花费java垃圾收集器大量的清理工作，建议在map函数外定义这些Writable对象，如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">class MyMapper … &#123;</div><div class="line">    Text wordText = new Text();</div><div class="line">    IntWritable one = new IntWritable(1);</div><div class="line">    public void map(...) &#123;</div><div class="line">        for (String word: words) &#123;</div><div class="line">            wordText.set(word);</div><div class="line">            context.write(wordText, one);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
<li><p>合理设置Combiner。Combine阶段处于Map端操作的最后一步，设置Combine操作可大大提高MapReduce的执行效率，前提是增加Combine不能改变最终的结果值，换句话说，不是所有的MapReduce程序都能添加Combine，如求平均数的MapReduce程序就不适合设置Combine操作。通常Combine函数与Reduce函数一致</p>
</li>
</ol>
<h2 id="对参数进行调优（基于hadoop2-6-0）"><a href="#对参数进行调优（基于hadoop2-6-0）" class="headerlink" title="对参数进行调优（基于hadoop2.6.0）"></a>对参数进行调优（基于hadoop2.6.0）</h2><p><strong>HDFS参数调优(hdfs-site.xml)</strong></p>
<ul>
<li><p>dfs.namenode.handler.count：namenode用于处理RPC的线程数，默认值10，可根据NameNode所在节点机器配置适当调大，如32、64；</p>
</li>
<li><p>dfs.datanode.handler.count：datanode上用于处理RPC的线程数，2.6版本默认值10，早期1.x版本默认值为3，可根据datanode节点的配置适当调整；</p>
</li>
</ul>
<p><strong>MapReduce参数调优(mapred-site.xml)</strong></p>
<ul>
<li><p>mapreduce.tasktracker.map.tasks.maximum：每个nodemanager节点上可运行的最大map任务数，默认值2，可根据实际值调整为10~100；</p>
</li>
<li><p>mapreduce.tasktracker.reduce.tasks.maximum：每个nodemanager节点上可运行的最大reduce任务数，默认值2，可根据实际值调整为10~100；</p>
</li>
<li><p>mapreduce.output.fileoutputformat.compress：是否对任务输出产生的结果进行压缩，默认值false。对传输数据进行压缩，既可以减少文件的存储空间，又可以加快数据在网络不同节点之间的传输速度。</p>
</li>
<li><p>mapreduce.output.fileoutputformat.compress.type：输出产生任务数据的压缩方式，默认值RECORD，可配置值有：NONE、RECORD、BLOCK</p>
</li>
<li><p>mapreduce.map.output.compress：map端压缩</p>
</li>
<li><p>mapreduce.map.output.compress.codec：map压缩格式</p>
</li>
<li><p>mapreduce.task.io.sort.mb：map任务输出结果的内存环形缓冲区大小，默认值100M，可根据map节点的机器进行配置，貌似不能超过值mapred.child.java.opts；</p>
</li>
<li><p>mapreduce.map.sort.spill.percent：map任务输出环形缓冲区大小溢写触发最大比例，默认值80%，这个值一般不建议修改；</p>
</li>
<li><p>mapreduce.reduce.shuffle.parallelcopies：reduce节点通过http拷贝map输出结果数据到本地的最大工作线程数，默认值5，可根据节点机器配置适当修改；</p>
</li>
<li><p>mapreduce.reduce.shuffle.input.buffer.percent：reduce节点在shuffle阶段拷贝map输出结果数据到本地时，内存缓冲区大小所占JVM内存的比例，默认值0.7，一般不建议修改；</p>
</li>
<li><p>mapreduce.reduce.shuffle.merge.percent：reduce节点shuffle内存缓冲区溢写触发最大比例，默认值0.66，一般不建议修改；</p>
</li>
<li><p>mapred.child.java.opts：配置每个map或reduce使用的内存数量，默认值-Xmx200m，即200M。如果nodemanager所在节点</p>
</li>
</ul>
<h2 id="Map和Reduce个数设置"><a href="#Map和Reduce个数设置" class="headerlink" title="Map和Reduce个数设置"></a>Map和Reduce个数设置</h2><ol>
<li><p>map的数量<br>map的数量通常是由hadoop集群的DFS块大小确定的，也就是输入文件的总块数，正常的map数量的并行规模大致是每一个Node是10~100个，对于CPU消耗较小的作业可以设置Map数量为300个左右，但是由于hadoop的没一个任务在初始化时需要一定的时间，因此比较合理的情况是每个map执行的时间至少超过1分钟。具体的数据分片是这样的，InputFormat在默认情况下会根据hadoop集群的DFS块大小进行分片，每一个分片会由一个map任务来进行处理，当然用户还是可以通过参数mapred.min.split.size参数在作业提交客户端进行自定义设置。还有一个重要参数就是mapred.map.tasks，这个参数设置的map数量仅仅是一个提示，只有当InputFormat 决定了map任务的个数比mapred.map.tasks值小时才起作用。同样，Map任务的个数也能通过使用JobConf 的conf.setNumMapTasks(int num)方法来手动地设置。这个方法能够用来增加map任务的个数，但是不能设定任务的个数小于Hadoop系统通过分割输入数据得到的值。因此，如果你有一个大小是10TB的输入数据，并设置DFS块大小为 128M，你必须设置至少82K个map任务，除非你设置的mapred.map.tasks参数比这个数还要大。当然为了提高集群的并发效率，可以设置一个默认的map数量，当用户的map数量较小或者比本身自动分割的值还小时可以使用一个相对交大的默认值，从而提高整体hadoop集群的效率。</p>
</li>
<li><p>reduece的数量<br>reduce在运行时往往需要从相关map端复制数据到reduce节点来处理，因此相比于map任务。reduce节点资源是相对比较缺少的，同时相对运行较慢，正确的reduce任务的个数应该是0.95或者1.75 *（节点数 ×mapred.tasktracker.tasks.maximum参数值）。mapred.tasktracker.tasks.reduce.maximum的数量一般设置为各节点cpu core数量,或者数量减1，即能同时计算的slot数量。如果任务数是节点个数的0.95倍，那么所有的reduce任务能够在 map任务的输出传输结束后同时开始运行。如果任务数是节点个数的1.75倍，那么高速的节点会在完成他们第一批reduce任务计算之后开始计算第二批 reduce任务，这样的情况更有利于负载均衡。同时需要注意增加reduce的数量虽然会增加系统的资源开销，但是可以改善负载匀衡，降低任务失败带来的负面影响。同样，Reduce任务也能够与 map任务一样，通过设定JobConf 的conf.setNumReduceTasks(int num)方法来增加任务个数。<br>cpu数量 = 服务器CPU总核数 / 每个CPU的核数<br>服务器CPU总核数 = more /proc/cpuinfo | grep ‘processor’ | wc -l<br>每个CPU的核数 = more /proc/cpuinfo | grep ‘cpu cores’</p>
</li>
<li><p>reduce数量为0<br>有些作业不需要进行归约进行处理，那么就可以设置reduce的数量为0来进行处理，这种情况下用户的作业运行速度相对较高，map的输出会直接写入到 SetOutputPath(path)设置的输出目录，而不是作为中间结果写到本地。同时Hadoop框架在写入文件系统前并不对之进行排序。</p>
</li>
</ol>
<p>参考转载</p>
<blockquote>
<p><a href="http://www.cnblogs.com/hanganglin/p/4563716.html" target="_blank" rel="external">http://www.cnblogs.com/hanganglin/p/4563716.html</a><br><a href="https://my.oschina.net/Chanthon/blog/150500" target="_blank" rel="external">https://my.oschina.net/Chanthon/blog/150500</a></p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MapReduce </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Jena学习笔记（二） SPARQL]]></title>
      <url>http://yoursite.com/2016/11/29/Jena%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%20SPARQL/</url>
      <content type="html"><![CDATA[<blockquote>
<p>官方描述：Apache Jena（或简称Jena）是一个用于构建语义Web和关联数据应用程序的自由和开源的Java框架。 该框架由不同的API组成，用于处理RDF数据。</p>
<p>Jena是一个用于Java语义Web应用程序的API（应用程序编程接口）。它不是一个程序或工具，如果这是你正在寻找，我建议或许TopBraid Composer作为一个好的选择。因此，Jena的主要用途是帮助您编写处理RDF和OWL文档和描述的Java代码。</p>
<p>SPARQL是用于访问由W3C RDF数据访问工作组设计的RDF的查询语言和协议。</p>
<p>作为一种查询语言，SPARQL是“数据导向的”，因为它只查询模型中保存的信息;在查询语言本身没有推理。当然，Jena模型是“聪明的”，因为它提供了某些三元组存在的印象，即按需创建它们，包括OWL推理。除了以查询的形式获取应用程序想要的描述外，SPARQL不执行任何操作，并以一组bindings或RDF图形的形式返回该信息。</p>
</blockquote>
<p>官方网站：<a href="http://jena.apache.org/index.html" target="_blank" rel="external">http://jena.apache.org/index.html</a><br>SPARQL教程：<a href="http://jena.apache.org/tutorials/sparql.html" target="_blank" rel="external">http://jena.apache.org/tutorials/sparql.html</a></p>
<h2 id=""><a href="#" class="headerlink" title=""></a><a id="more"></a></h2><h3 id="设置环境变量"><a href="#设置环境变量" class="headerlink" title="设置环境变量"></a>设置环境变量</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">Setting up your Environment</div><div class="line">An environment variable JENAROOT is used by all the command line tools to configure the class path automatically for you. You can set this up as follows:</div><div class="line"></div><div class="line">On Linux / Mac</div><div class="line"></div><div class="line">export JENAROOT=the directory you downloaded Jena to</div><div class="line">export PATH=$PATH:$JENAROOT/bin</div><div class="line">On Windows</div><div class="line"></div><div class="line">SET JENAROOT=the directory you downloaded Jena to</div><div class="line">SET PATH=%PATH%;%JENAROOT%\bat</div></pre></td></tr></table></figure>
<h3 id="数据格式"><a href="#数据格式" class="headerlink" title="数据格式"></a>数据格式</h3><p>首先，我们需要清楚查询要查询的数据。 SPARQL查询RDF图。 RDF图是一组三元组（Jena调用RDF图“模型”和三元组“语句”，因为这是他们在第一次设计Jena API时调用的）。</p>
<p>重要的是要意识到三元组的重要性，而不是序列化。序列化只是一种写三元组的方式。 RDF / XML是W3C的建议，但是可能很难看到序列化形式的三元组，因为有多种方法来编码同一个图。在本教程中，我们使用了一个更像“三元组”的序列化，称为Turtle（另请参阅W3C语义网络引文中描述的N3语言）。</p>
<p>我们将从vc-db-1.rdf中的简单数据开始：此文件包含用于多个vCard人员描述的RDF。 vCard在RFC2426中描述，并且RDF翻译在W3C笔记“在RDF / XML中表示vCard对象”中描述。我们的示例数据库只包含一些名称信息。</p>
<p>图形上，数据看起来像：<br><img src="http://i.imgur.com/Nd0fFky.png" alt=""></p>
<p>在三元组中，如下所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">@prefix vCard:   &lt;http://www.w3.org/2001/vcard-rdf/3.0#&gt; .</div><div class="line">@prefix rdf:     &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt; .</div><div class="line">@prefix :        &lt;#&gt; .</div><div class="line"></div><div class="line">&lt;http://somewhere/MattJones/&gt;</div><div class="line">    vCard:FN    &quot;Matt Jones&quot; ;</div><div class="line">    vCard:N     [ vCard:Family</div><div class="line">                              &quot;Jones&quot; ;</div><div class="line">                  vCard:Given</div><div class="line">                              &quot;Matthew&quot;</div><div class="line">                ] .</div><div class="line"></div><div class="line">&lt;http://somewhere/RebeccaSmith/&gt;</div><div class="line">    vCard:FN    &quot;Becky Smith&quot; ;</div><div class="line">    vCard:N     [ vCard:Family</div><div class="line">                              &quot;Smith&quot; ;</div><div class="line">                  vCard:Given</div><div class="line">                              &quot;Rebecca&quot;</div><div class="line">                ] .</div><div class="line"></div><div class="line">&lt;http://somewhere/JohnSmith/&gt;</div><div class="line">    vCard:FN    &quot;John Smith&quot; ;</div><div class="line">    vCard:N     [ vCard:Family</div><div class="line">                              &quot;Smith&quot; ;</div><div class="line">                  vCard:Given</div><div class="line">                              &quot;John&quot;</div><div class="line">                ] .</div><div class="line"></div><div class="line">&lt;http://somewhere/SarahJones/&gt;</div><div class="line">    vCard:FN    &quot;Sarah Jones&quot; ;</div><div class="line">    vCard:N     [ vCard:Family</div><div class="line">                              &quot;Jones&quot; ;</div><div class="line">                  vCard:Given</div><div class="line">                              &quot;Sarah&quot;</div><div class="line">                ] .</div></pre></td></tr></table></figure></p>
<p>更加明确的：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">@prefix vCard:   &lt;http://www.w3.org/2001/vcard-rdf/3.0#&gt; .</div><div class="line">@prefix rdf:     &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt; .</div><div class="line"></div><div class="line">&lt;http://somewhere/MattJones/&gt;  vCard:FN   &quot;Matt Jones&quot; .</div><div class="line">&lt;http://somewhere/MattJones/&gt;  vCard:N    _:b0 .</div><div class="line">_:b0  vCard:Family &quot;Jones&quot; .</div><div class="line">_:b0  vCard:Given  &quot;Matthew&quot; .</div><div class="line"></div><div class="line"></div><div class="line">&lt;http://somewhere/RebeccaSmith/&gt; vCard:FN    &quot;Becky Smith&quot; .</div><div class="line">&lt;http://somewhere/RebeccaSmith/&gt; vCard:N     _:b1 .</div><div class="line">_:b1 vCard:Family &quot;Smith&quot; .</div><div class="line">_:b1 vCard:Given  &quot;Rebecca&quot; .</div><div class="line"></div><div class="line">&lt;http://somewhere/JohnSmith/&gt;    vCard:FN    &quot;John Smith&quot; .</div><div class="line">&lt;http://somewhere/JohnSmith/&gt;    vCard:N     _:b2 .</div><div class="line">_:b2 vCard:Family &quot;Smith&quot; .</div><div class="line">_:b2 vCard:Given  &quot;John&quot;  .</div><div class="line"></div><div class="line">&lt;http://somewhere/SarahJones/&gt;   vCard:FN    &quot;Sarah Jones&quot; .</div><div class="line">&lt;http://somewhere/SarahJones/&gt;   vCard:N     _:b3 .</div><div class="line">_:b3 vCard:Family  &quot;Jones&quot; .</div><div class="line">_:b3 vCard:Given   &quot;Sarah&quot; .</div></pre></td></tr></table></figure></p>
<p>重要的是要意识到这些是相同的RDF图，并且图中的三元组没有特定的顺序。计算机不在乎其顺序。</p>
<h3 id="第一个SPARQL查询"><a href="#第一个SPARQL查询" class="headerlink" title="第一个SPARQL查询"></a>第一个SPARQL查询</h3><p>看一个简单的查询并展示如何使用Jena执行它。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">SELECT ?x</div><div class="line">WHERE &#123; ?x  &lt;http://www.w3.org/2001/vcard-rdf/3.0#FN&gt;  &quot;John Smith&quot; &#125;</div></pre></td></tr></table></figure></p>
<p>用命令行查询应用程序执行所述查询:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">---------------------------------</div><div class="line">| x                             |</div><div class="line">=================================</div><div class="line">| &lt;http://somewhere/JohnSmith/&gt; |</div><div class="line">---------------------------------</div></pre></td></tr></table></figure></p>
<p>这通过将WHERE子句中的三元模式与RDF图中的三元组进行匹配来实现。三元组的谓词和对象是固定值，因此模式将只匹配与这些值的三元组。主体是一个变量，并且对变量没有其他限制。模式匹配任何三元组与这些谓词和对象值，它匹配x的结果。</p>
<p>&lt;&gt;中包含的项目是一个URI（实际上是一个IRI），而包含在“”中的项目是一个普通的字面量。就像Turtle，N3或N-triples一样，输入的文字用\ ^ \ ^编写，语言标签可以用@添加。</p>
<p>？x是一个称为x的变量。？不会形成名称的一部分，这就是为什么它不会出现在表的输出中。<br>该查询返回x查询变量中的匹配项。所示的输出是通过一条ARQ的命令获得的。</p>
<h4 id="执行查询"><a href="#执行查询" class="headerlink" title="执行查询"></a>执行查询</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">Windows setup</div><div class="line">Execute:</div><div class="line"></div><div class="line">bat\sparql.bat --data=doc\Tutorial\vc-db-1.rdf --query=doc\Tutorial\q1.rq</div><div class="line">You can just put the bat/ directory on your classpath or copy the programs out of it.</div><div class="line"></div><div class="line">bash scripts for Linux/Cygwin/Unix</div><div class="line">Execute:</div><div class="line"></div><div class="line">bin/sparql --data=doc/Tutorial/vc-db-1.rdf --query=doc/Tutorial/q1.rq</div></pre></td></tr></table></figure>
<p>在Linux中执行结果<br><img src="http://i.imgur.com/HvWk6xW.png" alt=""></p>
<h4 id="获取所有人的FullName"><a href="#获取所有人的FullName" class="headerlink" title="获取所有人的FullName"></a>获取所有人的FullName</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">SELECT ?x ?fname</div><div class="line">WHERE &#123;?x  &lt;http://www.w3.org/2001/vcard-rdf/3.0#FN&gt;  ?fname&#125;</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">//执行</div><div class="line">ubuntu@master:~/paper/doc$ sparql --data=vc-db-1.rdf --query=q-bp1.rq</div><div class="line">----------------------------------------------------</div><div class="line">| x                                | fname         |</div><div class="line">====================================================</div><div class="line">| &lt;http://somewhere/JohnSmith/&gt;    | &quot;John Smith&quot;  |</div><div class="line">| &lt;http://somewhere/SarahJones/&gt;   | &quot;Sarah Jones&quot; |</div><div class="line">| &lt;http://somewhere/MattJones/&gt;    | &quot;Matt Jones&quot;  |</div><div class="line">| &lt;http://somewhere/RebeccaSmith/&gt; | &quot;Becky Smith&quot; |</div><div class="line">----------------------------------------------------</div></pre></td></tr></table></figure>
<h4 id="指定前缀"><a href="#指定前缀" class="headerlink" title="指定前缀"></a>指定前缀</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">ubuntu@master:~/paper/doc$ cat q2.rq </div><div class="line">PREFIX vCard:      &lt;http://www.w3.org/2001/vcard-rdf/3.0#&gt;</div><div class="line"></div><div class="line">SELECT ?x</div><div class="line">WHERE</div><div class="line"> &#123; ?x vCard:FN &quot;John Smith&quot; &#125;</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">ubuntu@master:~/paper/doc$ sparql --data=vc-db-1.rdf --query=q2.rq</div><div class="line">---------------------------------</div><div class="line">| x                             |</div><div class="line">=================================</div><div class="line">| &lt;http://somewhere/JohnSmith/&gt; |</div><div class="line">---------------------------------</div></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> paper </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Jena </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Jena学习笔记（一） RDF]]></title>
      <url>http://yoursite.com/2016/11/26/Jena%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%20RDF/</url>
      <content type="html"><![CDATA[<blockquote>
<p>官方描述：Apache Jena（或简称Jena）是一个用于构建语义Web和关联数据应用程序的自由和开源的Java框架。 该框架由不同的API组成，用于处理RDF数据。</p>
<p>Jena是一个用于Java语义Web应用程序的API（应用程序编程接口）。它不是一个程序或工具，如果这是你正在寻找，我建议或许TopBraid Composer作为一个好的选择。因此，Jena的主要用途是帮助您编写处理RDF和OWL文档和描述的Java代码。</p>
</blockquote>
<p>官方网站：<a href="http://jena.apache.org/index.html" target="_blank" rel="external">http://jena.apache.org/index.html</a><br>RDF API教程：<a href="http://jena.apache.org/tutorials/rdf_api.html" target="_blank" rel="external">http://jena.apache.org/tutorials/rdf_api.html</a></p>
<hr>
<a id="more"></a>
<h3 id="RDF定义"><a href="#RDF定义" class="headerlink" title="RDF定义"></a>RDF定义</h3><p>资源描述框架（RDF）是最初设计为元数据数据模型的万维网联盟（W3C）规范[1]的家族。 它已经被用作用于概念描述或者在web资源中实现的信息的建模的一般方法，使用各种语法符号和数据串行化格式。 它也用于知识管理应用程序中。<br>RDF数据模型类似于诸如实体关系或类图的经典概念建模方法，因为它基于以主语谓词对象的形式对资源（特别是web资源）进行语句表。这些表达式在RDF术语中称为三元组。主语表示资源，谓词表示资源的特征或方面，并且表示主语和对象之间的关系。例如，在RDF中表示“天空具有蓝色”的概念的一种方式是作为三元组：表示“天空”的主题，表示“具有颜色”的谓词和表示“蓝色”的对象。因此，RDF将面向对象设计中的实体 - 属性 - 值模型的经典符号中使用的对象交换对象;实体（天空），属性（颜色）和值（蓝色）。 RDF是具有几种串行格式（即，文件格式）的抽象模型，因此资源或三元组被编码的特定方式随格式而变化。</p>
<h3 id="下载Jena并从Eclipse建立工程，导入jar"><a href="#下载Jena并从Eclipse建立工程，导入jar" class="headerlink" title="下载Jena并从Eclipse建立工程，导入jar"></a>下载Jena并从Eclipse建立工程，导入jar</h3><ul>
<li>RDF API 教程 <a href="http://jena.apache.org/tutorials/rdf_api.html" target="_blank" rel="external">http://jena.apache.org/tutorials/rdf_api.html</a></li>
</ul>
<h3 id="建立如下RDF图并打印"><a href="#建立如下RDF图并打印" class="headerlink" title="建立如下RDF图并打印"></a>建立如下RDF图并打印</h3><p><img src="http://i.imgur.com/m8ZtRNG.png" alt=""><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line">package com.hdu.rdf;</div><div class="line"></div><div class="line">import org.apache.jena.rdf.model.Model;</div><div class="line">import org.apache.jena.rdf.model.ModelFactory;</div><div class="line">import org.apache.jena.rdf.model.Property;</div><div class="line">import org.apache.jena.rdf.model.RDFNode;</div><div class="line">import org.apache.jena.rdf.model.Resource;</div><div class="line">import org.apache.jena.rdf.model.Statement;</div><div class="line">import org.apache.jena.rdf.model.StmtIterator;</div><div class="line">import org.apache.jena.vocabulary.VCARD;</div><div class="line"></div><div class="line">public class Tutorial2AddProperty &#123;</div><div class="line">	public static void main(String[] args) &#123;</div><div class="line">		// some definitions</div><div class="line">		String personURI = &quot;http://somewhere/JohnSmith&quot;;</div><div class="line">		String givenName = &quot;John&quot;;</div><div class="line">		String familyName = &quot;Smith&quot;;</div><div class="line">		String fullName = givenName + &quot; &quot; + familyName;</div><div class="line"></div><div class="line">		// create an empty model</div><div class="line">		Model model = ModelFactory.createDefaultModel();</div><div class="line"></div><div class="line">		// create the resource</div><div class="line">		// and add the properties cascading style</div><div class="line">		Resource johnSmith = model.createResource(personURI).addProperty(VCARD.FN, fullName).addProperty(VCARD.N,</div><div class="line">				model.createResource().addProperty(VCARD.Given, givenName).addProperty(VCARD.Family, familyName));</div><div class="line">		// model.write(System.out);</div><div class="line"></div><div class="line">		// list the statements in the graph</div><div class="line">		StmtIterator iter = model.listStatements();</div><div class="line">		// print out the predicate, subject and object of each statement</div><div class="line">		while (iter.hasNext()) &#123;</div><div class="line">			Statement stmt = iter.nextStatement();</div><div class="line">			Resource subject = stmt.getSubject(); // get the subject</div><div class="line">			Property predicate = stmt.getPredicate(); // get the predicate</div><div class="line">			RDFNode object = stmt.getObject(); // get the object</div><div class="line"></div><div class="line">			System.out.print(subject.toString());</div><div class="line">			System.out.print(&quot; &quot; + predicate.toString() + &quot; &quot;);</div><div class="line">			if (object instanceof Resource) &#123;</div><div class="line">				System.out.print(object.toString());</div><div class="line">			&#125; else &#123;</div><div class="line">				// object is a literal</div><div class="line">				System.out.print(&quot; \&quot;&quot; + object.toString() + &quot;\&quot;&quot;);</div><div class="line">			&#125;</div><div class="line"></div><div class="line">			System.out.println(&quot; .&quot;);</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>结果</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">//iterator遍历 每行包含三个字段，表示每个语句的主题，谓词和对象</div><div class="line">http://somewhere/JohnSmith http://www.w3.org/2001/vcard-rdf/3.0#N anon:14df86:ecc3dee17b:-7fff .</div><div class="line">anon:14df86:ecc3dee17b:-7fff http://www.w3.org/2001/vcard-rdf/3.0#Family  &quot;Smith&quot; .</div><div class="line">anon:14df86:ecc3dee17b:-7fff http://www.w3.org/2001/vcard-rdf/3.0#Given  &quot;John&quot; .</div><div class="line">http://somewhere/JohnSmith http://www.w3.org/2001/vcard-rdf/3.0#FN  &quot;John Smith&quot; .</div><div class="line"></div><div class="line">//write输出  xml格式</div><div class="line">&lt;rdf:RDF</div><div class="line">  xmlns:rdf=&apos;http://www.w3.org/1999/02/22-rdf-syntax-ns#&apos;</div><div class="line">  xmlns:vcard=&apos;http://www.w3.org/2001/vcard-rdf/3.0#&apos;</div><div class="line"> &gt;</div><div class="line">  &lt;rdf:Description rdf:about=&apos;http://somewhere/JohnSmith&apos;&gt;</div><div class="line">    &lt;vcard:FN&gt;John Smith&lt;/vcard:FN&gt;</div><div class="line">    &lt;vcard:N rdf:nodeID=&quot;A0&quot;/&gt;</div><div class="line">  &lt;/rdf:Description&gt;</div><div class="line">  &lt;rdf:Description rdf:nodeID=&quot;A0&quot;&gt;</div><div class="line">    &lt;vcard:Given&gt;John&lt;/vcard:Given&gt;</div><div class="line">    &lt;vcard:Family&gt;Smith&lt;/vcard:Family&gt;</div><div class="line">  &lt;/rdf:Description&gt;</div><div class="line">&lt;/rdf:RDF&gt;</div></pre></td></tr></table></figure></p>
<p><strong>说明</strong></p>
<p>他的RDF规范指定如何将RDF表示为XML。 RDF XML语法相当复杂。读者参考由RDFCore WG开发的引物以进行更详细的介绍。但是，让我们快速看看如何解释上面的。</p>
<p>RDF通常嵌入在<rdf：rdf>元素中。如果有其他方式知道某些XML是RDF，但是它通常存在，那么该元素是可选的。 RDF元素定义文档中使用的两个命名空间。然后是一个<rdf：description>元素，描述其URI为“http：// somewhere / JohnSmith”的资源。如果缺少rdf：about属性，则此元素将表示空白节点。</rdf：description></rdf：rdf></p>
<p><vcard：fn>元素描述了资源的属性。属性名称是vcard命名空间中的“FN”。 RDF通过连接命名空间前缀的URI引用和名称的本地名称部分的“FN”，将其转换为URI引用。这提供了一个URI引用”<a href="http://www.w3.org/2001/vcard-rdf/3.0#FN&quot;。属性的值是文字&quot;John" target="_blank" rel="external">http://www.w3.org/2001/vcard-rdf/3.0#FN&quot;。属性的值是文字&quot;John</a> Smith”。</vcard：fn></p>
<p><vcard：n>元素是一个资源。在这种情况下，资源由相对URI引用表示。 RDF通过将其与当前文档的基本URI连接，将其转换为绝对URI引用。</vcard：n></p>
<p>此RDF XML中有错误;它不完全代表我们创建的模型。模型中的空白节点已经被赋予URI引用。它不再是空白。 RDF / XML语法不能表示所有RDF模型;例如它不能表示作为两个语句的对象的空白节点。我们用来编写这个RDF / XML的’dumb’作者没有尝试正确地写入可以正确写入的Models子集。它为每个空白节点提供一个URI，使其不再为空。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">// now write the model in XML form to a file</div><div class="line">model.write(System.out, &quot;RDF/XML-ABBREV&quot;);</div><div class="line"></div><div class="line">// now write the model in N-TRIPLES form to a file</div><div class="line">model.write(System.out, &quot;N-TRIPLES&quot;);</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">&lt;rdf:RDF</div><div class="line">    xmlns:rdf=&quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#&quot;</div><div class="line">    xmlns:vcard=&quot;http://www.w3.org/2001/vcard-rdf/3.0#&quot;&gt;</div><div class="line">  &lt;rdf:Description rdf:about=&quot;http://somewhere/JohnSmith&quot;&gt;</div><div class="line">    &lt;vcard:N rdf:parseType=&quot;Resource&quot;&gt;</div><div class="line">      &lt;vcard:Family&gt;Smith&lt;/vcard:Family&gt;</div><div class="line">      &lt;vcard:Given&gt;John&lt;/vcard:Given&gt;</div><div class="line">    &lt;/vcard:N&gt;</div><div class="line">    &lt;vcard:FN&gt;John Smith&lt;/vcard:FN&gt;</div><div class="line">  &lt;/rdf:Description&gt;</div><div class="line">&lt;/rdf:RDF&gt;</div><div class="line">&lt;http://somewhere/JohnSmith&gt; &lt;http://www.w3.org/2001/vcard-rdf/3.0#N&gt; _:BX2D71b38d8eX3A1589596bd63X3AX2D7fff .</div><div class="line">&lt;http://somewhere/JohnSmith&gt; &lt;http://www.w3.org/2001/vcard-rdf/3.0#FN&gt; &quot;John Smith&quot; .</div><div class="line">_:BX2D71b38d8eX3A1589596bd63X3AX2D7fff &lt;http://www.w3.org/2001/vcard-rdf/3.0#Family&gt; &quot;Smith&quot; .</div><div class="line">_:BX2D71b38d8eX3A1589596bd63X3AX2D7fff &lt;http://www.w3.org/2001/vcard-rdf/3.0#Given&gt; &quot;John&quot; .</div></pre></td></tr></table></figure>
<h3 id="读取RDF"><a href="#读取RDF" class="headerlink" title="读取RDF"></a>读取RDF</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">static final String inputFileName = &quot;vc-db-1.rdf&quot;;</div><div class="line"></div><div class="line"> // create an empty model</div><div class="line"> Model model = ModelFactory.createDefaultModel();</div><div class="line"></div><div class="line"> // use the FileManager to find the input file</div><div class="line"> InputStream in = FileManager.get().open( inputFileName );</div><div class="line">if (in == null) &#123;</div><div class="line">    throw new IllegalArgumentException(</div><div class="line">                                 &quot;File: &quot; + inputFileName + &quot; not found&quot;);</div><div class="line">&#125;</div><div class="line"></div><div class="line">// read the RDF/XML file</div><div class="line">model.read(in, null);</div><div class="line"></div><div class="line">// write it to standard out</div><div class="line">model.write(System.out);</div></pre></td></tr></table></figure>
<p><strong>读取结果</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line">&lt;rdf:RDF</div><div class="line">  xmlns:rdf=&apos;http://www.w3.org/1999/02/22-rdf-syntax-ns#&apos;</div><div class="line">  xmlns:vcard=&apos;http://www.w3.org/2001/vcard-rdf/3.0#&apos;</div><div class="line"> &gt;</div><div class="line">  &lt;rdf:Description rdf:nodeID=&quot;A0&quot;&gt;</div><div class="line">    &lt;vcard:Family&gt;Smith&lt;/vcard:Family&gt;</div><div class="line">    &lt;vcard:Given&gt;John&lt;/vcard:Given&gt;</div><div class="line">  &lt;/rdf:Description&gt;</div><div class="line">  &lt;rdf:Description rdf:about=&apos;http://somewhere/JohnSmith/&apos;&gt;</div><div class="line">    &lt;vcard:FN&gt;John Smith&lt;/vcard:FN&gt;</div><div class="line">    &lt;vcard:N rdf:nodeID=&quot;A0&quot;/&gt;</div><div class="line">  &lt;/rdf:Description&gt;</div><div class="line">  &lt;rdf:Description rdf:about=&apos;http://somewhere/SarahJones/&apos;&gt;</div><div class="line">    &lt;vcard:FN&gt;Sarah Jones&lt;/vcard:FN&gt;</div><div class="line">    &lt;vcard:N rdf:nodeID=&quot;A1&quot;/&gt;</div><div class="line">  &lt;/rdf:Description&gt;</div><div class="line">  &lt;rdf:Description rdf:about=&apos;http://somewhere/MattJones/&apos;&gt;</div><div class="line">    &lt;vcard:FN&gt;Matt Jones&lt;/vcard:FN&gt;</div><div class="line">    &lt;vcard:N rdf:nodeID=&quot;A2&quot;/&gt;</div><div class="line">  &lt;/rdf:Description&gt;</div><div class="line">  &lt;rdf:Description rdf:nodeID=&quot;A3&quot;&gt;</div><div class="line">    &lt;vcard:Family&gt;Smith&lt;/vcard:Family&gt;</div><div class="line">    &lt;vcard:Given&gt;Rebecca&lt;/vcard:Given&gt;</div><div class="line">  &lt;/rdf:Description&gt;</div><div class="line">  &lt;rdf:Description rdf:nodeID=&quot;A1&quot;&gt;</div><div class="line">    &lt;vcard:Family&gt;Jones&lt;/vcard:Family&gt;</div><div class="line">    &lt;vcard:Given&gt;Sarah&lt;/vcard:Given&gt;</div><div class="line">  &lt;/rdf:Description&gt;</div><div class="line">  &lt;rdf:Description rdf:nodeID=&quot;A2&quot;&gt;</div><div class="line">    &lt;vcard:Family&gt;Jones&lt;/vcard:Family&gt;</div><div class="line">    &lt;vcard:Given&gt;Matthew&lt;/vcard:Given&gt;</div><div class="line">  &lt;/rdf:Description&gt;</div><div class="line">  &lt;rdf:Description rdf:about=&apos;http://somewhere/RebeccaSmith/&apos;&gt;</div><div class="line">    &lt;vcard:FN&gt;Becky Smith&lt;/vcard:FN&gt;</div><div class="line">    &lt;vcard:N rdf:nodeID=&quot;A3&quot;/&gt;</div><div class="line">  &lt;/rdf:Description&gt;</div><div class="line">&lt;/rdf:RDF&gt;</div></pre></td></tr></table></figure></p>
<h3 id="Jena-RDF包"><a href="#Jena-RDF包" class="headerlink" title="Jena RDF包"></a>Jena RDF包</h3><p>Jena是用于语义Web应用程序的Java API。应用程序开发人员的关键RDF包是org.apache.jena.rdf.model。 API已经根据接口进行了定义，以便应用程序代码可以在不改变的情况下与不同的实现工作。此包包含用于表示模型，资源，属性，文字，语句和RDF的所有其他关键概念的接口，以及用于创建模型的ModelFactory。所以应用程序代码保持独立的实现，最好是尽可能使用接口，而不是特定的类实现。</p>
<p>org.apache.jena.tutorial包包含本教程中使用的所有示例的工作源代码。</p>
<p>org.apache.jena … impl包包含可能对许多实现通用的实现类。例如，它们定义类ResourceImpl，PropertyImpl和LiteralImpl，它们可以被不同的实现直接使用或子类化。应用程序应该很少，如果有的话，直接使用这些类。例如，不是创建ResourceImpl的新实例，最好使用正在使用的任何模型的createResource方法。这样，如果模型实现使用了Resource的优化实现，则两种类型之间不需要转换。</p>
<h3 id="浏览模型"><a href="#浏览模型" class="headerlink" title="浏览模型"></a>浏览模型</h3><p>给定资源的URI，可以使用Model.getResource（String uri）方法从模型中检索资源对象。 此方法定义为返回一个Resource对象（如果模型中存在），否则创建一个新对象。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line">static final String inputFileName = &quot;vc-db-1.rdf&quot;;</div><div class="line">    static final String johnSmithURI = &quot;http://somewhere/JohnSmith/&quot;;</div><div class="line">    </div><div class="line">    public static void main (String args[]) &#123;</div><div class="line">        // create an empty model</div><div class="line">        Model model = ModelFactory.createDefaultModel();</div><div class="line">       </div><div class="line">        // use the FileManager to find the input file</div><div class="line">        InputStream in = FileManager.get().open(inputFileName);</div><div class="line">        if (in == null) &#123;</div><div class="line">            throw new IllegalArgumentException( &quot;File: &quot; + inputFileName + &quot; not found&quot;);</div><div class="line">        &#125;</div><div class="line">        </div><div class="line">        </div><div class="line">        // read the RDF/XML file</div><div class="line">        model.read(new InputStreamReader(in), &quot;&quot;);</div><div class="line">        </div><div class="line">        // retrieve the Adam Smith vcard resource from the model</div><div class="line">        Resource vcard = model.getResource(johnSmithURI);</div><div class="line"></div><div class="line">        // retrieve the value of the N property</div><div class="line">        Resource name = (Resource) vcard.getRequiredProperty(VCARD.N)</div><div class="line">                                        .getObject();</div><div class="line">        // retrieve the given name property</div><div class="line">        String fullName = vcard.getRequiredProperty(VCARD.FN)</div><div class="line">                               .getString();</div><div class="line">        // add two nick name properties to vcard</div><div class="line">		// 获取johnSmithURI资源后，对其添加两个nickname属性</div><div class="line">        vcard.addProperty(VCARD.NICKNAME, &quot;Smithy&quot;)</div><div class="line">             .addProperty(VCARD.NICKNAME, &quot;Adman&quot;);</div><div class="line">        </div><div class="line">        // set up the output</div><div class="line">        System.out.println(&quot;The nicknames of \&quot;&quot; + fullName + &quot;\&quot; are:&quot;);</div><div class="line">        // list the nicknames</div><div class="line">		//返回声明迭代器，获取对象</div><div class="line">        StmtIterator iter = vcard.listProperties(VCARD.NICKNAME);</div><div class="line">        while (iter.hasNext()) &#123;</div><div class="line">            System.out.println(&quot;    &quot; + iter.nextStatement().getObject()</div><div class="line">                                            .toString());</div><div class="line">        &#125;</div><div class="line">    &#125;</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">The nicknames of &quot;John Smith&quot; are:</div><div class="line">    Adman</div><div class="line">    Smithy</div></pre></td></tr></table></figure>
<h3 id="查询模型"><a href="#查询模型" class="headerlink" title="查询模型"></a>查询模型</h3><p>上一节讨论从具有已知URI的资源导航模型的情况。 本节介绍搜索模型。 核心Jena API仅支持有限的查询原语。 更强大的查询功能在SPARQL中。</p>
<p>Model.listStatements（）方法列出了模型中的所有语句，也许是查询模型的最粗糙的方法。 它的使用不推荐在非常大的模型。 Model.listSubjects（）是类似的，但返回一个迭代器在所有具有属性的资源，即一些语句的主题。</p>
<p>Model.listSubjectsWithProperty（Property p，RDFNode o）将返回所有资源的迭代器，这些资源具有值为o的属性p。 如果我们假设只有vcard资源会有vcard：FN属性，并且在我们的数据中，所有这些资源都有这样的属性，那么我们可以找到所有的vcards：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">static final String inputFileName = &quot;vc-db-1.rdf&quot;;</div><div class="line">   </div><div class="line">   public static void main (String args[]) &#123;</div><div class="line">       // create an empty model</div><div class="line">       Model model = ModelFactory.createDefaultModel();</div><div class="line">      </div><div class="line">       // use the FileManager to find the input file</div><div class="line">       InputStream in = FileManager.get().open(inputFileName);</div><div class="line">       if (in == null) &#123;</div><div class="line">           throw new IllegalArgumentException( &quot;File: &quot; + inputFileName + &quot; not found&quot;);</div><div class="line">       &#125;</div><div class="line">       </div><div class="line">       // read the RDF/XML file</div><div class="line">       model.read( in, &quot;&quot;);</div><div class="line">       </div><div class="line">       // select all the resources with a VCARD.FN property</div><div class="line">       ResIterator iter = model.listResourcesWithProperty(VCARD.FN);</div><div class="line">       if (iter.hasNext()) &#123;</div><div class="line">           System.out.println(&quot;The database contains vcards for:&quot;);</div><div class="line">           while (iter.hasNext()) &#123;</div><div class="line">               System.out.println(&quot;  &quot; + iter.nextResource()</div><div class="line">                                             .getRequiredProperty(VCARD.FN)</div><div class="line">                                             .getString() );</div><div class="line">           &#125;</div><div class="line">       &#125; else &#123;</div><div class="line">           System.out.println(&quot;No vcards were found in the database&quot;);</div><div class="line">       &#125;            </div><div class="line">   &#125;</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">The database contains vcards for:</div><div class="line">  Sarah Jones</div><div class="line">  John Smith</div><div class="line">  Becky Smith</div><div class="line">  Matt Jones</div></pre></td></tr></table></figure>
<h3 id="模型操作"><a href="#模型操作" class="headerlink" title="模型操作"></a>模型操作</h3><p>Jena提供了操作模型作为一个整体的三个操作,分別是并集，交集和差的运算。</p>
<p>两个模型的并集是表示每个模型的语句集合的合并。这是RDF设计支持的关键操作之一。它允许合并来自不同数据源的数据。 考虑以下两个模型：<br><img src="http://i.imgur.com/F1ooVdI.png" alt=""> <img src="http://i.imgur.com/HDmwweL.png" alt=""></p>
<p>当这些被合并时，两个http：//…JohnSmith节点被合并成一个，并且vcard：FN 弧被丢弃以产生：<br><img src="http://i.imgur.com/6cZO0rR.png" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">static final String inputFileName1 = &quot;vc-db-3.rdf&quot;;    </div><div class="line"> static final String inputFileName2 = &quot;vc-db-4.rdf&quot;;</div><div class="line"> </div><div class="line"> public static void main (String args[]) &#123;</div><div class="line">     // create an empty model</div><div class="line">     Model model1 = ModelFactory.createDefaultModel();</div><div class="line">     Model model2 = ModelFactory.createDefaultModel();</div><div class="line">    </div><div class="line">     // use the class loader to find the input file</div><div class="line">     InputStream in1 = FileManager.get().open(inputFileName1);</div><div class="line">     if (in1 == null) &#123;</div><div class="line">         throw new IllegalArgumentException( &quot;File: &quot; + inputFileName1 + &quot; not found&quot;);</div><div class="line">     &#125;</div><div class="line">     InputStream in2 = FileManager.get().open(inputFileName2);</div><div class="line">     if (in2 == null) &#123;</div><div class="line">         throw new IllegalArgumentException( &quot;File: &quot; + inputFileName2 + &quot; not found&quot;);</div><div class="line">     &#125;</div><div class="line">     </div><div class="line">     // read the RDF/XML files</div><div class="line">     model1.read( in1, &quot;&quot; );</div><div class="line">     model2.read( in2, &quot;&quot; );</div><div class="line">     </div><div class="line">     // merge the graphs</div><div class="line">     Model model = model1.union(model2);</div><div class="line">     </div><div class="line">     // print the graph as RDF/XML</div><div class="line">     model.write(System.out, &quot;RDF/XML-ABBREV&quot;);</div><div class="line">     System.out.println();</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">&lt;rdf:RDF</div><div class="line">    xmlns:rdf=&quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#&quot;</div><div class="line">    xmlns:vcard=&quot;http://www.w3.org/2001/vcard-rdf/3.0#&quot;&gt;</div><div class="line">  &lt;rdf:Description rdf:about=&quot;http://somewhere/JohnSmith/&quot;&gt;</div><div class="line">    &lt;vcard:N rdf:parseType=&quot;Resource&quot;&gt;</div><div class="line">      &lt;vcard:Given&gt;John&lt;/vcard:Given&gt;</div><div class="line">      &lt;vcard:Family&gt;Smith&lt;/vcard:Family&gt;</div><div class="line">    &lt;/vcard:N&gt;</div><div class="line">    &lt;vcard:EMAIL&gt;</div><div class="line">      &lt;vcard:internet&gt;</div><div class="line">        &lt;rdf:value&gt;John@somewhere.com&lt;/rdf:value&gt;</div><div class="line">      &lt;/vcard:internet&gt;</div><div class="line">    &lt;/vcard:EMAIL&gt;</div><div class="line">    &lt;vcard:FN&gt;John Smith&lt;/vcard:FN&gt;</div><div class="line">  &lt;/rdf:Description&gt;</div><div class="line">&lt;/rdf:RDF&gt;</div></pre></td></tr></table></figure>
<h3 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h3><p>RDF定义了一种特殊的资源来表示事物的集合。 这些资源称为容器。 容器的成员可以是文字或资源。 有三种容器：</p>
<p>BAG是一个无序的集合<br>ALT是旨在表示可选的无序集合<br>SEQ是有序集合<br>容器由资源表示。 该资源将有一个rdf：type属性，其值应为rdf：Bag，rdf：Alt或rdf：Seq之一，或其中一个的子类，具体取决于容器的类型。 容器的第一个成员是容器的rdf：_1属性的值; 容器的第二个成员是容器的rdf：_2属性的值，等等。 rdf：_nnn属性被称为序数属性。</p>
<p>例如，包含Smith的vcards的简单包的模型可能如下所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line">static final String inputFileName = &quot;vc-db-1.rdf&quot;;</div><div class="line">   </div><div class="line">   public static void main (String args[]) &#123;</div><div class="line">       // create an empty model</div><div class="line">       Model model = ModelFactory.createDefaultModel();</div><div class="line">      </div><div class="line">       // use the class loader to find the input file</div><div class="line">       InputStream in = FileManager.get().open( inputFileName );</div><div class="line">       if (in == null) &#123;</div><div class="line">           throw new IllegalArgumentException( &quot;File: &quot; + inputFileName + &quot; not found&quot;);</div><div class="line">       &#125;</div><div class="line">       </div><div class="line">       // read the RDF/XML file</div><div class="line">       model.read(new InputStreamReader(in), &quot;&quot;);</div><div class="line">       </div><div class="line">       // create a bag</div><div class="line">       Bag smiths = model.createBag();</div><div class="line">       </div><div class="line">       // select all the resources with a VCARD.FN property</div><div class="line">       // whose value ends with &quot;Smith&quot;</div><div class="line">       StmtIterator iter = model.listStatements(</div><div class="line">           new </div><div class="line">               SimpleSelector(null, VCARD.FN, (RDFNode) null) &#123;</div><div class="line">                   @Override</div><div class="line">                   public boolean selects(Statement s) &#123;</div><div class="line">                           return s.getString().endsWith(&quot;Smith&quot;);</div><div class="line">                   &#125;</div><div class="line">               &#125;);</div><div class="line">       // add the Smith&apos;s to the bag</div><div class="line">       while (iter.hasNext()) &#123;</div><div class="line">           smiths.add( iter.nextStatement().getSubject());</div><div class="line">       &#125;</div><div class="line">       </div><div class="line">       // print the graph as RDF/XML</div><div class="line">       model.write(new PrintWriter(System.out));</div><div class="line">       System.out.println();</div><div class="line">       </div><div class="line">       // print out the members of the bag</div><div class="line">       NodeIterator iter2 = smiths.iterator();</div><div class="line">       if (iter2.hasNext()) &#123;</div><div class="line">           System.out.println(&quot;The bag contains:&quot;);</div><div class="line">           while (iter2.hasNext()) &#123;</div><div class="line">               System.out.println(&quot;  &quot; +</div><div class="line">                   ((Resource) iter2.next())</div><div class="line">                                    .getRequiredProperty(VCARD.FN)</div><div class="line">                                    .getString());</div><div class="line">           &#125;</div><div class="line">       &#125; else &#123;</div><div class="line">           System.out.println(&quot;The bag is empty&quot;);</div><div class="line">       &#125;</div><div class="line">   &#125;</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line">&lt;rdf:RDF</div><div class="line">    xmlns:rdf=&quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#&quot;</div><div class="line">    xmlns:vcard=&quot;http://www.w3.org/2001/vcard-rdf/3.0#&quot;&gt;</div><div class="line">  &lt;rdf:Description rdf:about=&quot;http://somewhere/SarahJones/&quot;&gt;</div><div class="line">    &lt;vcard:N rdf:parseType=&quot;Resource&quot;&gt;</div><div class="line">      &lt;vcard:Given&gt;Sarah&lt;/vcard:Given&gt;</div><div class="line">      &lt;vcard:Family&gt;Jones&lt;/vcard:Family&gt;</div><div class="line">    &lt;/vcard:N&gt;</div><div class="line">    &lt;vcard:FN&gt;Sarah Jones&lt;/vcard:FN&gt;</div><div class="line">  &lt;/rdf:Description&gt;</div><div class="line">  &lt;rdf:Bag&gt;</div><div class="line">    &lt;rdf:li&gt;</div><div class="line">      &lt;rdf:Description rdf:about=&quot;http://somewhere/RebeccaSmith/&quot;&gt;</div><div class="line">        &lt;vcard:N rdf:parseType=&quot;Resource&quot;&gt;</div><div class="line">          &lt;vcard:Given&gt;Rebecca&lt;/vcard:Given&gt;</div><div class="line">          &lt;vcard:Family&gt;Smith&lt;/vcard:Family&gt;</div><div class="line">        &lt;/vcard:N&gt;</div><div class="line">        &lt;vcard:FN&gt;Becky Smith&lt;/vcard:FN&gt;</div><div class="line">      &lt;/rdf:Description&gt;</div><div class="line">    &lt;/rdf:li&gt;</div><div class="line">    &lt;rdf:li&gt;</div><div class="line">      &lt;rdf:Description rdf:about=&quot;http://somewhere/JohnSmith/&quot;&gt;</div><div class="line">        &lt;vcard:N rdf:parseType=&quot;Resource&quot;&gt;</div><div class="line">          &lt;vcard:Given&gt;John&lt;/vcard:Given&gt;</div><div class="line">          &lt;vcard:Family&gt;Smith&lt;/vcard:Family&gt;</div><div class="line">        &lt;/vcard:N&gt;</div><div class="line">        &lt;vcard:FN&gt;John Smith&lt;/vcard:FN&gt;</div><div class="line">      &lt;/rdf:Description&gt;</div><div class="line">    &lt;/rdf:li&gt;</div><div class="line">  &lt;/rdf:Bag&gt;</div><div class="line">  &lt;rdf:Description rdf:about=&quot;http://somewhere/MattJones/&quot;&gt;</div><div class="line">    &lt;vcard:N rdf:parseType=&quot;Resource&quot;&gt;</div><div class="line">      &lt;vcard:Given&gt;Matthew&lt;/vcard:Given&gt;</div><div class="line">      &lt;vcard:Family&gt;Jones&lt;/vcard:Family&gt;</div><div class="line">    &lt;/vcard:N&gt;</div><div class="line">    &lt;vcard:FN&gt;Matt Jones&lt;/vcard:FN&gt;</div><div class="line">  &lt;/rdf:Description&gt;</div><div class="line">&lt;/rdf:RDF&gt;</div><div class="line"></div><div class="line">The bag contains:</div><div class="line">  Becky Smith</div><div class="line">  John Smith</div></pre></td></tr></table></figure>
<h3 id="词汇表"><a href="#词汇表" class="headerlink" title="词汇表"></a>词汇表</h3><p>空白节点（Blank Node）<br>表示资源，但不指示资源的URI。空白节点表现为一阶逻辑中存在的合格变量。<br>Dublin Core<br>关于Web资源的元数据标准。更多信息可以在Dublin Core网站上找到。<br>文字（Literal）<br>可以是属性值的字符串。<br>对象（Object）<br>三元组的一部分，即语句的值。<br>谓词（Predicate）<br>三元组的属性部分。<br>属性（Property）<br>属性是资源的属性。例如DC.title是一个属性，和RDF.type一样。<br>资源（Resource）<br>一些实体。它可以是诸如网页的web资源，或者它可以是具体的物理事物，例如树或汽车。它可以是一个抽象的想法，如象棋或足球。资源由URI命名。<br>声明（Statement）<br>RDF模型中的弧，通常被解释为事实。<br>主语Subject）<br>作为RDF模型中的弧源的资源<br>三元组（Triple）<br>包含主语，谓词和对象的结构。语句的另一个术语。</p>
<h3 id="脚注"><a href="#脚注" class="headerlink" title="脚注"></a>脚注</h3><p>RDF资源的标识符可以包括片段标识符，例如， http：// hostname / rdf / tutorial /＃ch-简介，因此，严格地说，RDF资源由URI引用标识。<br>除了作为一个字符串，字面量还有一个可选的语言编码来表示字符串的语言。例如，文字“two”对于英语可能具有“en”的语言编码，而对于法国，文字“deux”可能具有“fr”的语言编码。</p>
]]></content>
      
        <categories>
            
            <category> paper </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Jena </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Distributed Cache在mapreduce中读取小文件]]></title>
      <url>http://yoursite.com/2016/11/26/Distributed%20Cache%E5%9C%A8mapreduce%E4%B8%AD%E8%AF%BB%E5%8F%96%E5%B0%8F%E6%96%87%E4%BB%B6/</url>
      <content type="html"><![CDATA[<p>Distributed Cache 在 MapReduce 任务中应用很广， 它可以大大提高一些被频繁读取文件的访问速度。被添加到 Distributed Cache 的文件会被拷贝到 Mapper 和 Reducer 的运行目录中。</p>
<p><strong>在job添加如下方法 </strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">remoteReGamePath为hdfs文件路径字符串</div><div class="line">job.addCacheFile(new Path(remoteReGamePath).toUri());</div></pre></td></tr></table></figure></p>
<a id="more"></a>
<p><strong>以下例子为在map中读取此文件并存入集合</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line">private Set&lt;String&gt; recommendGame = new HashSet&lt;String&gt;();</div><div class="line">/**</div><div class="line">		 * 读取推荐游戏文件</div><div class="line">		 * </div><div class="line">		 * @param uri</div><div class="line">		 */</div><div class="line">		private void readReGame(URI uri) &#123;</div><div class="line">			try &#123;</div><div class="line">				Path patternsPath = new Path(uri.getPath());</div><div class="line">				String patternsFileName = patternsPath.getName().toString();</div><div class="line">				BufferedReader reader = new BufferedReader(new FileReader(</div><div class="line">						patternsFileName));</div><div class="line">				String line;</div><div class="line">				while ((line = reader.readLine()) != null) &#123;</div><div class="line">					// TODO: your code here</div><div class="line">					//</div><div class="line">					recommendGame.add(line.split(&quot;,&quot;)[0]);</div><div class="line">				&#125;</div><div class="line">				reader.close();</div><div class="line"></div><div class="line">			&#125; catch (FileNotFoundException e) &#123;</div><div class="line">				// TODO Auto-generated catch block</div><div class="line">				e.printStackTrace();</div><div class="line">			&#125; catch (IOException e) &#123;</div><div class="line">				// TODO Auto-generated catch block</div><div class="line">				e.printStackTrace();</div><div class="line">			&#125;</div><div class="line"></div><div class="line">		&#125;</div><div class="line"></div><div class="line">		@Override</div><div class="line">		protected void setup(</div><div class="line">				Mapper&lt;LongWritable, Text, Text, Text&gt;.Context context)</div><div class="line">				throws IOException, InterruptedException &#123;</div><div class="line">			// TODO Auto-generated method stub</div><div class="line">			super.setup(context);</div><div class="line">			//获取cache  uri</div><div class="line">			URI[] uri = context.getCacheFiles();</div><div class="line"></div><div class="line">			readReGame(uri[0]);</div><div class="line"></div><div class="line">		&#125;</div></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MapReduce </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[mapreduce多目录输出笔记]]></title>
      <url>http://yoursite.com/2016/11/26/mapreduce%E5%A4%9A%E7%9B%AE%E5%BD%95%E8%BE%93%E5%87%BA%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<h3 id="使用MultipleOutputs实现多目录-文件输出"><a href="#使用MultipleOutputs实现多目录-文件输出" class="headerlink" title="使用MultipleOutputs实现多目录/文件输出"></a>使用MultipleOutputs实现多目录/文件输出</h3><p><code>org.apache.hadoop.mapreduce.lib.output.MultipleOutputs</code><br><a id="more"></a><br><strong>在map或者reduce类中加入如下方法</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">private MultipleOutputs&lt;Text, NullWritable&gt; mos;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	protected void setup(Reducer&lt;Text, NullWritable, Text, NullWritable&gt;.Context context)</div><div class="line">			throws IOException, InterruptedException &#123;</div><div class="line">		// TODO Auto-generated method stub</div><div class="line">		super.setup(context);</div><div class="line">		mos = new MultipleOutputs&lt;Text, NullWritable&gt;(context);// 初始化mos</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	protected void cleanup(Reducer&lt;Text, NullWritable, Text, NullWritable&gt;.Context context)</div><div class="line">			throws IOException, InterruptedException &#123;</div><div class="line">		// TODO Auto-generated method stub</div><div class="line">		super.cleanup(context);</div><div class="line">		mos.close();</div><div class="line">	&#125;</div></pre></td></tr></table></figure></p>
<p><strong>在需要输出数据的地方，可以使用定义好的 mos 进行输出</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">mos.write(&quot;outputName&quot;, key, value);</div><div class="line">mos.write(&quot;outputName&quot;, key, value, &quot;filePrefix&quot;); </div><div class="line">mos.write(&quot;outputName&quot;, key, value, &quot;path/filePrefix&quot;);//到文件夹</div></pre></td></tr></table></figure></p>
<p><strong>在Job Driver 时定义一些 Named Output</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">MultipleOutputs.addNamedOutput(job, &quot;outputXName&quot;,</div><div class="line">    XXXOutputFormat.class, OutputXKey.class, OutputXValue.class);</div><div class="line">MultipleOutputs.addNamedOutput(job, &quot;outputYName&quot;,</div><div class="line">    YYYOutputFormat.class, OutputYKey.class, OutputYValue.class);</div></pre></td></tr></table></figure></p>
<p><strong>取消类似part-r-00000的空文件</strong><br><code>LazyOutputFormat.setOutputFormatClass(job, TextOutputFormat.class)</code><br><strong>例子</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div></pre></td><td class="code"><pre><div class="line">package com.hdu.recommend.mr;</div><div class="line"></div><div class="line">import java.io.IOException;</div><div class="line"></div><div class="line">import org.apache.hadoop.conf.Configuration;</div><div class="line">import org.apache.hadoop.fs.Path;</div><div class="line">import org.apache.hadoop.io.LongWritable;</div><div class="line">import org.apache.hadoop.io.NullWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Job;</div><div class="line">import org.apache.hadoop.mapreduce.Mapper;</div><div class="line">import org.apache.hadoop.mapreduce.Reducer;</div><div class="line">import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line">import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;</div><div class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line">import org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat;</div><div class="line">import org.apache.hadoop.mapreduce.lib.output.MultipleOutputs;</div><div class="line">import org.apache.hadoop.mapreduce.lib.output.NullOutputFormat;</div><div class="line">import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;</div><div class="line">import org.apache.hadoop.yarn.conf.YarnConfiguration;</div><div class="line"></div><div class="line"></div><div class="line"> * @author Skye</div><div class="line"> *</div><div class="line"> */</div><div class="line">public class DataCleanIconAndWeb &#123;</div><div class="line">	public static class QLMapper extends</div><div class="line">			Mapper&lt;LongWritable, Text, Text, NullWritable&gt; &#123;</div><div class="line"></div><div class="line"></div><div class="line">		private String webGame = &quot;网页游戏&quot;;</div><div class="line"></div><div class="line">		Text outputValue = new Text();</div><div class="line">		// 设置多文件输出</div><div class="line">		private MultipleOutputs&lt;Text,NullWritable&gt; mos;</div><div class="line">		@Override</div><div class="line">		protected void setup(Mapper&lt;LongWritable, Text, Text, NullWritable&gt;.Context context)</div><div class="line">				throws IOException, InterruptedException &#123;</div><div class="line">			// TODO Auto-generated method stub</div><div class="line">			super.setup(context);</div><div class="line">			mos = new MultipleOutputs&lt;Text, NullWritable&gt;(context);// 初始化mos</div><div class="line">		&#125;</div><div class="line">		@Override</div><div class="line">		protected void cleanup(Mapper&lt;LongWritable, Text, Text, NullWritable&gt;.Context context)</div><div class="line">				throws IOException, InterruptedException &#123;</div><div class="line">			// TODO Auto-generated method stub</div><div class="line">			super.cleanup(context);</div><div class="line">			mos.close();</div><div class="line">		&#125;</div><div class="line">		@Override</div><div class="line">		protected void map(LongWritable key, Text value, Context context)</div><div class="line">				throws IOException, InterruptedException &#123;</div><div class="line">			// 接收数据v1</div><div class="line">			String line = value.toString();</div><div class="line">			// 切分数据</div><div class="line">			String[] words = line.split(&quot;&quot;);</div><div class="line">			// String[] words = line.split(&quot;\t&quot;);</div><div class="line">			boolean isWeb = false;</div><div class="line">			boolean flag = true;</div><div class="line">			</div><div class="line">			//一系列处理代码</div><div class="line">			//***</div><div class="line">			//***</div><div class="line">			//***</div><div class="line">			String action = words[1] + &quot;\t&quot; + words[0] + &quot;\t&quot; + words[2]</div><div class="line">						+ &quot;\t&quot; + words[3] + &quot;\t&quot; + words[5];</div><div class="line"></div><div class="line">			outputValue.set(action);</div><div class="line">			mos.write(&quot;iconRecord&quot;, outputValue, NullWritable.get(),&quot;iconRecord/icon&quot;);</div><div class="line">			</div><div class="line">			</div><div class="line">	</div><div class="line">			String action = words[1] + &quot;\t&quot; + words[0] + &quot;\t&quot;</div><div class="line">							+ words[2] + &quot;\t&quot; + words[3] + &quot;\t&quot; + words[4]</div><div class="line">							+ &quot;\t&quot; + words[5];</div><div class="line"></div><div class="line">			outputValue.set(action);</div><div class="line">			mos.write( &quot;webRecord&quot;,outputValue, NullWritable.get(),&quot;webRecord/web&quot;);</div><div class="line">				</div><div class="line"></div><div class="line">			</div><div class="line">		&#125;</div><div class="line"></div><div class="line">	&#125;</div><div class="line"></div><div class="line">	</div><div class="line"></div><div class="line">	public static void run(String originalDataPath, String dataCleanOutputFile)</div><div class="line">			throws Exception &#123;</div><div class="line"></div><div class="line">		// 构建Job对象</div><div class="line">		Configuration conf = new Configuration();</div><div class="line"></div><div class="line">		Job job = Job.getInstance(conf);</div><div class="line"></div><div class="line">		// 注意：main方法所在的类</div><div class="line">		job.setJarByClass(DataCleanIconAndWeb.class);</div><div class="line">		job.getConfiguration().setBoolean(&quot;mapreduce.output.fileoutputformat.compress&quot;, false);</div><div class="line">		job.getConfiguration().setStrings(</div><div class="line">				&quot;mapreduce.reduce.shuffle.input.buffer.percent&quot;, &quot;0.1&quot;);</div><div class="line">		job.getConfiguration().setBoolean(&quot;mapreduce.output.fileoutputformat.compress&quot;, false);</div><div class="line">		job.setNumReduceTasks(3);</div><div class="line"></div><div class="line">		// 设置Mapper相关属性</div><div class="line">		job.setMapperClass(QLMapper.class);</div><div class="line">		job.setMapOutputKeyClass(Text.class);</div><div class="line">		job.setMapOutputValueClass(NullWritable.class);</div><div class="line"></div><div class="line">		</div><div class="line">		FileInputFormat.setInputPaths(job, new Path(originalDataPath));</div><div class="line"></div><div class="line">		</div><div class="line"></div><div class="line">		// 设置Reducer相关属性</div><div class="line">		</div><div class="line">		job.setOutputKeyClass(Text.class);</div><div class="line">		job.setOutputValueClass(NullWritable.class);</div><div class="line"></div><div class="line">		FileOutputFormat.setOutputPath(job, new Path(dataCleanOutputFile));</div><div class="line">		</div><div class="line">		MultipleOutputs.addNamedOutput(job, &quot;iconRecord&quot;,</div><div class="line">				TextOutputFormat.class, Text.class, NullWritable.class);</div><div class="line">		MultipleOutputs.addNamedOutput(job, &quot;webRecord&quot;,</div><div class="line">				TextOutputFormat.class, Text.class, NullWritable.class);</div><div class="line">		</div><div class="line">		// 文件格式</div><div class="line">		job.setInputFormatClass(TextInputFormat.class);</div><div class="line">		//取消part-r-00000新式文件输出</div><div class="line">		LazyOutputFormat.setOutputFormatClass(job, TextOutputFormat.class);</div><div class="line">		</div><div class="line">		</div><div class="line">		//job.setOutputFormatClass(TextOutputFormat.class);</div><div class="line">		// 提交任务</div><div class="line">		job.waitForCompletion(true);</div><div class="line"></div><div class="line">		long endTime = System.currentTimeMillis();</div><div class="line"></div><div class="line">	&#125;</div><div class="line"> </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<blockquote>
<p>参考<br><a href="http://gnailuy.com/dataplatform/2015/11/22/common-techniques-for-mapreduce/" target="_blank" rel="external">http://gnailuy.com/dataplatform/2015/11/22/common-techniques-for-mapreduce/</a><br><a href="http://blog.csdn.net/zgc625238677/article/details/51524786" target="_blank" rel="external">http://blog.csdn.net/zgc625238677/article/details/51524786</a><br><a href="https://www.iteblog.com/archives/848" target="_blank" rel="external">https://www.iteblog.com/archives/848</a></p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MapReduce </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[hive数据查询导出]]></title>
      <url>http://yoursite.com/2016/11/26/hive%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5/</url>
      <content type="html"><![CDATA[<h3 id="hive数据查询导出"><a href="#hive数据查询导出" class="headerlink" title="hive数据查询导出"></a>hive数据查询导出</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">insert overwrite directory &apos;/user/hdu/recommend/gameRecommendNew4/test11.26/gameprestep1&apos;</div><div class="line">row format delimited</div><div class="line">fields terminated by &apos;\t&apos;</div><div class="line">SELECT userid , gamename , COUNT(*) AS count , MAX(gamestarttime) AS lasttime</div><div class="line">FROM userdetailtwo</div><div class="line">GROUP BY userid , gamename</div></pre></td></tr></table></figure>
<a id="more"></a>
<p><strong>出错</strong><br><code>FAILED: ParseException line 2:0 cannot recognize input near &#39;row&#39; &#39;format&#39; &#39;delimited&#39; in statement</code></p>
<p><strong>原因</strong><br>This is because the hive query will by default use the ^ as the delimiter. You can try the same by exporting to local file system.That should be supported.</p>
<p><strong>解决</strong><br>create an external table to the location where you want your output file.Use create table as command and insert the required data into the external table.By that you will get the data in the HDFS location<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">create external table user_game_count_lasttime2(userid STRING ,gamename STRING,count INT,lasttime STRING)</div><div class="line">ROW FORMAT DELIMITED</div><div class="line">FIElDS TERMINATED BY &apos;\t&apos;</div><div class="line">STORED AS TEXTFILE</div><div class="line">LOCATION &apos;/user/hdu/recommend/gameRecommendNew4/test11.26/gameprestep1_2&apos;;</div><div class="line"></div><div class="line">insert overwrite table user_game_count_lasttime2 </div><div class="line">SELECT userid , gamename , COUNT(*) AS count , MAX(gamestarttime) AS lasttime</div><div class="line">FROM userdetailtwo</div><div class="line">GROUP BY userid , gamename;</div></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Hive </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hadoop Job相关命令]]></title>
      <url>http://yoursite.com/2016/11/05/hadoop%20Job%E5%91%BD%E4%BB%A4/</url>
      <content type="html"><![CDATA[<p>hadoop命令行 与job相关的：<br>命令行工具 •<br>1.查看 Job 信息：<br>hadoop job -list<br>2.杀掉 Job：<br>hadoop  job -kill  job_id<br>3.指定路径下查看历史日志汇总：<br>hadoop job -history output-dir<br>4.作业的更多细节：<br>hadoop job -history all output-dir<br>5.打印map和reduce完成百分比和所有计数器：<br>hadoop job -status job_id<br>6.杀死任务。被杀死的任务不会不利于失败尝试：<br>hadoop jab -kill-task <task-id><br>7.使任务失败。被失败的任务会对失败尝试不利：<br>hadoop job  -fail-task <task-id></task-id></task-id></p>
<a id="more"></a>]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[mapreduce运行内存及JVM配置错误running beyond physical memory limits]]></title>
      <url>http://yoursite.com/2016/11/03/mapreduce%E8%BF%90%E8%A1%8C%E5%86%85%E5%AD%98%E5%8F%8AJVM%E9%85%8D%E7%BD%AE%E9%94%99%E8%AF%AFrunning%20beyond%20physical%20/</url>
      <content type="html"><![CDATA[<h3 id="错误描述："><a href="#错误描述：" class="headerlink" title="错误描述："></a>错误描述：</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">16/11/02 21:52:58 INFO mapreduce.Job: Task Id : attempt_1476760655616_0575_r_000000_2, Status : FAILED</div><div class="line">Container [pid=24537,containerID=container_1476760655616_0575_01_000052] is running beyond physical memory limits. Current usage: 4.0 GB of 3 GB physical memory used; 6.9 GB of 6.3 GB virtual memory used. Killing container.</div><div class="line">Dump of the process-tree for container_1476760655616_0575_01_000052 :</div><div class="line">	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE</div></pre></td></tr></table></figure>
<a id="more"></a>
<h3 id="解决："><a href="#解决：" class="headerlink" title="解决："></a>解决：</h3><p>查看hadoop配置参数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;mapreduce.map.memory.mb&lt;/name&gt;</div><div class="line">    &lt;value&gt;3072&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">      &lt;name&gt;mapreduce.reduce.memory.mb&lt;/name&gt;</div><div class="line">        &lt;value&gt;3072&lt;/value&gt;</div><div class="line">        &lt;/property&gt;</div><div class="line">        &lt;property&gt;</div><div class="line">          &lt;name&gt;mapreduce.map.java.opts&lt;/name&gt;</div><div class="line">            &lt;value&gt;-Xmx3072m&lt;/value&gt;</div><div class="line">            &lt;/property&gt;</div><div class="line">            &lt;property&gt;</div><div class="line">              &lt;name&gt;mapreduce.reduce.java.opts&lt;/name&gt;</div><div class="line">                &lt;value&gt;-Xmx6144m&lt;/value&gt;</div><div class="line">                &lt;/property&gt;</div><div class="line">&lt;property&gt;</div></pre></td></tr></table></figure></p>
<p><code>mapreduce.reduce.java.opts</code>参数大于<code>mapreduce.reduce.memory.mb</code>,需小于才行</p>
<p>在mapreduce执行函数中设置参数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">conf.setInt(&quot;mapreduce.reduce.memory.mb&quot;, 6144);</div></pre></td></tr></table></figure></p>
<p>1.</p>
<p>参考 </p>
<blockquote>
<p><a href="http://stackoverflow.com/questions/21005643/container-is-running-beyond-memory-limits" target="_blank" rel="external">http://stackoverflow.com/questions/21005643/container-is-running-beyond-memory-limits</a></p>
</blockquote>
<p>我们集群中的每台机器都有48 GB的RAM。此RAM的一些应保留为操作系统使用。在每个节点上，我们将为YARN分配40 GB RAM以使用操作系统并保留8 GB</p>
<p>对于我们的示例集群，我们有一个容器的最小RAM（yarn.scheduler.minimum-allocation-mb）= 2 GB。因此，我们将为Map任务容器分配4 GB，为Reduce任务容器分配8 GB。</p>
<p>在mapred-site.xml中：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">mapreduce.map.memory.mb：4096</div><div class="line"></div><div class="line">mapreduce.reduce.memory.mb：8192</div></pre></td></tr></table></figure></p>
<p>每个容器将运行Map和Reduce任务的JVM。 JVM堆大小应设置为低于上面定义的Map和Reduce内存，以使它们在YARN分配的Container内存的边界内。</p>
<p>在mapred-site.xml中：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">mapreduce.map.java.opts：-Xmx3072m</div><div class="line"></div><div class="line">mapreduce.reduce.java.opts：-Xmx6144m</div></pre></td></tr></table></figure></p>
<p>以上设置配置Map和Reduce任务将使用的物理RAM的上限。<br>。</p>
<p>2.</p>
<blockquote>
<p><a href="http://blog.chinaunix.net/uid-25691489-id-5587957.html" target="_blank" rel="external">http://blog.chinaunix.net/uid-25691489-id-5587957.html</a></p>
</blockquote>
<p>大概是job运行超过了map和reduce设置的内存大小，导致任务失败，调整增加了map和reduce的内容，问题排除，一些参数介绍如下：</p>
<p>RM的内存资源配置，主要是通过下面的两个参数进行的（这两个值是Yarn平台特性，应在yarn-site.xml中配置好）：<br>yarn.scheduler.minimum-allocation-mb<br>yarn.scheduler.maximum-allocation-mb<br>说明：单个容器可申请的最小与最大内存，应用在运行申请内存时不能超过最大值，小于最小值则分配最小值，从这个角度看，最小值有点想操作系统中的页。最小值还有另外一种用途，计算一个节点的最大container数目注：这两个值一经设定不能动态改变(此处所说的动态改变是指应用运行时)。</p>
<p>NM的内存资源配置，主要是通过下面两个参数进行的（这两个值是Yarn平台特性，应在yarn-sit.xml中配置） ：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">yarn.nodemanager.resource.memory-mb</div><div class="line">yarn.nodemanager.vmem-pmem-ratio</div></pre></td></tr></table></figure></p>
<p>说明：每个节点可用的最大内存，RM中的两个值不应该超过此值。此数值可以用于计算container最大数目，即：用此值除以RM中的最小容器内存。虚拟内存率，是占task所用内存的百分比，默认值为2.1倍;注意：第一个参数是不可修改的，一旦设置，整个运行过程中不可动态修改，且该值的默认大小是8G，即使计算机内存不足8G也会按着8G内存来使用。</p>
<p>AM内存配置相关参数，此处以MapReduce为例进行说明（这两个值是AM特性，应在mapred-site.xml中配置），如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mapreduce.map.memory.mb</div><div class="line">mapreduce.reduce.memory.mb</div></pre></td></tr></table></figure></p>
<p>说明：这两个参数指定用于MapReduce的两个任务（Map and Reduce task）的内存大小，其值应该在RM中的最大最小container之间。如果没有配置则通过如下简单公式获得：<br>max(MIN_CONTAINER_SIZE, (Total Available RAM) / containers))<br>一般的reduce应该是map的2倍。注：这两个值可以在应用启动时通过参数改变；</p>
<p>AM中其它与内存相关的参数，还有JVM相关的参数，这些参数可以通过，如下选项配置：<br>mapreduce.map.java.opts<br>mapreduce.reduce.java.opts<br>说明：这两个参主要是为需要运行JVM程序（java、scala等）准备的，通过这两个设置可以向JVM中传递参数的，与内存有关的是，-Xmx，-Xms等选项。此数值大小，应该在AM中的map.mb和reduce.mb之间。</p>
<p>我们对上面的内容进行下总结，当配置Yarn内存的时候主要是配置如下三个方面：每个Map和Reduce可用物理内存限制；对于每个任务的JVM对大小的限制；虚拟内存的限制；</p>
<p>下面通过一个具体错误实例，进行内存相关说明，错误如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Container[pid=41884,containerID=container_1405950053048_0016_01_000284] is running beyond virtual memory limits. Current usage: 314.6 MB of 2.9 GB physical memory used; 8.7 GB of 6.2 GB virtual memory used. Killing container.</div></pre></td></tr></table></figure></p>
<p>配置如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">            &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;</div><div class="line">            &lt;value&gt;100000&lt;/value&gt;</div><div class="line">        &lt;/property&gt;</div><div class="line">        &lt;property&gt;</div><div class="line">            &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;</div><div class="line">            &lt;value&gt;10000&lt;/value&gt;</div><div class="line">        &lt;/property&gt;</div><div class="line">        &lt;property&gt;</div><div class="line">            &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;</div><div class="line">            &lt;value&gt;3000&lt;/value&gt;</div><div class="line">        &lt;/property&gt;</div><div class="line">       &lt;property&gt;</div><div class="line">            &lt;name&gt;mapreduce.reduce.memory.mb&lt;/name&gt;</div><div class="line">            &lt;value&gt;2000&lt;/value&gt;</div><div class="line">        &lt;/property&gt;</div></pre></td></tr></table></figure></p>
<p>通过配置我们看到，容器的最小内存和最大内存分别为：3000m和10000m，而reduce设置的默认值小于2000m，map没有设置，所以两个值均为3000m，也就是log中的“2.9 GB physical<br>memory used”。而由于使用了默认虚拟内存率(也就是2.1倍)，所以对于Map Task和Reduce Task总的虚拟内存为都为3000*2.1=6.2G。而应用的虚拟内存超过了这个数值，故报错 。解决办<br>法：在启动Yarn是调节虚拟内存率或者应用运行时调节内存大小。</p>
]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MapReduce </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[mapreduce执行错误Mapper.<init>错误]]></title>
      <url>http://yoursite.com/2016/11/03/mapreduce%E6%89%A7%E8%A1%8C%E9%94%99%E8%AF%AFMapper.init%E9%94%99%E8%AF%AF/</url>
      <content type="html"><![CDATA[<blockquote>
<p>参考<br><a href="http://blog.itpub.net/30066956/viewspace-2107549/" target="_blank" rel="external">http://blog.itpub.net/30066956/viewspace-2107549/</a></p>
</blockquote>
<p>错误详情：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">16/11/02 21:37:26 INFO mapreduce.Job: Task Id : attempt_1476760655616_0574_m_000027_2, Status : FAILED</div><div class="line">Error: java.lang.RuntimeException: java.lang.NoSuchMethodException: com.hdu.recommend.tools.CopyData$QLMapper.&lt;init&gt;()</div><div class="line">	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:131)</div><div class="line">	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:742)</div><div class="line">	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)</div><div class="line">	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)</div><div class="line">	at java.security.AccessController.doPrivileged(Native Method)</div><div class="line">	at javax.security.auth.Subject.doAs(Subject.java:415)</div><div class="line">	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)</div><div class="line">	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)</div><div class="line">Caused by: java.lang.NoSuchMethodException: com.hdu.recommend.tools.CopyData$QLMapper.&lt;init&gt;()</div><div class="line">	at java.lang.Class.getConstructor0(Class.java:2849)</div><div class="line">	at java.lang.Class.getDeclaredConstructor(Class.java:2053)</div><div class="line">	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:125)</div><div class="line">	... 7 more</div></pre></td></tr></table></figure></p>
<a id="more"></a>
<p>解决：<br>注意Mapper 与 Reducer 类写成内部类，一定要加static ！！！！</p>
]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MapReduce </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[eclipse中操作hive错误org.apache.hadoop.security.AccessControlException]]></title>
      <url>http://yoursite.com/2016/11/03/eclipse%E4%B8%AD%E6%93%8D%E4%BD%9Chive%E9%94%99%E8%AF%AForg.apache.hadoop.security.AccessControlException/</url>
      <content type="html"><![CDATA[<p>错误：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">java.sql.SQLException: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask</div><div class="line"></div><div class="line">Job Submission failed with exception &apos;org.apache.hadoop.security.AccessControlException(Permission denied: user=anonymous, access=WRITE, inode=&quot;/user&quot;:hdfs:supergroup:drwxr-xr-x</div></pre></td></tr></table></figure></p>
<p>解决：<br>权限问题<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hadoop fs -chmod -R 777  /</div></pre></td></tr></table></figure></p>
<a id="more"></a>]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Hive </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Git SSH公钥配置]]></title>
      <url>http://yoursite.com/2016/10/28/Git%20SSH%E5%85%AC%E9%92%A5%E9%85%8D%E7%BD%AE/</url>
      <content type="html"><![CDATA[<blockquote>
<p>Coding.net配置</p>
</blockquote>
<h3 id="账户-SSH-公钥"><a href="#账户-SSH-公钥" class="headerlink" title="账户 SSH 公钥"></a>账户 SSH 公钥</h3><p>账户 SSH 公钥是跟用户账户关联的公钥，一旦设置，SSH 就拥有账户下所有项目仓库的读写权限。 设置“账户 SSH 公钥”是开发者使用 SSH 方式访问/修改代码仓库的“前置工作”，分为“获取 SSH 协议地址”、“生成公钥”、“在 Coding.net 添加公钥”三个步骤。<br><a id="more"></a></p>
<h3 id="获取-SSH-协议地址"><a href="#获取-SSH-协议地址" class="headerlink" title="获取 SSH 协议地址"></a>获取 SSH 协议地址</h3><p>在项目的代码页面点击 SSH 切换到 SSH 协议， 获得 clone 地址，形如<code>git@git.coding.net:wzw/leave-a-message.git</code>。 请使用这个地址来访问您的代码仓库。</p>
<h3 id="生成公钥"><a href="#生成公钥" class="headerlink" title="生成公钥"></a>生成公钥</h3><p>Mac/Linux 打开命令行终端, Windows 打开 Git Bash 。 输入<code>ssh-keygen -t rsa -C &quot;username@example.com&quot;</code>,( 注册的邮箱)，接下来点击enter键即可（也可以输入密码）。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">$ssh-keygen -t rsa -b 4096 -C &quot;your_email@example.com&quot;</div><div class="line"># Creates a new ssh key, using the provided email as a label</div><div class="line"># Generating public/private rsa key pair.</div><div class="line">Enter file in which to save the key (/Users/you/.ssh/id_rsa): [Press enter]  // 推荐使用默认地址,如果使用非默认地址可能需要配置 .ssh/config</div><div class="line">成功之后</div><div class="line"></div><div class="line">Your identification has been saved in /Users/you/.ssh/id_rsa.</div><div class="line"># Your public key has been saved in /Users/you/.ssh/id_rsa.pub.</div><div class="line"># The key fingerprint is:</div><div class="line"># 01:0f:f4:3b:ca:85:d6:17:a1:7d:f0:68:9d:f0:a2:db your_email@example.com</div></pre></td></tr></table></figure></p>
<h3 id="在-Coding-net-添加公钥"><a href="#在-Coding-net-添加公钥" class="headerlink" title="在 Coding.net 添加公钥"></a>在 Coding.net 添加公钥</h3><p>本地打开 id_rsa.pub 文件（或执行 $cat id_rsa.pub ），复制其中全部内容，添加到账户“SSH 公钥”页面 中，公钥名称可以随意起名字。<br>完成后点击“添加”，然后输入密码或动态码即可添加完成。</p>
<h3 id="完成后在命令行测试，首次建立链接会要求信任主机"><a href="#完成后在命令行测试，首次建立链接会要求信任主机" class="headerlink" title="完成后在命令行测试，首次建立链接会要求信任主机"></a>完成后在命令行测试，首次建立链接会要求信任主机</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ ssh -T git@git.coding.net // 注意 git.coding.net 接入到 CDN 上所以会解析多个不同的 host ip The authenticity of host ‘git.coding.net (61.146.73.68)’ can not be established. RSA key fingerprint is 98:ab:2b:30:60:00:82:86:bb:85:db:87:22:c4:4f:b1. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added ‘git.coding.net,61.146.73.68’ (RSA) to the list of kn own hosts.</div><div class="line"></div><div class="line">Enter passphrase for key ‘/c/Users/Yuankai/.ssh/id_rsa’: Coding.net Tips : [ Hello Kyle_lyk! You have connected to Coding.net by SSH successfully! ]</div></pre></td></tr></table></figure>
<p>接下来就可以用git操作仓库了，是使用SourceTree非常方便</p>
]]></content>
      
        <categories>
            
            <category> Git </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Git </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[spark-1.6.0安装]]></title>
      <url>http://yoursite.com/2016/10/27/spark-1.6.0%E5%AE%89%E8%A3%85/</url>
      <content type="html"><![CDATA[<blockquote>
<p>已安装Hadoop2.7.2的三节点集群</p>
</blockquote>
<h3 id="安装Scala"><a href="#安装Scala" class="headerlink" title="安装Scala"></a>安装Scala</h3><ol>
<li>下载scala-2.11.7.tgz</li>
<li><p>解压Scala</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ tar -zxvf scala-2.11.7.tgz -C ~/cloud/</div></pre></td></tr></table></figure>
</li>
<li><p>配置环境变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">export  SCALA_HOME=/home/ubuntu/cloud/scala-2.11.7</div><div class="line">export PATH = $PATH:$SCALA_HOME/bin</div></pre></td></tr></table></figure>
</li>
<li><p>测试</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scala -version</div><div class="line">Scala code runner version 2.11.7 -- Copyright 2002-2013, LAMP/EPFL</div></pre></td></tr></table></figure>
</li>
<li><p>配置到每台节点</p>
<a id="more"></a>
<h3 id="安装Spark"><a href="#安装Spark" class="headerlink" title="安装Spark"></a>安装Spark</h3></li>
</ol>
<p>#Spark<br>export SPARK_HOME=/home/ubuntu/cloud/spark-1.6.0<br>export PATH=$PATH:$SPARK_HOME/bin</p>
<p>export JAVA_HOME=/usr/java/jdk1.8.0_91<br>export SPARK_MASTER_IP=10.0.0.7</p>
<p>#export SPARK_WORKER_MEMORY=2g<br>export HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop</p>
<p>slave1<br>slave2</p>
]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[name node is in safe mode问题]]></title>
      <url>http://yoursite.com/2016/10/18/name%20node%20is%20in%20safe%20mode/</url>
      <content type="html"><![CDATA[<h3 id="name-node-is-in-safe-mode"><a href="#name-node-is-in-safe-mode" class="headerlink" title="name node is in safe mode"></a>name node is in safe mode</h3><p>问题： 向hdfs put数据的时候，导致了 name node is in safe mode，然后使用 Hadoop dfsadmin -safemode leave 后， 解除了安全模式。可是再次使用hdfs put或rm数据，仍旧导致name node 进入安全模式。</p>
<p>答案：分析了一下，问题是namenode所在机器的硬盘满了。因此即使使用了 hadoop dfsadmin -safemode leave 之后， 仍旧不能使用hdfs。</p>
<h4 id="解决办法："><a href="#解决办法：" class="headerlink" title="解决办法："></a>解决办法：</h4><ol>
<li>删除namenode所在机器的一些数据（本地数据）</li>
<li>结束安全模式   hadoop dfsadmin -safemode leave </li>
<li>可以正常使用hdfs了</li>
</ol>
]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[LinkedHashMap和TreeMap的区别]]></title>
      <url>http://yoursite.com/2016/10/18/LinkedHashMap%E5%92%8CTreeMap%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
      <content type="html"><![CDATA[<h3 id="LinkedHashMap和TreeMap的区别"><a href="#LinkedHashMap和TreeMap的区别" class="headerlink" title="LinkedHashMap和TreeMap的区别"></a>LinkedHashMap和TreeMap的区别</h3><p>首先2个都是map，所以用key取值肯定是没区别的，区别在于用Iterator遍历的时候<br>LinkedHashMap保存了记录的插入顺序，先插入的先遍历到<br>TreeMap默认是按升序排，也可以指定排序的比较器。遍历的时候按升序遍历。<br>例如：a是LinkedHashMap，b是TreeMap。<br>a.put(“2”,”ab”);<br>a.put(“1”,”bc”);<br>b.put(“2”,”ab”);<br>b.put(“1”,”bc”);</p>
<p>那么遍历a的时候，先遍历到key是2的，因为2先放进去。<br>遍历b的时候，先遍历到“1”，因为按顺序是先1后2</p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[HDUACM1200]]></title>
      <url>http://yoursite.com/2016/09/21/HDUACM1200/</url>
      <content type="html"><![CDATA[<h3 id="题目："><a href="#题目：" class="headerlink" title="题目："></a>题目：</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div></pre></td><td class="code"><pre><div class="line">To and Fro</div><div class="line"></div><div class="line">Time Limit: 2000/1000 MS (Java/Others)    Memory Limit: 65536/32768 K (Java/Others)</div><div class="line">Total Submission(s): 6390    Accepted Submission(s): 4389</div><div class="line"></div><div class="line"></div><div class="line">Problem Description</div><div class="line">Mo and Larry have devised a way of encrypting messages. They first decide secretly on the number of columns and write the message (letters only) down the columns, padding with extra random letters so as to make a rectangular array of letters. For example, if the message is “There’s no place like home on a snowy night” and there are five columns, Mo would write down</div><div class="line"></div><div class="line">t o i o y</div><div class="line">h p k n n</div><div class="line">e l e a i</div><div class="line">r a h s g</div><div class="line">e c o n h</div><div class="line">s e m o t</div><div class="line">n l e w x</div><div class="line"></div><div class="line"></div><div class="line">Note that Mo includes only letters and writes them all in lower case. In this example, Mo used the character ‘x’ to pad the message out to make a rectangle, although he could have used any letter.</div><div class="line"></div><div class="line">Mo then sends the message to Larry by writing the letters in each row, alternating left-to-right and right-to-left. So, the above would be encrypted as</div><div class="line"></div><div class="line">toioynnkpheleaigshareconhtomesnlewx</div><div class="line"></div><div class="line">Your job is to recover for Larry the original message (along with any extra padding letters) from the encrypted one.</div><div class="line"> </div><div class="line"></div><div class="line">Input</div><div class="line">There will be multiple input sets. Input for each set will consist of two lines. The first line will contain an integer in the range 2. . . 20 indicating the number of columns used. The next line is a string of up to 200 lower case letters. The last input set is followed by a line containing a single 0, indicating end of input.</div><div class="line"> </div><div class="line"></div><div class="line">Output</div><div class="line">Each input set should generate one line of output, giving the original plaintext message, with no spaces.</div><div class="line"> </div><div class="line"></div><div class="line">Sample Input</div><div class="line">5</div><div class="line">toioynnkpheleaigshareconhtomesnlewx</div><div class="line">3</div><div class="line">ttyohhieneesiaabss</div><div class="line">0</div><div class="line"> </div><div class="line"></div><div class="line">Sample Output</div><div class="line">theresnoplacelikehomeonasnowynightx</div><div class="line">thisistheeasyoneab</div><div class="line"> </div><div class="line"></div><div class="line">Source</div><div class="line">East Central North America 2004</div><div class="line"> </div><div class="line"></div><div class="line">Recommend</div><div class="line">Ignatius.L   |   We have carefully selected several similar problems for you:  1196 1073 1161 1113 1256</div></pre></td></tr></table></figure>
<h3 id="解答："><a href="#解答：" class="headerlink" title="解答："></a>解答：</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div></pre></td><td class="code"><pre><div class="line">package hdu;</div><div class="line"></div><div class="line">import java.util.Scanner;</div><div class="line">/**</div><div class="line"> * 做的时候没看清楚  直接把蛇形输出做了正序的转换，然后才进行二维数组存储，多了个步骤</div><div class="line"> * @author Skye</div><div class="line"> *</div><div class="line"> */</div><div class="line">public class Main &#123;</div><div class="line"></div><div class="line">	public static void main(String[] args) &#123;</div><div class="line">		// TODO Auto-generated method stub</div><div class="line"></div><div class="line">		Scanner sc = new Scanner(System.in);</div><div class="line">		int col = sc.nextInt();</div><div class="line">		String message = null;</div><div class="line">		int rowNum,row = 0;</div><div class="line">		StringBuffer result = new StringBuffer();</div><div class="line">		char[] stringArr = null;</div><div class="line">		StringBuffer tmpString = new StringBuffer();</div><div class="line">		char[] tmpChar = null;</div><div class="line">		boolean isChange = false;</div><div class="line">		while (col != 0) &#123;</div><div class="line">			message = sc.next();</div><div class="line">			rowNum = message.length()/col;</div><div class="line">			// System.out.println(message);</div><div class="line">			stringArr = message.toCharArray();</div><div class="line">			// ttyohhieneesiaabss</div><div class="line">			for (int i = 0; i &lt; stringArr.length; i++) &#123;</div><div class="line">				// System.out.println(stringArr[i]);</div><div class="line">				if (i % col == 0) &#123; // 到行开头</div><div class="line">					row = i / col + 1; // 记录当前字母在第几行</div><div class="line">					if (row % 2 == 0) &#123;</div><div class="line">						isChange = true;</div><div class="line">					&#125; else &#123;</div><div class="line">						isChange = false;</div><div class="line">					&#125;</div><div class="line">				&#125;</div><div class="line"></div><div class="line">				if (isChange == false) &#123;</div><div class="line">					</div><div class="line">					if (i != 0 &amp;&amp; i % col == 0) &#123;</div><div class="line">						//System.out.println(tmpString.toString());</div><div class="line">						tmpChar = tmpString.toString().toCharArray();</div><div class="line">						for (int j = tmpChar.length - 1; j &gt;= 0; j--) &#123;</div><div class="line">							result.append(tmpChar[j]);</div><div class="line">						&#125;</div><div class="line">						tmpString = new StringBuffer();</div><div class="line">					&#125;</div><div class="line">					result.append(stringArr[i]);</div><div class="line">				&#125; else &#123;</div><div class="line">					tmpString.append(stringArr[i]);</div><div class="line">				&#125;</div><div class="line"></div><div class="line">			&#125;</div><div class="line">			if(isChange == true)&#123;</div><div class="line">				//System.out.println(tmpString.toString());</div><div class="line">				tmpChar = tmpString.toString().toCharArray();</div><div class="line">				for (int j = tmpChar.length - 1; j &gt;= 0; j--) &#123;</div><div class="line">					result.append(tmpChar[j]);</div><div class="line">				&#125;</div><div class="line">				tmpString = new StringBuffer();</div><div class="line">			&#125;</div><div class="line">			//System.out.println(result);</div><div class="line">			</div><div class="line">			char[][] charArr = new char[rowNum][col];</div><div class="line">			char[] resultChar = result.toString().toCharArray();</div><div class="line">			int count = 0;</div><div class="line">			for(int k = 0; k &lt; rowNum;k++)&#123;</div><div class="line">				for(int p = 0; p &lt; col;p++)&#123;</div><div class="line">					charArr[k][p] = resultChar[count++];</div><div class="line">				&#125;</div><div class="line">			&#125;</div><div class="line">			StringBuffer resultFinal = new StringBuffer();</div><div class="line">			for(int k = 0; k &lt; col;k++)&#123;</div><div class="line">				for(int p = 0; p &lt; rowNum;p++)&#123;</div><div class="line">					resultFinal.append(charArr[p][k]);</div><div class="line">				&#125;</div><div class="line">			&#125;</div><div class="line">			System.out.println(resultFinal);</div><div class="line">			resultFinal = new StringBuffer();</div><div class="line">			result = new StringBuffer();</div><div class="line">			col = sc.nextInt();</div><div class="line">		&#125;</div><div class="line">		sc.close();</div><div class="line">	&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="HDU另解："><a href="#HDU另解：" class="headerlink" title="HDU另解："></a>HDU另解：</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line">import java.io.*;</div><div class="line">import java.util.*;</div><div class="line"></div><div class="line">public class Main</div><div class="line">&#123;</div><div class="line"></div><div class="line">	public static void main(String[] args)</div><div class="line">	&#123;</div><div class="line">		Scanner input = new Scanner(System.in);</div><div class="line">		while (input.hasNext())</div><div class="line">		&#123;</div><div class="line">			int n = input.nextInt();</div><div class="line">			if(n==0) break;</div><div class="line">			input.nextLine();</div><div class="line">			String str = input.nextLine();</div><div class="line">			char c1[] = str.toCharArray();                   // 把每个字符单个存起来</div><div class="line">			char c2[][] = new char[1010][1010];</div><div class="line">			int line = c1.length / n;                        //记录行数</div><div class="line">			int k = 0;                                      // 记录c1字符的位数</div><div class="line">			for (int i = 0; i &lt; line; i++)</div><div class="line">			&#123;</div><div class="line">				if (i % 2 == 1)</div><div class="line">				&#123;</div><div class="line">					for (int j = n - 1; j &gt;= 0; j--)</div><div class="line">					&#123;</div><div class="line">						c2[i][j] = c1[k++];</div><div class="line">					&#125;</div><div class="line">				&#125; </div><div class="line">				else</div><div class="line">				&#123;</div><div class="line">					for (int j = 0; j &lt; n; j++)</div><div class="line">					&#123;</div><div class="line">						c2[i][j] = c1[k++];</div><div class="line">					&#125;</div><div class="line">				&#125;</div><div class="line">			&#125;</div><div class="line"></div><div class="line">			for (int j = 0; j &lt; n; j++)</div><div class="line">			&#123;</div><div class="line">				for (int i = 0; i &lt; line; i++)</div><div class="line">				&#123;</div><div class="line">					System.out.print(c2[i][j]);</div><div class="line">				&#125;</div><div class="line">			&#125;</div><div class="line">			System.out.println();</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>]]></content>
      
        <categories>
            
            <category> ACM </category>
            
        </categories>
        
        
        <tags>
            
            <tag> ACM </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Java Map 按key排序和按Value排序]]></title>
      <url>http://yoursite.com/2016/08/31/Java%20Map%20%E6%8C%89key%E6%8E%92%E5%BA%8F%E5%92%8C%E6%8C%89Value%E6%8E%92%E5%BA%8F/</url>
      <content type="html"><![CDATA[<p>做推荐系统项目时，对标签评分需要对标签评分map进行排序.</p>
<h3 id="理论准备"><a href="#理论准备" class="headerlink" title="理论准备"></a>理论准备</h3><ul>
<li><p>Map是键值对的集合接口，它的实现类主要包括：HashMap,TreeMap,Hashtable以及LinkedHashMap等。</p>
</li>
<li><p>TreeMap：基于红黑树（Red-Black tree）的 NavigableMap 实现，该映射根据其键的自然顺序进行排序，或者根据创建映射时提供的 Comparator 进行排序，具体取决于使用的构造方法。<br>HashMap的值是没有顺序的，它是按照key的HashCode来实现的，对于这个无序的HashMap我们要怎么来实现排序呢？参照TreeMap的value排序。</p>
</li>
<li><p>Map.Entry返回Collections视图。</p>
</li>
</ul>
<h3 id="key排序"><a href="#key排序" class="headerlink" title="key排序"></a>key排序</h3><p>TreeMap默认是升序的，如果我们需要改变排序方式，则需要使用比较器：Comparator。Comparator可以对集合对象或者数组进行排序的比较器接口，实现该接口的public compare(T o1,To2)方法即可实现排序，如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">import java.util.Comparator;</div><div class="line">import java.util.Iterator;</div><div class="line">import java.util.Map;</div><div class="line">import java.util.Set;</div><div class="line">import java.util.TreeMap;</div><div class="line">public class TreeMapTest &#123;</div><div class="line">    public static void main(String[] args) &#123;</div><div class="line">        Map&lt;String, String&gt; map = new TreeMap&lt;String, String&gt;(</div><div class="line">                new Comparator&lt;String&gt;() &#123;</div><div class="line">                    public int compare(String obj1, String obj2) &#123;</div><div class="line">                        // 降序排序</div><div class="line">                        return obj2.compareTo(obj1);</div><div class="line">                    &#125;</div><div class="line">                &#125;);</div><div class="line">        map.put(&quot;b&quot;, &quot;ccccc&quot;);</div><div class="line">        map.put(&quot;d&quot;, &quot;aaaaa&quot;);</div><div class="line">        map.put(&quot;c&quot;, &quot;bbbbb&quot;);</div><div class="line">        map.put(&quot;a&quot;, &quot;ddddd&quot;);</div><div class="line">        </div><div class="line">        Set&lt;String&gt; keySet = map.keySet();</div><div class="line">        Iterator&lt;String&gt; iter = keySet.iterator();</div><div class="line">        while (iter.hasNext()) &#123;</div><div class="line">            String key = iter.next();</div><div class="line">            System.out.println(key + &quot;:&quot; + map.get(key));</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>运行如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">d:aaaaa</div><div class="line">c:bbbbb</div><div class="line">b:ccccc</div><div class="line">a:ddddd</div></pre></td></tr></table></figure></p>
<h3 id="value排序"><a href="#value排序" class="headerlink" title="value排序"></a>value排序</h3><p>上面例子是对根据TreeMap的key值来进行排序的，但是有时我们需要根据TreeMap的value来进行排序。对value排序我们就需要借助于Collections的sort(List<t> list, Comparator&lt;? super T&gt; c)方法，该方法根据指定比较器产生的顺序对指定列表进行排序。但是有一个前提条件，那就是所有的元素都必须能够根据所提供的比较器来进行比较，如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">import java.util.ArrayList;</div><div class="line">import java.util.Collections;</div><div class="line">import java.util.Comparator;</div><div class="line">import java.util.List;</div><div class="line">import java.util.Map;</div><div class="line">import java.util.Map.Entry;</div><div class="line">import java.util.TreeMap;</div><div class="line">public class TreeMapTest &#123;</div><div class="line">    public static void main(String[] args) &#123;</div><div class="line">        Map&lt;String, String&gt; map = new TreeMap&lt;String, String&gt;();</div><div class="line">        map.put(&quot;a&quot;, &quot;ddddd&quot;);</div><div class="line">        map.put(&quot;c&quot;, &quot;bbbbb&quot;);</div><div class="line">        map.put(&quot;d&quot;, &quot;aaaaa&quot;);</div><div class="line">        map.put(&quot;b&quot;, &quot;ccccc&quot;);</div><div class="line">        </div><div class="line">        //这里将map.entrySet()转换成list</div><div class="line">        List&lt;Map.Entry&lt;String,String&gt;&gt; list = new ArrayList&lt;Map.Entry&lt;String,String&gt;&gt;(map.entrySet());</div><div class="line">        //然后通过比较器来实现排序</div><div class="line">        Collections.sort(list,new Comparator&lt;Map.Entry&lt;String,String&gt;&gt;() &#123;</div><div class="line">            //升序排序</div><div class="line">            public int compare(Entry&lt;String, String&gt; o1,</div><div class="line">                    Entry&lt;String, String&gt; o2) &#123;</div><div class="line">                return o1.getValue().compareTo(o2.getValue());</div><div class="line">            &#125;</div><div class="line">            </div><div class="line">        &#125;);</div><div class="line">        </div><div class="line">        for(Map.Entry&lt;String,String&gt; mapping:list)&#123; </div><div class="line">               System.out.println(mapping.getKey()+&quot;:&quot;+mapping.getValue()); </div><div class="line">          &#125; </div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></t></p>
<p>运行结果如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">d:aaaaa</div><div class="line">c:bbbbb</div><div class="line">b:ccccc</div><div class="line">a:ddddd</div></pre></td></tr></table></figure></p>
<blockquote>
<p>参考：<a href="http://blog.csdn.net/xiaoyu714543065/article/details/38519817" target="_blank" rel="external">http://blog.csdn.net/xiaoyu714543065/article/details/38519817</a></p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Java BufferdReader读取文件乱码]]></title>
      <url>http://yoursite.com/2016/08/29/Java%20BufferdReader%E8%AF%BB%E5%8F%96%E6%96%87%E4%BB%B6%E4%B9%B1%E7%A0%81/</url>
      <content type="html"><![CDATA[<h3 id="javaBufferdReader读取文件乱码"><a href="#javaBufferdReader读取文件乱码" class="headerlink" title="javaBufferdReader读取文件乱码"></a>javaBufferdReader读取文件乱码</h3><p>以下为读取文件方法</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">private static void putIdGame()&#123;</div><div class="line">	</div><div class="line">	URL.setURLStreamHandlerFactory(new FsUrlStreamHandlerFactory());</div><div class="line">	int count = 0;</div><div class="line">	try &#123;</div><div class="line"></div><div class="line">		</div><div class="line">		URL url = new URL(HDFS + path);</div><div class="line">		InputStream gameList = url.openStream();</div><div class="line">		BufferedReader reader_url = new BufferedReader(new InputStreamReader(gameList,&quot;UTF-8&quot;));</div><div class="line">		String inString_RL = reader_url.readLine();</div><div class="line">		</div><div class="line">		while (inString_RL != null &amp;&amp; count &lt; 50) &#123;</div><div class="line">			int userId;</div><div class="line">			String[] str = inString_RL.split(&quot;,&quot;); </div><div class="line">			count ++;</div><div class="line">			map.put(str[1], str[0]);</div><div class="line">			System.out.println(str[0]);</div><div class="line">			inString_RL = reader_url.readLine();</div><div class="line">		&#125;</div><div class="line">		reader_url.close();</div><div class="line">	&#125; catch (FileNotFoundException e) &#123;</div><div class="line">		System.out.println(&quot;未找文件！&quot;);</div><div class="line">	&#125; catch (IOException e1) &#123;</div><div class="line">		System.out.println(&quot;文件读写错误！&quot;);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在<code>InputStreamReader</code>中加入”UTF-8”即可</p>
<h3 id="Java读取文件时第一行出现乱码“？”问号"><a href="#Java读取文件时第一行出现乱码“？”问号" class="headerlink" title="Java读取文件时第一行出现乱码“？”问号"></a>Java读取文件时第一行出现乱码“？”问号</h3><p>在windows 环境下，使用java文件流读取文本文件时，会出现第一个字符为未知字符”?” ,其他字符完整。而且第一个字符显示为？但是用equals比对发现并非是”?”号,google之，了解到bom编码标记。使用 16进制打印输出结果：</p>
<p>只要出现该头的16进制编码为这种字符便可以断定该文本文件的编码方式了。</p>
<p>bom编码标记：</p>
<p>bom全称是：byte order mark，汉语意思是标记字节顺序码。只是出现在：unicode字符集中，只有unicode字符集，存储时候，要求指定编码，如果不指定，windows还会用默认的：ANSI读取。常见的bom头是：</p>
<p>  UTF-8 ║ EF BB BF<br>  UTF-16LE ║ FF FE (小尾）<br>  UTF-16BE ║ FE FF （大尾）<br>  UTF-32LE ║ FF FE 00 00<br>  UTF-32BE ║ 00 00 FE FF</p>
<h4 id="解决方法："><a href="#解决方法：" class="headerlink" title="解决方法："></a>解决方法：</h4><ol>
<li><p>工具将txt文件另存为UTF-8无BOM格式</p>
</li>
<li></li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">public String readerFile(InputStream in) throws IOException &#123;</div><div class="line">		StringBuffer strBuff = new StringBuffer();</div><div class="line">		String temp = null;</div><div class="line">		BufferedReader reader = new BufferedReader(new InputStreamReader(in,Charset.forName(&quot;utf-8&quot;)));</div><div class="line">		while ((temp = reader.readLine()) != null) &#123;</div><div class="line">			byte[] by = temp.getBytes();</div><div class="line">			String header = Integer.toHexString(by[0]).toUpperCase();</div><div class="line">			//判断是否拥有无法识别的字符</div><div class="line">			if (header.equalsIgnoreCase(&quot;FFFFFFEF&quot;) || header.equalsIgnoreCase(&quot;3F&quot;)) &#123;</div><div class="line">				strBuff.append(temp.substring(1) + &quot;\n&quot;);</div><div class="line">				continue;</div><div class="line">			&#125;</div><div class="line">			strBuff.append(temp + &quot;\n&quot;);</div><div class="line">		&#125;</div><div class="line">		reader.close();</div><div class="line">		in.close();</div><div class="line">		return strBuff.toString();</div><div class="line">	&#125;</div></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[HDFS工具类]]></title>
      <url>http://yoursite.com/2016/08/26/HDFS%E5%B7%A5%E5%85%B7%E7%B1%BB/</url>
      <content type="html"><![CDATA[<p>花了点时间整理了验证一下在本地eclipse上操作HDFS的工具类，实现在本地通过API操作HDFS。</p>
<p>实现以下功能：</p>
<ul>
<li>ls </li>
<li>rmr</li>
<li>mkdir</li>
<li>copyFromLocal</li>
<li>cat</li>
<li>copyToLocal</li>
<li>创建一个新文件，并写入内容</li>
</ul>
<p>主要引用参考：</p>
<blockquote>
<p><a href="http://blog.fens.me/hadoop-hdfs-api/" target="_blank" rel="external">http://blog.fens.me/hadoop-hdfs-api/</a></p>
</blockquote>
<p>类如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div></pre></td><td class="code"><pre><div class="line">package com.hdu.hdfs;</div><div class="line"></div><div class="line">import java.io.IOException;</div><div class="line">import java.net.URI;</div><div class="line"></div><div class="line">import org.apache.hadoop.conf.Configuration;</div><div class="line">import org.apache.hadoop.fs.BlockLocation;</div><div class="line">import org.apache.hadoop.fs.FSDataInputStream;</div><div class="line">import org.apache.hadoop.fs.FSDataOutputStream;</div><div class="line">import org.apache.hadoop.fs.FileStatus;</div><div class="line">import org.apache.hadoop.fs.FileSystem;</div><div class="line">import org.apache.hadoop.fs.Hdfs;</div><div class="line">import org.apache.hadoop.fs.Path;</div><div class="line">import org.apache.hadoop.hdfs.web.HsftpFileSystem;</div><div class="line">import org.apache.hadoop.io.IOUtils;</div><div class="line">import org.apache.hadoop.mapred.JobConf;</div><div class="line"></div><div class="line">/**</div><div class="line"> * HDFS工具类</div><div class="line"> * </div><div class="line"> * 实现功能：</div><div class="line"> * hadoop fs -ls / </div><div class="line"> * hadoop fs -mkdir /data </div><div class="line"> * hadoop fs -rmr /data/test.txt</div><div class="line"> * hadoop fs -copyFromLocal /test/test.txt /data </div><div class="line"> * hadoop fs -cat /data/test.txt</div><div class="line"> * hadoop fs -copyToLocal /data /test/test.txt </div><div class="line"> * 创建一个新文件，并写入内容  </div><div class="line"> * 重命名</div><div class="line"> * </div><div class="line"> * 需要导入以下路径的所有jar包： hadoop-2.7.2\share\hadoop\common</div><div class="line"> * hadoop-2.7.2\share\hadoop\common\lib hadoop-2.7.2\share\hadoop\hdfs</div><div class="line"> * hadoop-2.7.2\share\hadoop\hdfs\lib hadoop-2.7.2\share\hadoop\mapreduce</div><div class="line"> * </div><div class="line"> * </div><div class="line"> * @author Skye</div><div class="line"> *</div><div class="line"> */</div><div class="line">public class HdfsDAO &#123;</div><div class="line"></div><div class="line">	// HDFS访问地址</div><div class="line">	private static final String HDFS = &quot;hdfs://192.168.1.111:9000/&quot;;</div><div class="line">	// hdfs路径</div><div class="line">	private String hdfsPath;</div><div class="line">	// Hadoop系统配置</div><div class="line">	private Configuration conf;</div><div class="line"></div><div class="line">	public HdfsDAO(Configuration conf) &#123;</div><div class="line">		this(HDFS, conf);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public HdfsDAO(String hdfs, Configuration conf) &#123;</div><div class="line">		this.hdfsPath = hdfs;</div><div class="line">		this.conf = conf;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	// 启动函数</div><div class="line">	public static void main(String[] args) throws IOException &#123;</div><div class="line">		JobConf conf = config();</div><div class="line">		HdfsDAO hdfs = new HdfsDAO(conf);</div><div class="line">		// hdfs.mkdirs(&quot;/new&quot;);</div><div class="line">		// 可以同时建多级目录</div><div class="line">		// hdfs.mkdirs(&quot;/new/new3&quot;);</div><div class="line">		// hdfs.ls(&quot;/tuijian&quot;);</div><div class="line">		// hdfs.rmr(&quot;/new&quot;);</div><div class="line">		// 可用当前eclipse工作空间的相对路径和文件绝对路径 以及当前项目的路径不加&quot;/&quot;</div><div class="line">		// hdfs.copyFileToHdfs(&quot;data/hive笔记.md&quot;, &quot;/data&quot;);</div><div class="line">		// hdfs.copyFileToHdfs(&quot;/Xiaomi/MiFlashClean.cmd&quot;, &quot;/data&quot;);</div><div class="line">		// hdfs.copyFileToHdfs(&quot;E:/推荐系统/100万用户数据/user_pay&quot;, &quot;/data&quot;);</div><div class="line">		// hdfs.rmr(&quot;/data/MiFlashClean.cmd&quot;);</div><div class="line">		// hdfs.rmr(&quot;/data/user_pay_201606&quot;);</div><div class="line">		// hdfs.createFile(&quot;/new/createTest&quot;, &quot;1,英雄联盟&quot;);</div><div class="line">		// hdfs.download(&quot;/data/RecommendList&quot;, &quot;C:/Users/Skye/Desktop&quot;);</div><div class="line">		// hdfs.cat(&quot;/data/RecommendList1&quot;);</div><div class="line">		// hdfs.renameFile(&quot;/data/RecommendList&quot;, &quot;/data/RecommendListOld&quot;);</div><div class="line">		// hdfs.ls(&quot;/data&quot;);</div><div class="line">		//hdfs.findLocationOnHadoop(&quot;/data/RecommendListOld&quot;);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	// 加载Hadoop配置文件</div><div class="line">	public static JobConf config() &#123;</div><div class="line">		JobConf conf = new JobConf(HdfsDAO.class);</div><div class="line">		conf.setJobName(&quot;HdfsDAO&quot;);</div><div class="line">		// conf.addResource(&quot;classpath:/hadoop/core-site.xml&quot;);</div><div class="line">		// conf.addResource(&quot;classpath:/hadoop/hdfs-site.xml&quot;);</div><div class="line">		// conf.addResource(&quot;classpath:/hadoop/mapred-site.xml&quot;);</div><div class="line">		return conf;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public void mkdirs(String folder) throws IOException &#123;</div><div class="line">		Path path = new Path(folder);</div><div class="line">		FileSystem fs = FileSystem.get(URI.create(hdfsPath), conf);</div><div class="line">		if (!fs.exists(path)) &#123;</div><div class="line">			fs.mkdirs(path);</div><div class="line">			System.out.println(&quot;Create: &quot; + folder);</div><div class="line">		&#125;</div><div class="line">		fs.close();</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public void rmr(String folder) throws IOException &#123;</div><div class="line">		Path path = new Path(folder);</div><div class="line">		FileSystem fs = FileSystem.get(URI.create(hdfsPath), conf);</div><div class="line">		fs.deleteOnExit(path);</div><div class="line">		System.out.println(&quot;Delete: &quot; + folder);</div><div class="line">		fs.close();</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public void ls(String folder) throws IOException &#123;</div><div class="line">		Path path = new Path(folder);</div><div class="line">		FileSystem fs = FileSystem.get(URI.create(hdfsPath), conf);</div><div class="line">		FileStatus[] list = fs.listStatus(path);</div><div class="line">		System.out.println(&quot;ls: &quot; + folder);</div><div class="line">		System.out.println(&quot;==========================================================&quot;);</div><div class="line">		for (FileStatus f : list) &#123;</div><div class="line">			System.out.printf(&quot;name: %s, folder: %s, size: %d\n&quot;, f.getPath(), f.isDir(), f.getLen());</div><div class="line">		&#125;</div><div class="line">		System.out.println(&quot;==========================================================&quot;);</div><div class="line">		fs.close();</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public void createFile(String file, String content) throws IOException &#123;</div><div class="line">		FileSystem fs = FileSystem.get(URI.create(hdfsPath), conf);</div><div class="line">		byte[] buff = content.getBytes();</div><div class="line">		FSDataOutputStream os = null;</div><div class="line">		try &#123;</div><div class="line">			os = fs.create(new Path(file));</div><div class="line">			os.write(buff, 0, buff.length);</div><div class="line">			System.out.println(&quot;Create: &quot; + file);</div><div class="line">		&#125; finally &#123;</div><div class="line">			if (os != null)</div><div class="line">				os.close();</div><div class="line">		&#125;</div><div class="line">		fs.close();</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public void copyFileToHdfs(String local, String remote) throws IOException &#123;</div><div class="line">		FileSystem fs = FileSystem.get(URI.create(hdfsPath), conf);</div><div class="line">		fs.copyFromLocalFile(new Path(local), new Path(remote));</div><div class="line">		System.out.println(&quot;copy from: &quot; + local + &quot; to &quot; + remote);</div><div class="line">		fs.close();</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public void download(String remote, String local) throws IOException &#123;</div><div class="line">		Path path = new Path(remote);</div><div class="line">		FileSystem fs = FileSystem.get(URI.create(hdfsPath), conf);</div><div class="line">		fs.copyToLocalFile(path, new Path(local));</div><div class="line">		System.out.println(&quot;download: from&quot; + remote + &quot; to &quot; + local);</div><div class="line">		fs.close();</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public void renameFile(String oldFileName, String newFileName) throws IOException &#123;</div><div class="line">		boolean isSuccess = true;</div><div class="line"></div><div class="line">		FileSystem fs = FileSystem.get(URI.create(hdfsPath), conf);</div><div class="line">		try &#123;</div><div class="line">			isSuccess = fs.rename(new Path(oldFileName), new Path(newFileName));</div><div class="line">		&#125; catch (IOException e) &#123;</div><div class="line">			isSuccess = false;</div><div class="line">		&#125;</div><div class="line">		System.out.println(isSuccess ? &quot;Rename success！ &quot; + oldFileName + &quot; to &quot; + newFileName</div><div class="line">				: &quot;Rename failed！&quot; + oldFileName + &quot; to &quot; + newFileName);</div><div class="line">		fs.close();</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	/**</div><div class="line">	 * 查看某个文件在HDFS集群的位置</div><div class="line">	 * </div><div class="line">	 * @throws IOException</div><div class="line">	 */</div><div class="line"></div><div class="line">	public void findLocationOnHadoop(String filePath) throws IOException &#123;</div><div class="line">		// Path targetFile=new Path(rootPath+&quot;user/hdfsupload/AA.txt&quot;);</div><div class="line">		// FileStatus fileStaus=coreSys.getFileStatus(targetFile);</div><div class="line">		Path targetFile = new Path(HDFS + filePath);</div><div class="line">		FileSystem fs = FileSystem.get(URI.create(hdfsPath), conf);</div><div class="line">		FileStatus fileStaus = fs.getFileStatus(targetFile);</div><div class="line">		BlockLocation[] bloLocations = fs.getFileBlockLocations(fileStaus, 0, fileStaus.getLen());</div><div class="line">		for (int i = 0; i &lt; bloLocations.length; i++) &#123;</div><div class="line">			System.out.println(&quot;block_&quot; + i + &quot;_location:&quot; + bloLocations[i].getHosts()[0]);</div><div class="line">		&#125;</div><div class="line">		fs.close();</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public void cat(String remoteFile) throws IOException &#123;</div><div class="line">		Path path = new Path(remoteFile);</div><div class="line">		FileSystem fs = FileSystem.get(URI.create(hdfsPath), conf);</div><div class="line">		FSDataInputStream fsdis = null;</div><div class="line">		System.out.println(&quot;cat: &quot; + remoteFile);</div><div class="line">		try &#123;</div><div class="line">			fsdis = fs.open(path);</div><div class="line">			IOUtils.copyBytes(fsdis, System.out, 4096, false);</div><div class="line">		&#125; finally &#123;</div><div class="line">			IOUtils.closeStream(fsdis);</div><div class="line">			fs.close();</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hive1.2.1安装笔记]]></title>
      <url>http://yoursite.com/2016/08/22/Hive%E5%AE%89%E8%A3%85%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">ubuntu 16.04</div><div class="line">4台机器的Hadoop2.7.2集群</div><div class="line">Mysql安装在slave2中</div><div class="line">hive安装在master上</div></pre></td></tr></table></figure>
<h3 id="下载Hive"><a href="#下载Hive" class="headerlink" title="下载Hive"></a>下载Hive</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ wget http://mirrors.cnnic.cn/apache/hive/hive-1.2.1/apache-hive-1.2.1-bin.tar.gz</div><div class="line"># 解压</div><div class="line">$ tar -zxvf apache-hive-1.2.1-bin.tar.gz /home/ubuntu/cloud</div></pre></td></tr></table></figure>
<h3 id="配置Hive环境变量"><a href="#配置Hive环境变量" class="headerlink" title="配置Hive环境变量"></a>配置Hive环境变量</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">$ sudo vim /etc/profile</div><div class="line"></div><div class="line">#添加</div><div class="line">export HIVE_HOME=/home/ubuntu/cloud/apache-hive-1.2.1-bin</div><div class="line">export PATH=$PATH:$HIVE_HOME/bin</div><div class="line"></div><div class="line">$source /etc/profile</div></pre></td></tr></table></figure>
<h3 id="在Mysql中创建Hive用户"><a href="#在Mysql中创建Hive用户" class="headerlink" title="在Mysql中创建Hive用户"></a>在Mysql中创建Hive用户</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">mysql&gt;CREATE USER &apos;hive&apos; IDENTIFIED BY &apos;hive&apos;;</div><div class="line">mysql&gt;GRANT ALL PRIVILEGES ON *.* TO &apos;hive&apos;@&apos;%&apos; IDENTIFIED BY &apos;hive&apos; WITH GRANT OPTION;</div><div class="line">mysql&gt;flush privileges;</div></pre></td></tr></table></figure>
<h3 id="创建Hive数据库"><a href="#创建Hive数据库" class="headerlink" title="创建Hive数据库"></a>创建Hive数据库</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ mysql -uhive -phive</div><div class="line">mysql&gt;create database hive;</div></pre></td></tr></table></figure>
<h3 id="配置Hive"><a href="#配置Hive" class="headerlink" title="配置Hive"></a>配置Hive</h3><p>进入Hive的conf目录,找到<code>hive-default.xml.template</code>，cp份为<code>hive-site.xml</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">$ vim hive-site.xml</div><div class="line"># 删除configuration标签里的所有内容 添加如下内容</div><div class="line"></div><div class="line">	&lt;property&gt;</div><div class="line">        &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</div><div class="line">        &lt;value&gt;jdbc:mysql://slave2:3306/hive?createDatabaseIfNotExist=true&lt;/value&gt;</div><div class="line">        &lt;description&gt;JDBC connect string for a JDBC metastore&lt;/description&gt;    </div><div class="line">	&lt;/property&gt;   </div><div class="line">	&lt;property&gt; </div><div class="line">        &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; </div><div class="line">        &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt; </div><div class="line">        &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;     </div><div class="line">	&lt;/property&gt;               </div><div class="line"> </div><div class="line">	&lt;property&gt; </div><div class="line">        &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</div><div class="line">        &lt;value&gt;hive&lt;/value&gt;</div><div class="line">        &lt;description&gt;username to use against metastore database&lt;/description&gt;</div><div class="line">	&lt;/property&gt;</div><div class="line">	&lt;property&gt;  </div><div class="line">        &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</div><div class="line">        &lt;value&gt;hive&lt;/value&gt;</div><div class="line">        &lt;description&gt;password to use against metastore database&lt;/description&gt;  </div><div class="line">	&lt;/property&gt;</div></pre></td></tr></table></figure></p>
<h3 id="下载mysql-connector-java-5-1-32-bin-jar"><a href="#下载mysql-connector-java-5-1-32-bin-jar" class="headerlink" title="下载mysql-connector-java-5.1.32-bin.jar"></a>下载mysql-connector-java-5.1.32-bin.jar</h3><p>这里用5.1.32版本测试不报错，5.1.38会报warn</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">#将连接jar包拷贝到Hive的lib目录</div><div class="line">$ cp mysql-connector-java-5.1.32-bin.jar /home/ubuntu/cloud/apache-hive-1.2.1-bin/lib/</div></pre></td></tr></table></figure>
<h3 id="若要装hive客户端可在客户端节点设置"><a href="#若要装hive客户端可在客户端节点设置" class="headerlink" title="若要装hive客户端可在客户端节点设置"></a>若要装hive客户端可在客户端节点设置</h3><p><code>vim hive-site.xml</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line"></div><div class="line">&lt;!-- thrift://&lt;host_name&gt;:&lt;port&gt; 默认端口是9083 --&gt;</div><div class="line">&lt;property&gt;</div><div class="line">&lt;name&gt;hive.metastore.uris&lt;/name&gt;</div><div class="line">  &lt;value&gt;thrift://master:9083&lt;/value&gt;</div><div class="line">  &lt;description&gt;Thrift uri for the remote metastore. Used by metastore client to connect to remote metastore.&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line"> </div><div class="line">&lt;!--  hive表的默认存储路径 --&gt;</div><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;</div><div class="line">  &lt;value&gt;/user/hive/warehouse&lt;/value&gt;</div><div class="line">  &lt;description&gt;location of default database for the warehouse&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure></p>
<h3 id="Hive启动"><a href="#Hive启动" class="headerlink" title="Hive启动"></a>Hive启动</h3><p>要启动metastore服务<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">$ hive --service metastore &amp;</div><div class="line">$ jps</div><div class="line">10288 RunJar  #多了一个进程</div><div class="line">9365 NameNode</div><div class="line">9670 SecondaryNameNode</div><div class="line">11096 Jps</div><div class="line">9944 NodeManager</div><div class="line">9838 ResourceManager</div><div class="line">9471 DataNode</div></pre></td></tr></table></figure></p>
<p>启动hive命令行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">ubuntu@master:~$ hive</div><div class="line"></div><div class="line">Logging initialized using configuration in jar:file:/home/ubuntu/cloud/apache-hive-1.2.1-bin/lib/hive-common-1.2.1.jar!/hive-log4j.properties</div><div class="line">hive&gt; show tables;</div><div class="line">OK</div><div class="line">Time taken: 0.705 seconds</div></pre></td></tr></table></figure></p>
<p>启动hiveserver2<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hive --service hiveserver2 start &amp;</div></pre></td></tr></table></figure></p>
<h3 id="问题解决"><a href="#问题解决" class="headerlink" title="问题解决"></a>问题解决</h3><p>问题：创建表出先如下错误，删除表卡住</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:For direct MetaStore DB connections, we don&apos;t support retries at the client level.</div></pre></td></tr></table></figure>
<p>初始化<br>注意：初始化之前先删除hdfs上的metastore,否则会出错<code>/user/hive/warehouse</code><br>在hive服务端输入以下命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">schematool -dbType mysql -initSchema</div></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Hive </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[oracle启动dbstart出错或无反应的解决办法及自启动]]></title>
      <url>http://yoursite.com/2016/08/20/oracle%E5%90%AF%E5%8A%A8dbstart%E5%87%BA%E9%94%99%E6%88%96%E6%97%A0%E5%8F%8D%E5%BA%94%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95%E5%8F%8A%E8%87%AA%E5%90%AF%E5%8A%A8/</url>
      <content type="html"><![CDATA[<h3 id="问题一"><a href="#问题一" class="headerlink" title="问题一"></a>问题一</h3><p>启动dbstart 报错<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ORACLE_HOME_LISTNER is not SET, unable to auto-start Oracle Net Listener Usage: /home/oracle/oracle11g/product/11.2.0/dbhome_1/bin/dbstart ORACLE_HOME</div></pre></td></tr></table></figure></p>
<p>linux成功安装Oracle后切换到Oracle用户后，直接使用<code>dbstart</code>($ORACLE_HOME/bin中)启动oracle数据库报错如上。原因是dbstart调用的tnslsnr脚本位置有错。解决办法：<br>打开该脚本：<code>vim $ORACLE_HOME/bin/dbstart</code><br>查找“ORACLE_HOME_LISTENER”变量的定义处，<br>修改<br><code>ORACLE_HOME_LISTENER＝$1</code><br>为<code>ORACLE_HOME_LISTENER＝$ORACLE_HOME</code></p>
<h3 id="问题二"><a href="#问题二" class="headerlink" title="问题二"></a>问题二</h3><p>启动<code>dbstart</code>没有反应，即不报错也不显示启动信息<br>原因是oracle的配置需要修改才能使用dbstart启动对应的数据实例。<br>解决办法：</p>
<p><code>sudo vim /etc/oratab</code><br>将<code>orcl:/home/oracle/oracle11g/product/11.2.0/dbhome_1:N</code>改为<code>orcl:/home/oracle/oracle11g/product/11.2.0/dbhome_1:Y</code></p>
<h3 id="问题三"><a href="#问题三" class="headerlink" title="问题三"></a>问题三</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&gt;dbstart</div><div class="line">Can&apos;t find init file for Database &quot;orcl&quot;.</div><div class="line"></div><div class="line">Database &quot;orcl&quot; NOT started.</div></pre></td></tr></table></figure>
<p>原因就是没有找到init文件 我的数据库实例是orcl<br>这个文件<code>在$ORACLE_HOME/dbs/</code>目录下<br><code>cd $ORACLE_HOME/dbs</code><br>解决办法就是建立一个initorcl.ora的软连接就可以了<br><code>ln -s spfileego.ora initorcl.ora</code></p>
<h3 id="Oracle自启动"><a href="#Oracle自启动" class="headerlink" title="Oracle自启动"></a>Oracle自启动</h3><p>创建开机自动启动数据库的脚本<br>开一个普通的字符终端连接到UbuntuServer，运行如下命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line"># vi /etc/init.d/Oracledb</div><div class="line">文件内容如下：</div><div class="line">#!/bin/bash</div><div class="line">#</div><div class="line"># /etc/init.d/oracledb</div><div class="line">#</div><div class="line"># Run-level Startup script for the Oracle Instance, Listener, and</div><div class="line"># Web Interface</div><div class="line"></div><div class="line">export ORACLE_HOME=/home/oracle/oracle11g/product/11.2.0/dbhome_1</div><div class="line">export ORACLE_SID=orcl</div><div class="line">export PATH=$ORACLE_HOME/bin:$PATH</div><div class="line"></div><div class="line">ORA_OWNR=&quot;oracle&quot;</div><div class="line"># if the executables do not exist -- display error</div><div class="line">if [ ! -f $ORACLE_HOME/bin/dbstart -o ! -d $ORACLE_HOME ]</div><div class="line">then</div><div class="line">echo &quot;Oracle startup: cannot start&quot;</div><div class="line">exit 1</div><div class="line">fi</div><div class="line"># depending on parameter -- startup, shutdown, restart</div><div class="line"># of the instance and listener or usage display</div><div class="line">case &quot;$1&quot; in</div><div class="line">start)</div><div class="line"># Oracle listener and instance startup</div><div class="line">echo -n &quot;Starting Oracle: &quot;</div><div class="line">su $ORA_OWNR -c &quot;$ORACLE_HOME/bin/lsnrctl start&quot;</div><div class="line">su $ORA_OWNR -c &quot;$ORACLE_HOME/bin/dbstart&quot;</div><div class="line">touch /var/lock/oracle</div><div class="line">su $ORA_OWNR -c &quot;$ORACLE_HOME/bin/emctl start dbconsole&quot;</div><div class="line">echo &quot;OK&quot;</div><div class="line">;;</div><div class="line">stop)</div><div class="line"># Oracle listener and instance shutdown</div><div class="line">echo -n &quot;Shutdown Oracle: &quot;</div><div class="line">su $ORA_OWNR -c &quot;$ORACLE_HOME/bin/lsnrctl stop&quot;</div><div class="line">su $ORA_OWNR -c &quot;$ORACLE_HOME/bin/dbshut&quot;</div><div class="line">rm -f /var/lock/oracle</div><div class="line">su $ORA_OWNR -c &quot;$ORACLE_HOME/bin/emctl stop dbconsole&quot;</div><div class="line">echo &quot;OK&quot;</div><div class="line">;;</div><div class="line">reload|restart)</div><div class="line">$0 stop</div><div class="line">$0 start</div><div class="line">;;</div><div class="line">*)</div><div class="line">echo &quot;Usage: `basename $0` start|stop|restart|reload&quot;</div><div class="line">exit 1</div><div class="line">esac</div><div class="line">exit 0</div></pre></td></tr></table></figure></p>
<p>再运行如下命令设置权限，并放到启动脚本中去：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># chmod 755 /etc/init.d/Oracledb</div><div class="line"># update-rc.d Oracledb defaults 99</div></pre></td></tr></table></figure></p>
<p>最后：<br><code># vi /etc/oratab</code><br>把文件中的N改成Y，即”orcl:/opt/oracle/product/db:N”修改为”orcl:/opt/oracle/product/db:Y”。</p>
]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Oracle </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Linux日常操作笔记]]></title>
      <url>http://yoursite.com/2016/08/19/Linux%E6%97%A5%E5%B8%B8%E6%93%8D%E4%BD%9C%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<h3 id="查看当前所在的工作目录的全路径-pwd"><a href="#查看当前所在的工作目录的全路径-pwd" class="headerlink" title="查看当前所在的工作目录的全路径 pwd"></a>查看当前所在的工作目录的全路径 pwd</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[root@localhost ~]# pwd</div><div class="line">/root</div></pre></td></tr></table></figure>
<h3 id="查看当前系统的时间-date"><a href="#查看当前系统的时间-date" class="headerlink" title="查看当前系统的时间 date"></a>查看当前系统的时间 date</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[root@localhost ~]# date +%Y-%m-%d</div><div class="line">2016-07-26</div><div class="line"></div><div class="line">date +%Y-%m-%d  --date=&quot;-1 day&quot; #加减也可以 month | year</div><div class="line">2016-07-25</div><div class="line"></div><div class="line">[root@localhost ~]# date -s &quot;2016-07-28 16:12:00&quot; ## 修改时间</div><div class="line">Thu Jul 28 16:12:00 PDT 2016</div></pre></td></tr></table></figure>
<h3 id="查看有谁在线（哪些人登陆到了服务器）"><a href="#查看有谁在线（哪些人登陆到了服务器）" class="headerlink" title="查看有谁在线（哪些人登陆到了服务器）"></a>查看有谁在线（哪些人登陆到了服务器）</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">who  查看当前在线</div><div class="line">[root@localhost ~]# who</div><div class="line">hadoop   tty1         2016-07-26 00:01 (:0)</div><div class="line">hadoop   pts/0        2016-07-26 00:49 (:0.0)</div><div class="line">root     pts/1        2016-07-26 00:50 (192.168.233.1)</div></pre></td></tr></table></figure>
<p>###last 查看最近的登陆历史记录</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[root@localhost ~]# last</div><div class="line">root     pts/1        192.168.233.1    Tue Jul 26 00:50   still logged in   </div><div class="line">hadoop   pts/0        :0.0             Tue Jul 26 00:49   still logged in   </div><div class="line">hadoop   tty1         :0               Tue Jul 26 00:01   still logged in   </div><div class="line">reboot   system boot  2.6.32-573.el6.x Tue Jul 26 07:58 - 16:23 (2+08:24)</div></pre></td></tr></table></figure>
<h3 id="关机-重启"><a href="#关机-重启" class="headerlink" title="关机/重启"></a>关机/重启</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">关机（必须用root用户）</div><div class="line">shutdown -h now  ## 立刻关机</div><div class="line">shutdown -h +10  ##  10分钟以后关机</div><div class="line">shutdown -h 12:00:00  ##12点整的时候关机</div><div class="line">halt   #  等于立刻关机</div><div class="line"></div><div class="line">重启</div><div class="line">shutdown -r now</div><div class="line">reboot   # 等于立刻重启</div></pre></td></tr></table></figure>
<h3 id="清屏"><a href="#清屏" class="headerlink" title="清屏"></a>清屏</h3><p><code>clear    ## 或者用快捷键  ctrl + l</code></p>
<h3 id="退出当前进程"><a href="#退出当前进程" class="headerlink" title="退出当前进程"></a>退出当前进程</h3><p><code>ctrl+c   ##有些程序也可以用q键退出</code></p>
<h3 id="挂起当前进程"><a href="#挂起当前进程" class="headerlink" title="挂起当前进程"></a>挂起当前进程</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">ctrl+z   ## 进程会挂起到后台</div><div class="line">bg jobid  ## 让进程在后台继续执行</div><div class="line">fg jobid   ## 让进程回到前台</div></pre></td></tr></table></figure>
<h3 id="echo"><a href="#echo" class="headerlink" title="echo"></a>echo</h3><p>相当于java中System.out.println(userName)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[root@localhost ~]# a=&quot;hi boy&quot;</div><div class="line">[root@localhost ~]# echo a</div><div class="line">a</div><div class="line">[root@localhost ~]# echo $a</div><div class="line">hi boy</div></pre></td></tr></table></figure></p>
<h3 id="目录操作"><a href="#目录操作" class="headerlink" title="目录操作"></a>目录操作</h3><p>查看目录信息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">ls /   ## 查看根目录下的子节点（文件夹和文件）信息</div><div class="line">ls -al ##  -a是显示隐藏文件   -l是以更详细的列表形式显示</div><div class="line">ls -l  ##有一个别名： ll    可以直接使用ll  &lt;是两个L&gt;</div></pre></td></tr></table></figure></p>
<h3 id="切换工作目录"><a href="#切换工作目录" class="headerlink" title="切换工作目录"></a>切换工作目录</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">cd  /home/hadoop    ## 切换到用户主目录</div><div class="line">cd ~     ## 切换到用户主目录</div><div class="line">cd -     ##  回退到上次所在的目录</div><div class="line">cd  什么路径都不带，则回到用户的主目录</div></pre></td></tr></table></figure>
<h3 id="创建文件夹"><a href="#创建文件夹" class="headerlink" title="创建文件夹"></a>创建文件夹</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">mkdir aaa     ## 这是相对路径的写法 </div><div class="line">mkdir  /data    ## 这是绝对路径的写法 </div><div class="line">mkdir -p  aaa/bbb/ccc   ## 级联创建目录</div></pre></td></tr></table></figure>
<h3 id="删除文件夹"><a href="#删除文件夹" class="headerlink" title="删除文件夹"></a>删除文件夹</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">rmdir  aaa   ## 可以删除空目录</div><div class="line">rm  -r  aaa   ## 可以把aaa整个文件夹及其中的所有子节点全部删除</div><div class="line">rm  -rf  aaa   ## 强制删除aaa</div></pre></td></tr></table></figure>
<h3 id="修改文件夹名称"><a href="#修改文件夹名称" class="headerlink" title="修改文件夹名称"></a>修改文件夹名称</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">mv  aaa  boy</div><div class="line">mv本质上是移动</div><div class="line">mv  install.log  aaa/  将当前目录下的install.log 移动到aaa文件夹中去</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">rename 可以用来批量更改文件名</div><div class="line">[root@localhost aaa]# ll</div><div class="line">total 0</div><div class="line">-rw-r--r--. 1 root root 0 Jul 28 17:33 1.txt</div><div class="line">-rw-r--r--. 1 root root 0 Jul 28 17:33 2.txt</div><div class="line">-rw-r--r--. 1 root root 0 Jul 28 17:33 3.txt</div><div class="line">[root@localhost aaa]# rename .txt .txt.bak *</div><div class="line">[root@localhost aaa]# ll</div><div class="line">total 0</div><div class="line">-rw-r--r--. 1 root root 0 Jul 28 17:33 1.txt.bak</div><div class="line">-rw-r--r--. 1 root root 0 Jul 28 17:33 2.txt.bak</div><div class="line">-rw-r--r--. 1 root root 0 Jul 28 17:33 3.txt.bak</div></pre></td></tr></table></figure>
<h3 id="文件操作"><a href="#文件操作" class="headerlink" title="文件操作"></a>文件操作</h3><p>创建文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">touch  somefile.1       </div><div class="line">## 创建一个空文件</div><div class="line"></div><div class="line">echo &quot;hi,boy&quot; &gt; somefile.2     </div><div class="line">## 利用重定向“&gt;”的功能，将一条指令的输出结果写入到一个文件中，会覆盖原文件内容，如果指定的文件不存在，则会创建出来</div><div class="line"></div><div class="line">echo &quot;hi baby&quot; &gt;&gt; somefile.2    </div><div class="line">## 将一条指令的输出结果追加到一个文件中，不会覆盖原文件内容</div></pre></td></tr></table></figure></p>
<h3 id="vi文本编辑器"><a href="#vi文本编辑器" class="headerlink" title="vi文本编辑器"></a>vi文本编辑器</h3><p>最基本用法<br>vi  somefile.4<br>1 首先会进入“一般模式”，此模式只接受各种快捷键，不能编辑文件内容<br>2 按i键，就会从一般模式进入编辑模式，此模式下，敲入的都是文件内容<br>3 编辑完成之后，按Esc键退出编辑模式，回到一般模式；<br>4 再按：，进入“底行命令模式”，输入wq命令，回车即可</p>
<p>常用快捷键<br>一些有用的快捷键（在一般模式下使用）：<br>a   在光标后一位开始插入<br>A   在该行的最后插入<br>I   在该行的最前面插入<br>gg   直接跳到文件的首行<br>G    直接跳到文件的末行<br>dd    删除一行<br>3dd   删除3行<br>yy    复制一行<br>3yy   复制3行<br>p     粘贴<br>u     undo<br>v        进入字符选择模式，选择完成后，按y复制，按p粘贴<br>ctrl+v   进入块选择模式，选择完成后，按y复制，按p粘贴<br>shift+v  进入行选择模式，选择完成后，按y复制，按p粘贴</p>
<p>查找并替换<br>1 显示行号<br>:set nu<br>2 隐藏行号<br>:set nonu<br>3 查找关键字<br>:/you       ## 效果：查找文件中出现的you，并定位到第一个找到的地方，按n可以定位到下一个匹配位置（按N定位到上一个）<br>4 替换操作<br>:s/sad/bbb    查找光标所在行的第一个sad，替换为bbb<br>:%s/sad/bbb      查找文件中所有sad，替换为bbb</p>
<h3 id="拷贝-删除-移动"><a href="#拷贝-删除-移动" class="headerlink" title="拷贝/删除/移动"></a>拷贝/删除/移动</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">cp  somefile.1   /home/hadoop/</div><div class="line">rm /home/hadoop/somefile.1</div><div class="line">rm -f /home/hadoop/somefile.1</div><div class="line">mv /home/hadoop/somefile.1 ../</div></pre></td></tr></table></figure>
<h3 id="查看文件内容"><a href="#查看文件内容" class="headerlink" title="查看文件内容"></a>查看文件内容</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">cat    somefile      一次性将文件内容全部输出（控制台）</div><div class="line">more   somefile      可以翻页查看, 下翻一页(空格)    上翻一页（b）   退出（q）</div><div class="line">less   somefile      可以翻页查看,下翻一页(空格)    上翻一页（b），上翻一行(↑)  下翻一行（↓）  可以搜索关键字（/keyword）</div><div class="line">跳到文件末尾： G</div><div class="line">跳到文件首行： gg</div><div class="line">退出less ：  q</div><div class="line"></div><div class="line">tail -10  install.log  查看文件尾部的10行</div><div class="line">tail +10  install.log  查看文件 10--&gt;末行</div><div class="line">tail -f install.log    小f跟踪文件的唯一inode号，就算文件改名后，还是跟踪原来这个inode表示的文件</div><div class="line">tail -F install.log    大F按照文件名来跟踪</div><div class="line"></div><div class="line">head -10  install.log   查看文件头部的10行</div></pre></td></tr></table></figure>
<h3 id="打包压缩"><a href="#打包压缩" class="headerlink" title="打包压缩"></a>打包压缩</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line">1、gzip压缩</div><div class="line">gzip a.txt</div><div class="line"></div><div class="line">2、解压</div><div class="line">gunzip a.txt.gz</div><div class="line">gzip -d a.txt.gz</div><div class="line"></div><div class="line">3、bzip2压缩</div><div class="line">bzip2 a</div><div class="line"></div><div class="line">4、解压</div><div class="line">bunzip2 a.bz2</div><div class="line">bzip2 -d a.bz2</div><div class="line"></div><div class="line">5、打包：将指定文件或文件夹</div><div class="line">tar -cvf bak.tar  ./aaa</div><div class="line">将/etc/password追加文件到bak.tar中(r)</div><div class="line">tar -rvf bak.tar /etc/password</div><div class="line"></div><div class="line">6、解压</div><div class="line">tar -xvf bak.tar</div><div class="line"></div><div class="line">7、打包并压缩</div><div class="line">tar -zcvf a.tar.gz  aaa/</div><div class="line"></div><div class="line">8、解包并解压缩(重要的事情说三遍!!!)</div><div class="line">tar  -zxvf  a.tar.gz</div><div class="line">解压到/usr/下</div><div class="line">tar  -zxvf  a.tar.gz  -C  /usr</div><div class="line"></div><div class="line">9、查看压缩包内容</div><div class="line">tar -ztvf a.tar.gz</div><div class="line">zip/unzip</div><div class="line"></div><div class="line">10、打包并压缩成bz2</div><div class="line">tar -jcvf a.tar.bz2</div><div class="line"></div><div class="line">11、解压bz2</div><div class="line">tar -jxvf a.tar.bz2</div></pre></td></tr></table></figure>
<h3 id="查找命令"><a href="#查找命令" class="headerlink" title="查找命令"></a>查找命令</h3><p>常用查找命令的使用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">1、查找可执行的命令所在的路径：</div><div class="line">which ls</div><div class="line"></div><div class="line">2、查找可执行的命令和帮助的位置：</div><div class="line">whereis ls</div><div class="line"></div><div class="line">3、从某个文件夹开始查找文件</div><div class="line">find / -name &quot;hadooop*&quot;</div><div class="line">find / -name &quot;hadooop*&quot; -ls</div><div class="line"></div><div class="line">4、查找并删除</div><div class="line">find / -name &quot;hadooop*&quot; -ok rm &#123;&#125; \;</div><div class="line">find / -name &quot;hadooop*&quot; -exec rm &#123;&#125; \;</div><div class="line"></div><div class="line">5、查找用户为hadoop的文件</div><div class="line">find  /usr  -user  hadoop  -ls</div><div class="line"></div><div class="line">6、查找用户为hadoop的文件夹</div><div class="line">find /home -user hadoop -type d -ls</div><div class="line"></div><div class="line">7、查找权限为777的文件</div><div class="line">find / -perm -777 -type d -ls</div><div class="line"></div><div class="line">8、显示命令历史</div><div class="line">history</div></pre></td></tr></table></figure>
<h3 id="grep命令"><a href="#grep命令" class="headerlink" title="grep命令"></a>grep命令</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line">1 基本使用</div><div class="line">查询包含hadoop的行</div><div class="line">grep hadoop /etc/password</div><div class="line">grep aaa  ./*.txt </div><div class="line"></div><div class="line">2 cut截取以:分割保留第七段</div><div class="line">grep hadoop /etc/passwd | cut -d: -f7</div><div class="line"></div><div class="line">3 查询不包含hadoop的行</div><div class="line">grep -v hadoop /etc/passwd</div><div class="line"></div><div class="line">4 正则表达包含hadoop</div><div class="line">grep &apos;hadoop&apos; /etc/passwd</div><div class="line"></div><div class="line">5 正则表达(点代表任意一个字符)</div><div class="line">grep &apos;h.*p&apos; /etc/passwd</div><div class="line"></div><div class="line">6 正则表达以hadoop开头</div><div class="line">grep &apos;^hadoop&apos; /etc/passwd</div><div class="line"></div><div class="line">7 正则表达以hadoop结尾</div><div class="line">grep &apos;hadoop$&apos; /etc/passwd</div><div class="line"></div><div class="line">规则：</div><div class="line">.  : 任意一个字符</div><div class="line">a* : 任意多个a(零个或多个a)</div><div class="line">a? : 零个或一个a</div><div class="line">a+ : 一个或多个a</div><div class="line">.* : 任意多个任意字符</div><div class="line">\. : 转义.</div><div class="line">o\&#123;2\&#125; : o重复两次</div><div class="line"></div><div class="line">查找不是以#开头的行</div><div class="line">grep -v &apos;^#&apos; a.txt | grep -v &apos;^$&apos; </div><div class="line"></div><div class="line">以h或r开头的</div><div class="line">grep &apos;^[hr]&apos; /etc/passwd</div><div class="line"></div><div class="line">不是以h和r开头的</div><div class="line">grep &apos;^[^hr]&apos; /etc/passwd</div><div class="line"></div><div class="line">不是以h到r开头的</div><div class="line">grep &apos;^[^h-r]&apos; /etc/passwd</div></pre></td></tr></table></figure>
<h3 id="文件权限的操作"><a href="#文件权限的操作" class="headerlink" title="文件权限的操作"></a>文件权限的操作</h3><p>linux文件权限的描述格式解读</p>
<p>drwxr-xr-x      （也可以用二进制表示  111 101 101  –&gt;  755）</p>
<p>d：标识节点类型（d：文件夹   -：文件  l:链接）<br>r：可读   w：可写    x：可执行<br>第一组rwx：  ## 表示这个文件的拥有者对它的权限：可读可写可执行<br>第二组r-x：  ## 表示这个文件的所属组用户对它的权限：可读，不可写，可执行<br>第三组r-x：  ## 表示这个文件的其他用户（相对于上面两类用户）对它的权限：可读，不可写，可执行</p>
<h4 id="修改文件权限"><a href="#修改文件权限" class="headerlink" title="修改文件权限"></a>修改文件权限</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">chmod g-rw haha.dat		 ## 表示将haha.dat对所属组的rw权限取消</div><div class="line">chmod o-rw haha.dat		 ## 表示将haha.dat对其他人的rw权限取消</div><div class="line">chmod u+x haha.dat		 ## 表示将haha.dat对所属用户的权限增加x</div><div class="line">chmod a-x haha.dat               ## 表示将haha.dat对所用户取消x权限</div><div class="line"></div><div class="line"></div><div class="line">也可以用数字的方式来修改权限</div><div class="line">chmod 664 haha.dat   </div><div class="line">就会修改成   rw-rw-r--</div><div class="line">如果要将一个文件夹的所有内容权限统一修改，则可以-R参数</div><div class="line">chmod -R 770 aaa/</div></pre></td></tr></table></figure>
<h4 id="修改文件所有权"><a href="#修改文件所有权" class="headerlink" title="修改文件所有权"></a>修改文件所有权</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&lt;只有root权限能执行&gt;</div><div class="line">chown angela  aaa		## 改变所属用户</div><div class="line">chown :angela  aaa		## 改变所属组</div><div class="line">chown angela:angela aaa/	## 同时修改所属用户和所属组</div></pre></td></tr></table></figure>
<h3 id="基本的用户管理"><a href="#基本的用户管理" class="headerlink" title="基本的用户管理"></a>基本的用户管理</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">添加一个用户：</div><div class="line">useradd spark</div><div class="line">passwd  spark     根据提示设置密码即可</div><div class="line"></div><div class="line">删除一个用户：</div><div class="line">userdel -r spark     加一个-r就表示把用户及用户的主目录都删除</div></pre></td></tr></table></figure>
<h4 id="添加用户"><a href="#添加用户" class="headerlink" title="添加用户"></a>添加用户</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">添加一个tom用户，设置它属于users组，并添加注释信息</div><div class="line">分步完成：useradd tom</div><div class="line">          usermod -g users tom</div><div class="line">	  usermod -c &quot;hr tom&quot; tom</div><div class="line">一步完成：useradd -g users -c &quot;hr tom&quot; tom</div><div class="line"></div><div class="line">设置tom用户的密码</div><div class="line">passwd tom</div></pre></td></tr></table></figure>
<h4 id="修改用户"><a href="#修改用户" class="headerlink" title="修改用户"></a>修改用户</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">修改tom用户的登陆名为tomcat</div><div class="line">usermod -l tomcat tom</div><div class="line"></div><div class="line">将tomcat添加到sys和root组中</div><div class="line">usermod -G sys,root tomcat</div><div class="line"></div><div class="line">查看tomcat的组信息</div><div class="line">groups tomcat</div></pre></td></tr></table></figure>
<h4 id="用户组操作"><a href="#用户组操作" class="headerlink" title="用户组操作"></a>用户组操作</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">添加一个叫america的组</div><div class="line">groupadd america</div><div class="line"></div><div class="line">将jerry添加到america组中</div><div class="line">usermod -g america jerry</div><div class="line"></div><div class="line">将tomcat用户从root组和sys组删除</div><div class="line">gpasswd -d tomcat root</div><div class="line">gpasswd -d tomcat sys</div><div class="line"></div><div class="line">将america组名修改为am</div><div class="line">groupmod -n am america</div></pre></td></tr></table></figure>
<h4 id="为用户配置sudo权限"><a href="#为用户配置sudo权限" class="headerlink" title="为用户配置sudo权限"></a>为用户配置sudo权限</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">用root编辑 vi /etc/sudoers</div><div class="line">在文件的如下位置，为hadoop添加一行即可</div><div class="line">root    ALL=(ALL)       ALL     </div><div class="line">hadoop  ALL=(ALL)       ALL</div><div class="line"></div><div class="line">然后，hadoop用户就可以用sudo来执行系统级别的指令</div><div class="line">[root@localhost ~]$ sudo useradd xiaoming</div></pre></td></tr></table></figure>
<h3 id="系统管理操作"><a href="#系统管理操作" class="headerlink" title="系统管理操作"></a>系统管理操作</h3><h4 id="挂载外部存储设备"><a href="#挂载外部存储设备" class="headerlink" title="挂载外部存储设备"></a>挂载外部存储设备</h4><p>可以挂载光盘、硬盘、磁带、光盘镜像文件等</p>
<ul>
<li>挂载光驱</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mkdir   /mnt/cdrom      创建一个目录，用来挂载</div><div class="line">mount -t iso9660 -o ro /dev/cdrom /mnt/cdrom/     将设备/dev/cdrom挂载到 挂载点 ：  /mnt/cdrom中</div></pre></td></tr></table></figure>
<ul>
<li>挂载光盘镜像文件（.iso文件）</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">mount -t iso9660 -o loop  /home/hadoop/Centos-6.7.DVD.iso /mnt/centos</div><div class="line">注：挂载的资源在重启后即失效，需要重新挂载。要想自动挂载，可以将挂载信息设置到/etc/fstab配置文件中，如下：</div><div class="line">/dev/cdrom              /mnt/cdrom              iso9660 defaults        0 0</div></pre></td></tr></table></figure>
<h4 id="卸载-umount"><a href="#卸载-umount" class="headerlink" title="卸载 umount"></a>卸载 umount</h4><p><code>umount /mnt/cdrom</code></p>
<h4 id="存储空间查看"><a href="#存储空间查看" class="headerlink" title="存储空间查看"></a>存储空间查看</h4><p><code>df -h</code></p>
<h4 id="统计文件或文件夹的大小"><a href="#统计文件或文件夹的大小" class="headerlink" title="统计文件或文件夹的大小"></a>统计文件或文件夹的大小</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">du -sh  /mnt/cdrom/packages</div><div class="line">df -h    查看磁盘的空间</div><div class="line">wc -lwc 统计文件行数、字数、字节数</div></pre></td></tr></table></figure>
<h4 id="系统服务管理"><a href="#系统服务管理" class="headerlink" title="系统服务管理"></a>系统服务管理</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">service sshd status</div><div class="line">service sshd stop </div><div class="line">service sshd start</div><div class="line">service sshd restart</div></pre></td></tr></table></figure>
<h4 id="系统启动级别管理"><a href="#系统启动级别管理" class="headerlink" title="系统启动级别管理"></a>系统启动级别管理</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">vi  /etc/inittab</div><div class="line"></div><div class="line">       # Default runlevel. The runlevels used are:</div><div class="line">       #   0 - halt (Do NOT set initdefault to this)</div><div class="line">       #   1 - Single user mode</div><div class="line">       #   2 - Multiuser, without NFS (The same as 3, if you do not have networking)</div><div class="line">       #   3 - Full multiuser mode</div><div class="line">       #   4 - unused</div><div class="line">       #   5 - X11</div><div class="line">       #   6 - reboot (Do NOT set initdefault to this)</div><div class="line">       #</div><div class="line">       id:3:initdefault:</div><div class="line">       ## 通常将默认启动级别设置为：3</div></pre></td></tr></table></figure>
<h4 id="进程管理"><a href="#进程管理" class="headerlink" title="进程管理"></a>进程管理</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">top</div><div class="line">free</div><div class="line">ps -ef | grep ssh</div><div class="line">kill -9</div></pre></td></tr></table></figure>
<h3 id="SSH免密登陆配置"><a href="#SSH免密登陆配置" class="headerlink" title="SSH免密登陆配置"></a>SSH免密登陆配置</h3><h4 id="SSH工作机制"><a href="#SSH工作机制" class="headerlink" title="SSH工作机制"></a>SSH工作机制</h4><p>1、相关概念<br>SSH 为 Secure Shell（安全外壳协议） 的缩写。<br>很多ftp、pop和telnet在本质上都是不安全的，因为它们在网络上用明文传送口令和数据，别有用心的人非常容易就可以截获这些口令和数据。<br>而SSH就是专为远程登录会话和其他网络服务提供安全性的协议。</p>
<p>SSH是由客户端和服务端的软件组成的<br>服务端是一个守护进程(sshd)，他在后台运行并响应来自客户端的连接请求。<br>客户端包含ssh程序以及像scp（远程拷贝）、slogin（远程登陆）、sftp（安全文件传输）等其他的应用程序。</p>
<p>2、认证机制<br>从客户端来看，SSH提供两种级别的安全验证。</p>
<p>第一种级别（基于口令的安全验证）<br>只要你知道自己帐号和口令，就可以登录到远程主机。</p>
<p>第二种级别（基于密钥的安全验证）<br>需要依靠密匙，也就是你必须为自己创建一对密匙，并把公用密匙放在需要访问的服务器上。如果你要连接到SSH服务器上，<br>客户端软件就会向服务器发出请求，请求用你的密匙进行安全验证。服务器收到请求之后，先在该服务器上你的主目录下寻找你的公用密匙，<br>然后把它和你发送过来的公用密匙进行比较。如果两个密匙一致，服务器就用公用密匙加密“质询”（challenge）并把它发送给客户端软件。<br>客户端软件收到“质询”之后就可以用你的私人密匙解密再把它发送给服务器。</p>
<h4 id="密钥登陆方式配置"><a href="#密钥登陆方式配置" class="headerlink" title="密钥登陆方式配置"></a>密钥登陆方式配置</h4><p>假如 A  要登陆  B<br>在A上操作：<br>1/ 首先生成密钥对<br><code>ssh-keygen</code>   (提示时，直接回车即可)<br>2/ 再将A自己的公钥拷贝并追加到B的授权列表文件<code>authorized_keys</code>中<br><code>ssh-copy-id   B</code></p>
<h3 id="网络管理"><a href="#网络管理" class="headerlink" title="网络管理"></a>网络管理</h3><h4 id="主机名配置"><a href="#主机名配置" class="headerlink" title="主机名配置"></a>主机名配置</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">1/ 查看主机名</div><div class="line">hostname</div><div class="line"></div><div class="line">2/ 修改主机名(重启后无效)</div><div class="line">hostname hadoop</div><div class="line"></div><div class="line">3/ 修改主机名(重启后永久生效) </div><div class="line">vi /ect/sysconfig/network</div></pre></td></tr></table></figure>
<h4 id="IP地址配置"><a href="#IP地址配置" class="headerlink" title="IP地址配置"></a>IP地址配置</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">修改IP地址</div><div class="line">1/ 方式一：setup</div><div class="line">用root输入setup命令，进入交互式修改界面</div><div class="line"></div><div class="line">2/ 方式二：修改配置文件 一般使用这种方法</div><div class="line">(重启后永久生效)</div><div class="line">vi /etc/sysconfig/network-scripts/ifcfg-eth0</div><div class="line"></div><div class="line">3/ 方式三：ifconfig命令</div><div class="line">(重启后无效)</div><div class="line">ifconfig eth0 192.168.12.22</div></pre></td></tr></table></figure>
<h3 id="网络服务管理"><a href="#网络服务管理" class="headerlink" title="网络服务管理"></a>网络服务管理</h3><p>1 后台服务管理<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">service network status    查看指定服务的状态</div><div class="line">service network stop     停止指定服务</div><div class="line">service network start     启动指定服务</div><div class="line">service network restart   重启指定服务</div><div class="line">service --status-all       查看系统中所有的后台服务</div></pre></td></tr></table></figure></p>
<p>2 设置后台服务的自启配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">chkconfig   查看所有服务器自启配置</div><div class="line">chkconfig iptables off   关掉指定服务的自动启动</div><div class="line">chkconfig iptables on   开启指定服务的自动启动</div></pre></td></tr></table></figure></p>
<p>转载自：</p>
<blockquote>
<p><a href="http://www.kuqin.com/shuoit/20160805/352716.html" target="_blank" rel="external">http://www.kuqin.com/shuoit/20160805/352716.html</a></p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux技巧 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Mahout 如何进行 Precision 和 Recall 的计算]]></title>
      <url>http://yoursite.com/2016/08/18/Mahout%20%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%20Precision%20%E5%92%8C%20Recall%20%E7%9A%84%E8%AE%A1%E7%AE%97/</url>
      <content type="html"><![CDATA[<blockquote>
<p>当为某一个用户做推荐评估时，选择一个临界值，以该临界值为参照为该用户构造一个目标最大击中集（即相关项RelevantItemsIDs），然后将该用户数据中的包含在最大击中集中的物品去除，这样形成一个新的训练集。这个新的训练集中，只是去除了部分数据。然后，使用该训练集为该用户进行推荐。如果推荐的物品包含在最大击中集中，则说明击中。依照这个办法为该用户计算 Precision 和 Recall 值。依照这个办法为所有的用户计算 Precision 和 Recall 值。然后，Precision 和 Recall 的平均值作为模型的 Precision 和 Recall 值。</p>
</blockquote>
<p>RecommenderIRStatsEvaluator是一个接口，用于得到推荐系统的准确率，召回率等统计指标。<br>它定义的函数如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">public IRStatistics evaluate(RecommenderBuilder recommenderBuilder, DataModelBuilder dataModelBuilder, DataModel dataModel, IDRescorer rescorer, int at, double relevanceThreshold, doubleevaluationPercentage) </div><div class="line">/**</div><div class="line">   * @param recommenderBuilder</div><div class="line">   * 它通过public Recommender buildRecommender(DataModel model)定义推荐系统创建的方式；       </div><div class="line"></div><div class="line">   * @param dataModelBuilder</div><div class="line">   * 数据模型创建的方式，如果已经创建好了数据模型，一般这个参数可以为null</div><div class="line"></div><div class="line">   * @param dataModel</div><div class="line">   * 推荐系统使用的数据模型</div><div class="line">   * </div><div class="line">   * @param rescorer</div><div class="line">   * 推荐排序的方式，一般情况下可以为null</div><div class="line">   * </div><div class="line">   * @param at</div><div class="line">   * 推荐几个物品（TOPN),，它用来定义计算准确率的时候，一个user可以拥有的相关项items的最大个数，相关项item定义为user对这个item的评价超过了relevanceThreshold的项</div><div class="line"></div><div class="line">   * @param relevanceThreshold</div><div class="line">   * 相关临界值 ,和at一起使用定义一个user的相关项</div></pre></td></tr></table></figure></p>
<h3 id="计算临界值"><a href="#计算临界值" class="headerlink" title="计算临界值"></a>计算临界值</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">//computeThreshold(prefs)这个方法主要是计算得到当前用户对物品 打分的平均值加上标准差的值</div><div class="line">double theRelevanceThreshold = Double.isNaN(relevanceThreshold) ? computeThreshold(prefs)</div><div class="line">					: relevanceThreshold;</div></pre></td></tr></table></figure>
<h3 id="getRelevantItemsIDs"><a href="#getRelevantItemsIDs" class="headerlink" title="getRelevantItemsIDs"></a>getRelevantItemsIDs</h3><p>按照用户对物品的打分从大到小排序，将大于设定的的relevanceTheshold的值存入relevantItemIDs中，relevantItemIDs最大值为at<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">/**</div><div class="line"> * getRelevantItemsIDs的实现，</div><div class="line"> *1.首先得到userID的Preferences </div><div class="line"> *2.创建一个FastIDSet用来保存相关项的id，大小为at </div><div class="line"> *3.prefs根据值大小排序 </div><div class="line"> *4.遍历pref，如果user对这个item的评价prefs.getValue(i)不小于相关阈值，则将这个item的加入相关项，最多取at个满足条件的item</div><div class="line"> */</div><div class="line">FastIDSet relevantItemIDs = dataSplitter.getRelevantItemsIDs(userID, at, theRelevanceThreshold, dataModel);</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">public FastIDSet getRelevantItemsIDs(long userID,</div><div class="line">                                       int at,</div><div class="line">                                       double relevanceThreshold,</div><div class="line">                                       DataModel dataModel) throws TasteException &#123;</div><div class="line">    PreferenceArray prefs = dataModel.getPreferencesFromUser(userID);</div><div class="line">	//定义最大理论击中物品集合 </div><div class="line">    FastIDSet relevantItemIDs = new FastIDSet(at);</div><div class="line">	//将用户的打分排序 </div><div class="line">    prefs.sortByValueReversed();</div><div class="line">    for (int i = 0; i &lt; prefs.length() &amp;&amp; relevantItemIDs.size() &lt; at; i++) &#123;</div><div class="line">      if (prefs.getValue(i) &gt;= relevanceThreshold) &#123;</div><div class="line">        relevantItemIDs.add(prefs.getItemID(i));</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    return relevantItemIDs;</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<h3 id="获取训练集"><a href="#获取训练集" class="headerlink" title="获取训练集"></a>获取训练集</h3><p>这个训练集的构造规则是： </p>
<ol>
<li>对于其它的用户，将他们所有的（item，preference）都加入训练集； </li>
<li>对于这个用户user，将它的除了相关项之外的其它项的喜好加入训练集；</li>
</ol>
<p>然后，我们使用推荐算法进行推荐。推荐的时候，我们就可能给UserID 推荐移除的物品或者其他的物品。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">FastByIDMap&lt;PreferenceArray&gt; trainingUsers = new FastByIDMap&lt;PreferenceArray&gt;(dataModel.getNumUsers());</div><div class="line">			//对所有用户进行处理</div><div class="line">			//processOtherUser :Adds a single user and all their preferences to the training model.</div><div class="line">			LongPrimitiveIterator it2 = dataModel.getUserIDs();</div><div class="line">			while (it2.hasNext()) &#123;</div><div class="line">				dataSplitter.processOtherUser(userID, relevantItemIDs, trainingUsers, it2.nextLong(), dataModel);</div><div class="line">			&#125;</div></pre></td></tr></table></figure></p>
<h3 id="构造训练模型"><a href="#构造训练模型" class="headerlink" title="构造训练模型"></a>构造训练模型</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">DataModel trainingModel = dataModelBuilder == null ? new GenericDataModel(trainingUsers): dataModelBuilder.buildDataModel(trainingUsers);</div></pre></td></tr></table></figure>
<h3 id="进行推荐"><a href="#进行推荐" class="headerlink" title="进行推荐"></a>进行推荐</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Recommender recommender = recommenderBuilder.buildRecommender(trainingModel);</div><div class="line"></div><div class="line">int intersectionSize = 0;</div><div class="line"></div><div class="line">List&lt;RecommendedItem&gt; recommendedItems = recommender.recommend(userID, at, rescorer);</div></pre></td></tr></table></figure>
<h3 id="计算推荐结果包含在相关项中的个数"><a href="#计算推荐结果包含在相关项中的个数" class="headerlink" title="计算推荐结果包含在相关项中的个数"></a>计算推荐结果包含在相关项中的个数</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">List&lt;RecommendedItem&gt; recommendedItems = recommender.recommend(userID, at, rescorer);</div><div class="line"></div><div class="line">			for (RecommendedItem recommendedItem : recommendedItems) &#123;</div><div class="line"></div><div class="line">				if (relevantItemIDs.contains(recommendedItem.getItemID())) &#123;</div><div class="line">					intersectionSize++;</div><div class="line">				&#125;</div><div class="line">			&#125;</div></pre></td></tr></table></figure>
<h3 id="计算查全率、查准率"><a href="#计算查全率、查准率" class="headerlink" title="计算查全率、查准率"></a>计算查全率、查准率</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">int numRecommendedItems = recommendedItems.size();</div><div class="line"></div><div class="line">			// Precision</div><div class="line">			if (numRecommendedItems &gt; 0) &#123;</div><div class="line">				precision.addDatum((double) intersectionSize / (double) numRecommendedItems);</div><div class="line">			&#125;</div><div class="line"></div><div class="line">			// Recall</div><div class="line">			recall.addDatum((double) intersectionSize / (double) numRelevantItems);</div></pre></td></tr></table></figure>
<p>参考</p>
<blockquote>
<p><a href="http://pan.baidu.com/s/1pKE97wJ" target="_blank" rel="external">http://pan.baidu.com/s/1pKE97wJ</a><br><a href="http://www.myexception.cn/cloud/1983215.html" target="_blank" rel="external">http://www.myexception.cn/cloud/1983215.html</a></p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> 推荐系统 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Mahout </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Ubuntu16.04安装Oracle11g]]></title>
      <url>http://yoursite.com/2016/08/17/Ubuntu16.04%E5%AE%89%E8%A3%85Oracle11g/</url>
      <content type="html"><![CDATA[<h3 id="Oracle用户创建"><a href="#Oracle用户创建" class="headerlink" title="Oracle用户创建"></a>Oracle用户创建</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">sudo groupadd oinstall</div><div class="line">sudo groupadd dba</div><div class="line">sudo adduser -g oinstall -G dba -s  oracle</div><div class="line">sudo passwd oracle</div></pre></td></tr></table></figure>
<h3 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">mkdir /tmp/libstdc++5</div><div class="line">cd /tmp/libstdc++5</div><div class="line">wget http://mirrors.kernel.org/ubuntu/pool/universe/g/gcc-3.3/libstdc++5_3.3.6-28ubuntu1_amd64.deb</div><div class="line">wget http://mirrors.kernel.org/ubuntu/pool/universe/g/gcc-3.3/libstdc++5_3.3.6-28ubuntu1_i386.deb</div><div class="line">sudo dpkg --force-architecture -i libstdc++5_3.3.6-28ubuntu1_i386.deb</div><div class="line">sudo mv /usr/lib/libstdc++.so.5* /usr/lib32/</div><div class="line">sudo dpkg -i libstdc++5_3.3.6-28ubuntu1_amd64.deb</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line">sudo apt-get update</div><div class="line">sudo apt-get dist-upgrade</div><div class="line">sudo apt-get install automake</div><div class="line">sudo apt-get install autotools-dev</div><div class="line">sudo apt-get install binutils</div><div class="line">sudo apt-get install bzip2</div><div class="line">sudo apt-get install elfutils</div><div class="line">sudo apt-get install expat</div><div class="line">sudo apt-get install gawk</div><div class="line">sudo apt-get install gcc</div><div class="line">sudo apt-get install gcc-multilib</div><div class="line">sudo apt-get install g++-multilib</div><div class="line">sudo apt-get install ia32-libs</div><div class="line">sudo apt-get install ksh</div><div class="line">sudo apt-get install less</div><div class="line">sudo apt-get install lesstif2</div><div class="line">sudo apt-get install lesstif2-dev</div><div class="line">sudo apt-get install lib32z1</div><div class="line">sudo apt-get install libaio1</div><div class="line">sudo apt-get install libaio-dev</div><div class="line">sudo apt-get install libc6-dev</div><div class="line">sudo apt-get install libc6-dev-i386</div><div class="line">sudo apt-get install libc6-i386</div><div class="line">sudo apt-get install libelf-dev</div><div class="line">sudo apt-get install libltdl-dev</div><div class="line">sudo apt-get install libmotif4</div><div class="line">sudo apt-get install libodbcinstq4-1 libodbcinstq4-1:i386</div><div class="line">sudo apt-get install libpth-dev</div><div class="line">sudo apt-get install libpthread-stubs0</div><div class="line">sudo apt-get install libpthread-stubs0-dev</div><div class="line">sudo apt-get install libstdc++5</div><div class="line">sudo apt-get install lsb-cxx</div><div class="line">sudo apt-get install make</div><div class="line">sudo apt-get install openssh-server</div><div class="line">sudo apt-get install pdksh</div><div class="line">sudo apt-get install rlwrap</div><div class="line">sudo apt-get install rpm</div><div class="line">sudo apt-get install sysstat</div><div class="line">sudo apt-get install unixodbc</div><div class="line">sudo apt-get install unixodbc-dev</div><div class="line">sudo apt-get install unzip</div><div class="line">sudo apt-get install x11-utils</div><div class="line">sudo apt-get install zlibc</div></pre></td></tr></table></figure>
<h3 id="修改-etc-sysctl-conf增加以下内容"><a href="#修改-etc-sysctl-conf增加以下内容" class="headerlink" title="修改/etc/sysctl.conf增加以下内容"></a>修改/etc/sysctl.conf增加以下内容</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">kernel.sem = 250 32000 100 128</div><div class="line">kernel.shmall = 2097152</div><div class="line">kernel.shmmni = 4096</div><div class="line">kernel.shmmax=1073741824</div><div class="line">net.ipv4.ip_local_port_range = 9000  65500</div><div class="line">net.core.rmem_default = 262144</div><div class="line">net.core.rmem_max = 4194304</div><div class="line">net.core.wmem_default = 262144</div><div class="line">net.core.wmem_max = 1048576</div><div class="line">fs.aio-max-nr = 1048576</div><div class="line">fs.file-max = 6815744</div><div class="line">vm.hugetlb_shm_group = 1002</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"># 以下包安装不成功，先略过</div><div class="line">sudo apt-get install lesstif2</div><div class="line">sudo apt-get install lesstif2-dev</div><div class="line">sudo apt-get install libpthread-stubs0</div><div class="line">sudo apt-get install lsb-cxx</div><div class="line">sudo apt-get install pdksh</div></pre></td></tr></table></figure>
<h3 id="运行一下命令更新内核参数"><a href="#运行一下命令更新内核参数" class="headerlink" title="运行一下命令更新内核参数"></a>运行一下命令更新内核参数</h3><p><code>sudo sysctl -p</code></p>
<h3 id="修改-etc-security-limits-conf增加以下内容"><a href="#修改-etc-security-limits-conf增加以下内容" class="headerlink" title="修改/etc/security/limits.conf增加以下内容"></a>修改/etc/security/limits.conf增加以下内容</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">oracle soft nproc  2047</div><div class="line">oracle hard nproc  16384</div><div class="line">oracle soft nofile 1024</div><div class="line">oracle hard nofile 65536</div><div class="line">oracle soft stack  10240</div></pre></td></tr></table></figure>
<h3 id="修改-etc-pam-d-login增加以下内容"><a href="#修改-etc-pam-d-login增加以下内容" class="headerlink" title="修改/etc/pam.d/login增加以下内容"></a>修改/etc/pam.d/login增加以下内容</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">session required /lib/security/pam_limits.so</div><div class="line">session required pam_limits.so</div></pre></td></tr></table></figure>
<h3 id="欺骗oracle的安装程序"><a href="#欺骗oracle的安装程序" class="headerlink" title="欺骗oracle的安装程序"></a>欺骗oracle的安装程序</h3><p>oracle本身并不支持ubuntu来安装，所以要进行欺骗oracle的安装程序（sudo执行）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">mkdir /usr/lib64</div><div class="line">ln -s /etc /etc/rc.d</div><div class="line">ln -s /lib/x86_64-linux-gnu/libgcc_s.so.1 /lib64/</div><div class="line">ln -s /usr/bin/awk /bin/awk</div><div class="line">ln -s /usr/bin/basename /bin/basename</div><div class="line">ln -s /usr/bin/rpm /bin/rpm</div><div class="line">ln -s /usr/lib/x86_64-linux-gnu/libc_nonshared.a /usr/lib64/</div><div class="line">ln -s /usr/lib/x86_64-linux-gnu/libpthread_nonshared.a /usr/lib64/</div><div class="line">ln -s /usr/lib/x86_64-linux-gnu/libstdc++.so.6 /lib64/</div><div class="line">ln -s /usr/lib/x86_64-linux-gnu/libstdc++.so.6 /usr/lib64/</div><div class="line">vim /etc/redhat-release</div><div class="line">echo &apos;Red Hat Linux release 5&apos; &gt; /etc/redhat-release</div></pre></td></tr></table></figure></p>
<h3 id="为Oracle配置环境变量"><a href="#为Oracle配置环境变量" class="headerlink" title="为Oracle配置环境变量"></a>为Oracle配置环境变量</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">#oracle安装目录，第6步创建的文件夹</div><div class="line">export ORACLE_BASE=/home/oracle/oracle11g</div><div class="line">#网上说可以随便写</div><div class="line">export ORACLE_HOME=$ORACLE_BASE/product/11.2.0/dbhome_1</div><div class="line">#数据库的sid</div><div class="line">export ORACLE_SID=orcl</div><div class="line">export ORACLE_UNQNAME=orcl</div><div class="line">#默认字符集</div><div class="line">export NLS_LANG=.AL32UTF8</div><div class="line">#环境变量</div><div class="line">export PATH=$&#123;PATH&#125;:$&#123;ORACLE_HOME&#125;/bin/:$ORACLE_HOME/lib64;</div></pre></td></tr></table></figure>
<h3 id="安装oracle"><a href="#安装oracle" class="headerlink" title="安装oracle"></a>安装oracle</h3><p>上面的系统配置完成之后，最好重启一下服务器，<strong>使用oracle用户登陆系统</strong>。</p>
<ol>
<li>上传下载好的oracle压缩文件到/home/oracle目录下。</li>
<li>进入/home/oracle目录，执行# unzip linux.x64_11gR2_database_1of2.zip和# unzip linux.x64_11gR2_database_2of2.zip，解压的文件在/home/oracle/database目录中。</li>
<li><p>设置/home/oracle/database目录的权限：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># chown oracle:oinstall /home/oracle/database -R</div><div class="line"># chmod 775 /home/oracle/database -R</div></pre></td></tr></table></figure>
</li>
<li><p>进入/home/oracle/database目录，执行$ ./runInstaller，当检查均通过，会出现oracle安装界面,一路next，有一步可以选择字符，选utf8</p>
</li>
</ol>
<h3 id="安装过程可能遇到的问题"><a href="#安装过程可能遇到的问题" class="headerlink" title="安装过程可能遇到的问题"></a>安装过程可能遇到的问题</h3><ul>
<li><p>Oracle安装界面乱码解决方法<br>执行:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">exportNLS_LANG=AMERICAN_AMERICA.UTF8</div><div class="line">export LC_ALL=C</div></pre></td></tr></table></figure>
</li>
<li><p>Error in invoking target ‘install’ of makefile ‘/home/dong/tools/oracle11g/product/11.2.0/dbhome_1/ctx/lib/ins_ctx.mk’. See ‘/home/dong/tools/oraInventory/logs/installActions2015-01-22_09-39-03AM.log’ for details.</p>
<p>解决方法：</p>
<p>从<a href="http://download.csdn.net/detail/adnerly/9467935下载，使用rpm安装这个glibc-static-2.17-55.el7.x86_64.rpm资源，安装即可，" target="_blank" rel="external">http://download.csdn.net/detail/adnerly/9467935下载，使用rpm安装这个glibc-static-2.17-55.el7.x86_64.rpm资源，安装即可，</a> 然后点击retry ，接着往下执行<br>注:这是网上提供的解决方案，我的系统安装失败，我直接跳过了 </p>
</li>
<li><p>Error in invoking target ‘agent nmhs’ of makefile ‘/home/dong/tools/oracle11g/product/11.2.0/dbhome_1/sysman/lib/ins_emagent.mk’</p>
<p>解决方法：</p>
<p>打开新的终端窗口<br>使用vi命令，打开<code>/home/oracle/oracle11g/product/11.2.0/dbhome_1/sysman/lib/ins_emagent.mk</code>文件，将$(MK_EMAGENT_NMECTL)修改成$(MK_EMAGENT_NMECTL)-lnnz11 即可，然后点击retry ，接着往下执行</p>
</li>
<li><p>Error in invoking target ‘all_no_orcl’ of makefile ‘/home/oracle/oracle11g/product/11.2.0/dbhome_1/rdbms/lib/ins_rdbms.mk’. See ‘/home/dong/tools/Inventory/logs/installActions2016-03-19_02-37-44PM.log’ for details.</p>
<p>解决办法：</p>
<p>打开一个新的终端，输入如下四个命令：</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">sed -i &apos;s/^\(TNSLSNR_LINKLINE.*\$(TNSLSNR_OFILES)\) \(\$(LINKTTLIBS)\)/\1 -Wl,--no-as-needed \2/g&apos; $ORACLE_HOME/network/lib/env_network.mk</div><div class="line"></div><div class="line">sed -i &apos;s/^\(ORACLE_LINKLINE.*\$(ORACLE_LINKER)\) \(\$(PL_FLAGS)\)/\1 -Wl,--no-as-needed \2/g&apos; $ORACLE_HOME/rdbms/lib/env_rdbms.mk</div><div class="line"></div><div class="line">sed -i &apos;s/^\(\$LD \$LD_RUNTIME\) \(\$LD_OPT\)/\1 -Wl,--no-as-needed \2/g&apos; $ORACLE_HOME/bin/genorasdksh</div><div class="line"></div><div class="line">sed -i &apos;s/^\(\s*\)\(\$(OCRLIBS_DEFAULT)\)/\1 -Wl,--no-as-needed \2/g&apos; $ORACLE_HOME/srvm/lib/ins_srvm.mk</div></pre></td></tr></table></figure>
<p>然后在图形界面点击‘Retry’就能继续安装了。<br>参考</p>
<blockquote>
<p><a href="http://www.jianshu.com/p/9b2f601c275d" target="_blank" rel="external">http://www.jianshu.com/p/9b2f601c275d</a></p>
</blockquote>
<h3 id="然后按照安装程序提示最后执行两个脚本"><a href="#然后按照安装程序提示最后执行两个脚本" class="headerlink" title="然后按照安装程序提示最后执行两个脚本"></a>然后按照安装程序提示最后执行两个脚本</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sudo  /home/oracle/oraInventory/orainstRoot.sh </div><div class="line">sudo /home/oracle/oracle11g/product/11.2.0/dbhome_1/root.sh</div></pre></td></tr></table></figure>
<h3 id="创建监听，执行-netca启动配置界面"><a href="#创建监听，执行-netca启动配置界面" class="headerlink" title="创建监听，执行$ netca启动配置界面"></a>创建监听，执行<code>$ netca</code>启动配置界面</h3><p>参考</p>
<blockquote>
<p><a href="http://www.jianshu.com/p/9b2f601c275d" target="_blank" rel="external">http://www.jianshu.com/p/9b2f601c275d</a></p>
</blockquote>
<p>完成之后，执行命令$ lsnrctl start启动监听服务。</p>
<h3 id="创建数据库实例，执行-dbca启动配置界面"><a href="#创建数据库实例，执行-dbca启动配置界面" class="headerlink" title="创建数据库实例，执行$ dbca启动配置界面"></a>创建数据库实例，执行$ dbca启动配置界面</h3><h3 id="最后验证是否安装成功，浏览器访问"><a href="#最后验证是否安装成功，浏览器访问" class="headerlink" title="最后验证是否安装成功，浏览器访问"></a>最后验证是否安装成功，浏览器访问</h3><p><a href="https://192.168.1.114:1158/em" target="_blank" rel="external">https://192.168.1.114:1158/em</a></p>
<h3 id="创建开机自动启动数据库的脚本"><a href="#创建开机自动启动数据库的脚本" class="headerlink" title="创建开机自动启动数据库的脚本"></a>创建开机自动启动数据库的脚本</h3><p>开一个普通的字符终端连接到UbuntuServer，运行如下命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line"># vi /etc/init.d/oracledb</div><div class="line">文件内容如下：</div><div class="line">#!/bin/bash</div><div class="line">#</div><div class="line"># /etc/init.d/oracledb</div><div class="line">#</div><div class="line"># Run-level Startup script for the Oracle Instance, Listener, and</div><div class="line"># Web Interface</div><div class="line"></div><div class="line">export ORACLE_HOME=/home/oracle/oracle11g/product/11.2.0/dbhome_1</div><div class="line">export ORACLE_SID=orcl</div><div class="line">export PATH=$ORACLE_HOME/bin:$PATH</div><div class="line"></div><div class="line">ORA_OWNR=&quot;oracle&quot;</div><div class="line"># if the executables do not exist -- display error</div><div class="line">if [ ! -f $ORACLE_HOME/bin/dbstart -o ! -d $ORACLE_HOME ]</div><div class="line">then</div><div class="line">echo &quot;Oracle startup: cannot start&quot;</div><div class="line">exit 1</div><div class="line">fi</div><div class="line"># depending on parameter -- startup, shutdown, restart</div><div class="line"># of the instance and listener or usage display</div><div class="line">case &quot;$1&quot; in</div><div class="line">start)</div><div class="line"># Oracle listener and instance startup</div><div class="line">echo -n &quot;Starting Oracle: &quot;</div><div class="line">su $ORA_OWNR -c &quot;$ORACLE_HOME/bin/lsnrctl start&quot;</div><div class="line">su $ORA_OWNR -c &quot;$ORACLE_HOME/bin/dbstart&quot;</div><div class="line">touch /var/lock/oracle</div><div class="line">su $ORA_OWNR -c &quot;$ORACLE_HOME/bin/emctl start dbconsole&quot;</div><div class="line">echo &quot;OK&quot;</div><div class="line">;;</div><div class="line">stop)</div><div class="line"># Oracle listener and instance shutdown</div><div class="line">echo -n &quot;Shutdown Oracle: &quot;</div><div class="line">su $ORA_OWNR -c &quot;$ORACLE_HOME/bin/lsnrctl stop&quot;</div><div class="line">su $ORA_OWNR -c &quot;$ORACLE_HOME/bin/dbshut&quot;</div><div class="line">rm -f /var/lock/oracle</div><div class="line">su $ORA_OWNR -c &quot;$ORACLE_HOME/bin/emctl stop dbconsole&quot;</div><div class="line">echo &quot;OK&quot;</div><div class="line">;;</div><div class="line">reload|restart)</div><div class="line">$0 stop</div><div class="line">$0 start</div><div class="line">;;</div><div class="line">*)</div><div class="line">echo &quot;Usage: `basename $0` start|stop|restart|reload&quot;</div><div class="line">exit 1</div><div class="line">esac</div><div class="line">exit 0</div></pre></td></tr></table></figure></p>
<p>再运行如下命令设置权限，并放到启动脚本中去：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># chmod 755 /etc/init.d/oracledb</div><div class="line"># update-rc.d oracledb defaults 99</div></pre></td></tr></table></figure></p>
<p>最后：<br><code># vi /etc/oratab</code><br>把文件中的N改成Y，即”orcl:/opt/oracle/product/db:N”修改为”orcl:/opt/oracle/product/db:Y”。</p>
<h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">$ ps -ef|grep ora_|grep -v grep  --&gt;查看oracle进程</div><div class="line">$ ps -ef|grep tnslsnr|grep -v grep  --&gt;查看oracle的监听进程</div><div class="line">$ lsnrctl start --&gt;启动监听</div><div class="line">$ dbstart --&gt;启动数据库</div><div class="line">$ dbstop --&gt;停止数据库</div><div class="line">$ emctl start dbconsole --&gt;启动em控制台</div><div class="line">$ isqlplusctl start --&gt;启动pl/sql</div><div class="line">$ sqlplus &apos;/as sysdba&apos; --&gt;登录sqlplus</div><div class="line"></div><div class="line">$ env  --&gt;输出当前用户的环境变量</div><div class="line"></div><div class="line">$ netca --&gt;启用监听配置程序</div></pre></td></tr></table></figure>
<p>参考文章</p>
<blockquote>
<p><a href="http://www.jianshu.com/p/9b2f601c275d" target="_blank" rel="external">CentOS6.7安装Oracle 11g2R傻瓜图文教程</a><br><a href="http://www.jianshu.com/p/4d7ccf6135af" target="_blank" rel="external">Ubuntu 14.04安装Oracle11g 64位</a><br><a href="http://blog.csdn.net/u010286751/article/details/51975741" target="_blank" rel="external">ubuntu16.04安装oracle11g</a><br><a href="http://www.linuxidc.com/Linux/2011-12/48931.htm" target="_blank" rel="external">Ubuntu Server 11.04 安装 Oracle 11g r2 图解教程</a></p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Oracle </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[推荐系统评测指标—准确率(Precision)、召回率(Recall)、F值(F-Measure)]]></title>
      <url>http://yoursite.com/2016/08/17/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AF%84%E6%B5%8B%E6%8C%87%E6%A0%87/</url>
      <content type="html"><![CDATA[<p>下面简单列举几种常用的推荐系统评测指标：</p>
<h3 id="准确率与召回率（Precision-amp-Recall）"><a href="#准确率与召回率（Precision-amp-Recall）" class="headerlink" title="准确率与召回率（Precision &amp; Recall）"></a>准确率与召回率（Precision &amp; Recall）</h3><p><strong>准确率</strong>和<strong>召回率</strong>是广泛用于信息检索和统计学分类领域的两个度量值，用来评价结果的质量。其中精度是检索出相关文档数与检索出的文档总数的比率，衡量的是检索系统的查准率；召回率是指检索出的相关文档数和文档库中所有的相关文档数的比率，衡量的是检索系统的查全率。</p>
<p>一般来说，Precision就是检索出来的条目（比如：文档、网页等）有多少是准确的，Recall就是所有准确的条目有多少被检索出来了。</p>
<p>正确率、召回率和 F 值是在鱼龙混杂的环境中，选出目标的重要评价指标。不妨看看这些指标的定义先：</p>
<ol>
<li><p>正确率 = 提取出的正确信息条数 /  提取出的信息条数     </p>
</li>
<li><p>召回率 = 提取出的正确信息条数 /  样本中的信息条数    </p>
<p>两者取值在0和1之间，数值越接近1，查准率或查全率就越高。   </p>
</li>
<li><p>F值  = 正确率 <em> 召回率 </em> 2 / (正确率 + 召回率) （F 值即为正确率和召回率的调和平均值）</p>
</li>
</ol>
<hr>
<p>放到推荐系统中便是</p>
<p>准确率  = 推荐给user的Items中属于user相关项的个数 / 推荐给user的Items的总个数</p>
<p>召回率  =  推荐给user的Items中属于user相关项的个数 / user的所有相关项item个数</p>
<hr>
<p>不妨举这样一个例子：某池塘有1400条鲤鱼，300只虾，300只鳖。现在以捕鲤鱼为目的。撒一大网，逮着了700条鲤鱼，200只虾，100只鳖。那么，这些指标分别如下：</p>
<p>正确率 = 700 / (700 + 200 + 100) = 70%</p>
<p>召回率 = 700 / 1400 = 50%</p>
<p>F值 = 70% <em> 50% </em> 2 / (70% + 50%) = 58.3%</p>
<p>不妨看看如果把池子里的所有的鲤鱼、虾和鳖都一网打尽，这些指标又有何变化：</p>
<p>正确率 = 1400 / (1400 + 300 + 300) = 70%</p>
<p>召回率 = 1400 / 1400 = 100%</p>
<p>F值 = 70% <em> 100% </em> 2 / (70% + 100%) = 82.35%        </p>
<p>由此可见，正确率是评估捕获的成果中目标成果所占得比例；召回率，顾名思义，就是从关注领域中，召回目标类别的比例；而F值，则是综合这二者指标的评估指标，用于综合反映整体的指标。</p>
<p>当然希望检索结果Precision越高越好，同时Recall也越高越好，但事实上这两者在某些情况下有矛盾的。比如极端情况下，我们只搜索出了一个结果，且是准确的，那么Precision就是100%，但是Recall就很低；而如果我们把所有结果都返回，那么比如Recall是100%，但是Precision就会很低。因此在不同的场合中需要自己判断希望Precision比较高或是Recall比较高。如果是做实验研究，可以绘制Precision-Recall曲线来帮助分析。</p>
<h3 id="综合评价指标（F-Measure）"><a href="#综合评价指标（F-Measure）" class="headerlink" title="综合评价指标（F-Measure）"></a>综合评价指标（F-Measure）</h3><p>P和R指标有时候会出现的矛盾的情况，这样就需要综合考虑他们，最常见的方法就是F-Measure（又称为F-Score）。</p>
<p>F-Measure是Precision和Recall加权调和平均：</p>
<p><img src="http://img.blog.csdn.net/20130808110619562" alt=""></p>
<p>当参数α=1时，就是最常见的F1，也即</p>
<p><img src="http://img.blog.csdn.net/20130808110942546" alt=""></p>
<p>可知F1综合了P和R的结果，当F1较高时则能说明试验方法比较有效。</p>
<h3 id="E值"><a href="#E值" class="headerlink" title="E值"></a>E值</h3><p>E值表示查准率P和查全率R的加权平均值，当其中一个为0时，E值为1，其计算公式：</p>
<p><img src="http://img.blog.csdn.net/20131207154559265" alt=""></p>
<p>b越大，表示查准率的权重越大。</p>
<h3 id="平均正确率（Average-Precision-AP）"><a href="#平均正确率（Average-Precision-AP）" class="headerlink" title="平均正确率（Average Precision, AP）"></a>平均正确率（Average Precision, AP）</h3><p>平均正确率表示不同查全率的点上的正确率的平均。</p>
<p>转载自：</p>
<blockquote>
<p><a href="http://bookshadow.com/weblog/2014/06/10/precision-recall-f-measure/" target="_blank" rel="external">http://bookshadow.com/weblog/2014/06/10/precision-recall-f-measure/</a></p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> 推荐系统 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 推荐系统 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Ubuntu 16.04 mysql安装配置]]></title>
      <url>http://yoursite.com/2016/08/16/Ubuntu%2016.04%20mysql%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/</url>
      <content type="html"><![CDATA[<h3 id="安装mysql"><a href="#安装mysql" class="headerlink" title="安装mysql"></a>安装mysql</h3><p><code>sudo apt-get install mysql-server mysql-client</code></p>
<h3 id="测试是否安装成功"><a href="#测试是否安装成功" class="headerlink" title="测试是否安装成功"></a>测试是否安装成功</h3><p><code>sudo netstat -tap | grep mysql</code></p>
<h3 id="相关操作"><a href="#相关操作" class="headerlink" title="相关操作"></a>相关操作</h3><ul>
<li>登录 <code>mysql -uroot -p</code></li>
<li>检查MySQL服务器占用端口 <code>netstat -nlt|grep 3306</code></li>
<li>检查MySQL服务器系统进程 <code>ps -aux|grep mysql</code></li>
<li>查看数据库的字符集编码 <code>show variables like &#39;%char%&#39;;</code></li>
</ul>
<h3 id="让MySQL服务器被远程访问"><a href="#让MySQL服务器被远程访问" class="headerlink" title="让MySQL服务器被远程访问"></a>让MySQL服务器被远程访问</h3><ul>
<li><p>打开mysql配置文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo vim /etc/mysql/my.cnf</div><div class="line">#找到将bind-address = 127.0.0.1注销​</div><div class="line">#bind-address            = 127.0.0.1</div></pre></td></tr></table></figure>
</li>
<li><p>修改后，重启MySQL服务器<br><code>sudo /etc/init.d/mysql restart</code></p>
</li>
<li><p>重新登录<code>mysql -uroot -p</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">grant all privileges on *.* to &apos;root&apos;@&apos;%&apos; identified by &apos;xxxxxx&apos;;</div><div class="line">flush privileges;</div></pre></td></tr></table></figure>
</li>
<li><p>检查MySQL服务器占用端口</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">~ netstat -nlt|grep 3306</div><div class="line">  tcp        0      0 0.0.0.0:3306            0.0.0.0:*               LISTEN</div></pre></td></tr></table></figure>
</li>
</ul>
<p>我们看到从之间的网络监听从 127.0.0.1:3306 变成 0 0.0.0.0:3306，表示MySQL已经允许远程登陆访问。</p>
<h3 id="将字符编码设置为UTF-8"><a href="#将字符编码设置为UTF-8" class="headerlink" title="将字符编码设置为UTF-8"></a>将字符编码设置为UTF-8</h3><p>默认情况下，MySQL的字符集是latin1，因此在存储中文的时候，会出现乱码的情况，所以我们需要把字符集统一改成UTF-8。<br>打开mysql配置文件<br><code>sudo vim /etc/mysql/my.cnf</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">a） 打开mysql配置文件：</div><div class="line"></div><div class="line">                vim/etc/mysql/my.cnf</div><div class="line">b） 在[client]下追加：</div><div class="line"></div><div class="line">                default-character-set=utf8</div><div class="line">c） 在[mysqld]下追加：</div><div class="line"></div><div class="line">                character-set-server=utf8</div><div class="line">d） 在[mysql]下追加：</div><div class="line"></div><div class="line">                default-character-set=utf8</div></pre></td></tr></table></figure>
<p>修改后，重启MySQL服务器,并登录<br><code>mysql -uroot -p</code></p>
<p>再次查看字符串编码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">mysql&gt; show variables like &apos;%char%&apos;;</div><div class="line">+--------------------------+----------------------------+</div><div class="line">| Variable_name            | Value                      |</div><div class="line">+--------------------------+----------------------------+</div><div class="line">| character_set_client     | utf8                       |</div><div class="line">| character_set_connection | utf8                       |</div><div class="line">| character_set_database   | utf8                       |</div><div class="line">| character_set_filesystem | binary                     |</div><div class="line">| character_set_results    | utf8                       |</div><div class="line">| character_set_server     | utf8                       |</div><div class="line">| character_set_system     | utf8                       |</div><div class="line">| character_sets_dir       | /usr/share/mysql/charsets/ |</div><div class="line">+--------------------------+----------------------------+</div><div class="line">8 rows in set (0.00 sec)</div></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Mahout0.10.1安装]]></title>
      <url>http://yoursite.com/2016/08/15/Mahout0.10.1%E5%AE%89%E8%A3%85/</url>
      <content type="html"><![CDATA[<h3 id="解压安装包"><a href="#解压安装包" class="headerlink" title="解压安装包"></a>解压安装包</h3><h3 id="编辑环境变量"><a href="#编辑环境变量" class="headerlink" title="编辑环境变量"></a>编辑环境变量</h3><p><code>sudo vim /etc/profile</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">#MAHOUT</div><div class="line">export MAHOUT_HOME=/home/ubuntu/cloud/mahout-0.10.1</div><div class="line">export MAHOUT_CONF_DIR=$MAHOUT_HOME/conf</div><div class="line">export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop</div><div class="line"></div><div class="line">export PATH=$PATH:$&#123;JAVA_HOME&#125;/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$MAHOUT_HOME/conf:$MAHOUT_HOME/bin:</div></pre></td></tr></table></figure></p>
<h3 id="更新配置"><a href="#更新配置" class="headerlink" title="更新配置"></a>更新配置</h3><p><code>source /etc/profile</code></p>
<h3 id="输入mahout测试-出现许多算法"><a href="#输入mahout测试-出现许多算法" class="headerlink" title="输入mahout测试 出现许多算法"></a>输入mahout测试 出现许多算法</h3><h3 id="进行kmeans算法简单运行"><a href="#进行kmeans算法简单运行" class="headerlink" title="进行kmeans算法简单运行"></a>进行kmeans算法简单运行</h3><ul>
<li>下载测试数据集synthetic_control.data<br> <a href="http://archive.ics.uci.edu/ml/databases/synthetic_control/" target="_blank" rel="external">http://archive.ics.uci.edu/ml/databases/synthetic_control/</a></li>
<li>在hdfs上创建目录  <code>/user/ubuntu/testdata</code></li>
<li>上传测试数据<br><code>hadoop fs -put synthetic_control.data /user/ubuntu/testdata</code>  </li>
<li>运行<br><code>mahout org.apache.mahout.clustering.syntheticcontrol.kmeans.Job</code></li>
</ul>
<p>参考</p>
<blockquote>
<p><a href="http://www.cnblogs.com/zhangduo/p/4679907.html" target="_blank" rel="external">http://www.cnblogs.com/zhangduo/p/4679907.html</a></p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Mahout </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hadoop2.7.2集群搭建]]></title>
      <url>http://yoursite.com/2016/08/15/Hadoop2.7.2%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</url>
      <content type="html"><![CDATA[<h3 id="四台电脑集群"><a href="#四台电脑集群" class="headerlink" title="四台电脑集群"></a>四台电脑集群</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">192.168.1.111   master</div><div class="line">192.168.1.112   slave1</div><div class="line">192.168.1.113   slave2</div><div class="line">192.168.1.114   slave3</div></pre></td></tr></table></figure>
<h3 id="修改hosts"><a href="#修改hosts" class="headerlink" title="修改hosts"></a>修改hosts</h3><p><code>vim /etc/hosts</code></p>
<h3 id="配置master到其它三台slave的免密码登陆"><a href="#配置master到其它三台slave的免密码登陆" class="headerlink" title="配置master到其它三台slave的免密码登陆"></a>配置master到其它三台slave的免密码登陆</h3><p>各服务器上使用   ssh-keygen -t rsa    一路按回车就行了。<br>刚才都作甚了呢？主要是设置ssh的密钥和密钥的存放路径。 路径为~/.ssh下。<br>打开~/.ssh 下面有三个文件<br>authorized_keys，已认证的keys<br>id_rsa，私钥<br>id_rsa.pub，公钥   三个文件。<br>下面就是关键的地方了，（我们要做ssh认证。进行下面操作前，可以先搜关于认证和加密区别以及各自的过程。）<br>①在master上将公钥放到authorized_keys里。命令：<br><code>sudo cat id_rsa.pub &gt;&gt; authorized_keys</code><br>②将master上的authorized_keys放到其他linux的~/.ssh目录下。命令：<br><code>sudo scp authorized_keys ubuntu@192.168.1.112:~/.ssh</code><br>sudo scp authorized_keys 远程主机用户名@远程主机名或ip:存放路径。<br>③修改authorized_keys权限，命令：chmod 644 authorized_keys<br>④测试是否成功<br>ssh slave1 输入用户名密码，然后退出，再次ssh slave1不用密码，直接进入系统。这就表示成功了。</p>
<h3 id="安装jdk1-7"><a href="#安装jdk1-7" class="headerlink" title="安装jdk1.7"></a>安装jdk1.7</h3><ol>
<li><code>mkdir /usr/java</code></li>
<li><code>sudo tar -zxvf jdk-7u79-linux-x64.tar.gz -C /usr/java</code></li>
<li><p><code>vim /etc/profile</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">export JAVA_HOME=/usr/java/jdk1.7.0_79</div><div class="line">export CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/lib</div><div class="line">export PATH=$&#123;JAVA_HOME&#125;/bin:$PATH</div></pre></td></tr></table></figure>
</li>
<li><p>刷新配置<br><code>source /etc/profile</code></p>
</li>
<li>测试<br><code>java -version</code></li>
</ol>
<h3 id="关闭每台机器的防火墙"><a href="#关闭每台机器的防火墙" class="headerlink" title="关闭每台机器的防火墙"></a>关闭每台机器的防火墙</h3><p><code>sudo ufw disable</code> (重启生效)</p>
<h3 id="创建-home-cloud目录"><a href="#创建-home-cloud目录" class="headerlink" title="创建/home/cloud目录"></a>创建/home/cloud目录</h3><p><code>mkdir ~/cloud</code></p>
<h3 id="解压hadoop"><a href="#解压hadoop" class="headerlink" title="解压hadoop"></a>解压hadoop</h3><p><code>tar -zxvf hadoop-2.7.2.tar.gz -C ./cloud</code></p>
<h3 id="配置hadoop-env-sh-yarn-env-sh"><a href="#配置hadoop-env-sh-yarn-env-sh" class="headerlink" title="配置hadoop-env.sh yarn-env.sh"></a>配置hadoop-env.sh yarn-env.sh</h3><p>修改JAVA_HOME值<code>export JAVA_HOME=/usr/java/jdk1.7.0_79</code></p>
<h3 id="创建文件夹"><a href="#创建文件夹" class="headerlink" title="创建文件夹"></a>创建文件夹</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">mkdir /home/ubuntu/cloud/hadoop-2.7.2/tmp</div><div class="line">mkdir /home/ubuntu/cloud/hadoop-2.7.2/dfs/data</div><div class="line">mkdir /home/ubuntu/cloud/hadoop-2.7.2/dfs/name</div></pre></td></tr></table></figure>
<h3 id="配置slaves"><a href="#配置slaves" class="headerlink" title="配置slaves"></a>配置slaves</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">slave1</div><div class="line">slave2</div><div class="line">slave3</div></pre></td></tr></table></figure>
<h3 id="配置core-site-xml"><a href="#配置core-site-xml" class="headerlink" title="配置core-site.xml"></a>配置core-site.xml</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">       &lt;property&gt;</div><div class="line">                &lt;name&gt;fs.defaultFS&lt;/name&gt;</div><div class="line">                &lt;value&gt;hdfs://master:9000&lt;/value&gt;</div><div class="line">       &lt;/property&gt;</div><div class="line">       &lt;property&gt;</div><div class="line">                &lt;name&gt;io.file.buffer.size&lt;/name&gt;</div><div class="line">                &lt;value&gt;131072&lt;/value&gt;</div><div class="line">        &lt;/property&gt;</div><div class="line">       &lt;property&gt;</div><div class="line">               &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</div><div class="line">               &lt;value&gt;file:/home/ubuntu/cloud/hadoop-2.7.2/tmp&lt;/value&gt;</div><div class="line">               &lt;description&gt;Abase for other temporary   directories.&lt;/description&gt;</div><div class="line">       &lt;/property&gt;</div><div class="line">        &lt;property&gt;</div><div class="line">               &lt;name&gt;hadoop.proxyuser.ubuntu.hosts&lt;/name&gt;</div><div class="line">               &lt;value&gt;*&lt;/value&gt;</div><div class="line">       &lt;/property&gt;</div><div class="line">       &lt;property&gt;</div><div class="line">               &lt;name&gt;hadoop.proxyuser.ubuntu.groups&lt;/name&gt;</div><div class="line">               &lt;value&gt;*&lt;/value&gt;</div><div class="line">       &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<h3 id="配置hdfs-site-xml"><a href="#配置hdfs-site-xml" class="headerlink" title="配置hdfs-site.xml"></a>配置hdfs-site.xml</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;  </div><div class="line">    &lt;property&gt;  </div><div class="line">        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;  </div><div class="line">        &lt;value&gt;master:9001&lt;/value&gt;  </div><div class="line">    &lt;/property&gt;  </div><div class="line">    &lt;property&gt;  </div><div class="line">        &lt;name&gt;dfs.replication&lt;/name&gt;  </div><div class="line">        &lt;value&gt;4&lt;/value&gt;  </div><div class="line">    &lt;/property&gt;  </div><div class="line">    &lt;property&gt;  </div><div class="line">        &lt;name&gt;dfs.permissions.enabled&lt;/name&gt;  </div><div class="line">        &lt;value&gt;false&lt;/value&gt;  </div><div class="line">    &lt;/property&gt;  </div><div class="line">    &lt;property&gt;  </div><div class="line">        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;  </div><div class="line">        &lt;value&gt;file:/home/ubuntu/cloud/hadoop-2.7.2/dfs/name&lt;/value&gt;  </div><div class="line">    &lt;/property&gt;  </div><div class="line">    &lt;property&gt;  </div><div class="line">        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;  </div><div class="line">        &lt;value&gt;file:/home/ubuntu/cloud/hadoop-2.7.2/dfs/data&lt;/value&gt;  </div><div class="line">    &lt;/property&gt;  </div><div class="line">    &lt;property&gt;  </div><div class="line">        &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;  </div><div class="line">        &lt;value&gt;true&lt;/value&gt;  </div><div class="line">    &lt;/property&gt;  </div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<h3 id="配置mapred-site-xml"><a href="#配置mapred-site-xml" class="headerlink" title="配置mapred-site.xml"></a>配置mapred-site.xml</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">          &lt;property&gt;                                                                  &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</div><div class="line">                &lt;value&gt;yarn&lt;/value&gt;</div><div class="line">           &lt;/property&gt;</div><div class="line">          &lt;property&gt;</div><div class="line">                  &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</div><div class="line">                  &lt;value&gt;master:10020&lt;/value&gt;</div><div class="line">          &lt;/property&gt;</div><div class="line">          &lt;property&gt;</div><div class="line">                &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</div><div class="line">                &lt;value&gt;master:19888&lt;/value&gt;</div><div class="line">       &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<h3 id="配置yarn-site-xml"><a href="#配置yarn-site-xml" class="headerlink" title="配置yarn-site.xml"></a>配置yarn-site.xml</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">        &lt;property&gt;</div><div class="line">               &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</div><div class="line">               &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</div><div class="line">        &lt;/property&gt;</div><div class="line">        &lt;property&gt;                                                                </div><div class="line">            &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;</div><div class="line">               &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;</div><div class="line">        &lt;/property&gt;</div><div class="line">        &lt;property&gt;</div><div class="line">               &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;</div><div class="line">               &lt;value&gt;master:8032&lt;/value&gt;</div><div class="line">       &lt;/property&gt;</div><div class="line">       &lt;property&gt;</div><div class="line">               &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;</div><div class="line">               &lt;value&gt;master:8030&lt;/value&gt;</div><div class="line">       &lt;/property&gt;</div><div class="line">       &lt;property&gt;</div><div class="line">            &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;</div><div class="line">             &lt;value&gt;master:8031&lt;/value&gt;</div><div class="line">      &lt;/property&gt;</div><div class="line">      &lt;property&gt;</div><div class="line">              &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;</div><div class="line">               &lt;value&gt;master:8033&lt;/value&gt;</div><div class="line">       &lt;/property&gt;</div><div class="line">       &lt;property&gt;</div><div class="line">               &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;</div><div class="line">               &lt;value&gt;master:8088&lt;/value&gt;</div><div class="line">       &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<h3 id="复制到其它节点"><a href="#复制到其它节点" class="headerlink" title="复制到其它节点"></a>复制到其它节点</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo scp -r /home/ubuntu/cloud ubuntu@slave1:~/</div><div class="line">sudo scp -r /home/ubuntu/cloud ubuntu@slave2:~/</div><div class="line">sudo scp -r /home/ubuntu/cloud ubuntu@slave3:~/</div></pre></td></tr></table></figure>
<h3 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h3><p><code>vim /etc/profile</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">export HADOOP_HOME=/home/ubuntu/cloud/hadoop-2.7.2</div><div class="line">export PATH=$PATH:$&#123;JAVA_HOME&#125;/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:</div></pre></td></tr></table></figure></p>
<h3 id="启动hadoop"><a href="#启动hadoop" class="headerlink" title="启动hadoop"></a>启动hadoop</h3><ul>
<li>格式化namenode <code>hadoop namenode –format</code></li>
<li>启动hdfs <code>start-dfs.sh</code></li>
<li>启动yarn <code>start-yarn.sh</code></li>
<li>web端查看 <code>http://master:8088 http://master:50070</code></li>
</ul>
]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[ubuntu相关设置]]></title>
      <url>http://yoursite.com/2016/08/15/ubuntu%E7%9B%B8%E5%85%B3%E8%AE%BE%E7%BD%AE/</url>
      <content type="html"><![CDATA[<h3 id="修改时区"><a href="#修改时区" class="headerlink" title="修改时区"></a>修改时区</h3><p><code>sudo dpkg-reconfigure tzdata</code></p>
<p>出现时区列表，按照提示选择“Asia/Shanghai”</p>
<p>结果如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">Package configuration</div><div class="line"></div><div class="line">     ┌───────────────────────┤ Configuring tzdata ├───────────────────────┐</div><div class="line">     │ Please select the city or region corresponding to your time zone.  │</div><div class="line">     │                                                                    │</div><div class="line">     │ Time zone:                                                         │</div><div class="line">     │                                                                    │</div><div class="line">     │                          Qyzylorda        ↑                        │</div><div class="line">     │                          Rangoon          ▒                        │</div><div class="line">     │                          Riyadh           ▒                        │</div><div class="line">     │                          Sakhalin         ▒                        │</div><div class="line">     │                          Samarkand        ▒                        │</div><div class="line">     │                          Seoul            ▒                        │</div><div class="line">     │                          Shanghai         ▮                        │</div><div class="line">     │                          Singapore        ▒                        │</div><div class="line">     │                          Srednekolymsk    ▒                        │</div><div class="line">     │                          Taipei           ↓                        │</div><div class="line">     │                                                                    │</div><div class="line">     │                                                                    │</div><div class="line">     │                 &lt;Ok&gt;                     &lt;Cancel&gt;                  │</div><div class="line">     │                                                                    │</div><div class="line">     └────────────────────────────────────────────────────────────────────┘</div><div class="line"></div><div class="line">                                                                               </div><div class="line">Current default time zone: &apos;Asia/Shanghai&apos;</div><div class="line">Local time is now:      Mon Aug 15 00:11:59 CST 2016.</div><div class="line">Universal Time is now:  Sun Aug 14 16:11:59 UTC 2016.</div><div class="line"></div><div class="line">ubuntu@master:~$ date</div><div class="line">Mon Aug 15 00:12:13 CST 2016</div></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux技巧 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[ubuntu设置静态ip]]></title>
      <url>http://yoursite.com/2016/08/14/ubuntu%E8%AE%BE%E7%BD%AE%E9%9D%99%E6%80%81ip/</url>
      <content type="html"><![CDATA[<h3 id="找到文件并作如下修改"><a href="#找到文件并作如下修改" class="headerlink" title="找到文件并作如下修改"></a>找到文件并作如下修改</h3><p><code>sudo vim /etc/network/interfaces</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"># The primary network interface</div><div class="line">auto eno1</div><div class="line">iface eno1 inet static</div><div class="line">        address 192.168.1.111</div><div class="line">        netmask 255.255.255.0</div><div class="line">        network 192.168.1.0</div><div class="line">        broadcast 192.168.1.255</div><div class="line">        gateway 192.168.1.1</div><div class="line">        # dns-* options are implemented by the resolvconf package, if installed</div><div class="line">        dns-nameservers 202.101.172.35 202.101.172.46</div></pre></td></tr></table></figure>
<h3 id="修改dns解析"><a href="#修改dns解析" class="headerlink" title="修改dns解析"></a>修改dns解析</h3><p>因为以前是dhcp解析，所以会自动分配dns服务器地址</p>
<p>而一旦设置为静态ip后就没有自动获取到的dns服务器了</p>
<p>要自己设置一个</p>
<p><code>sudo vim /etc/resolv.conf</code></p>
<p>写上一个公网的DNS,以下为浙江杭州电信DNS</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"># Dynamic resolv.conf(5) file for glibc resolver(3) generated by resolvconf(8)</div><div class="line">#     DO NOT EDIT THIS FILE BY HAND -- YOUR CHANGES WILL BE OVERWRITTEN</div><div class="line">nameserver 202.101.172.35</div><div class="line">nameserver 202.101.172.46</div></pre></td></tr></table></figure>
<p>（注意：8.8.8.8是谷歌的DNS服务器，但是解析速度慢，还是找到一个国内的dns来用）</p>
<h3 id="重启网卡"><a href="#重启网卡" class="headerlink" title="重启网卡"></a>重启网卡</h3><p><code>sudo /etc/init.d/networking restart</code></p>
]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> linux网络 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[JVM内存配置]]></title>
      <url>http://yoursite.com/2016/07/26/JVM%E5%86%85%E5%AD%98%E9%85%8D%E7%BD%AE/</url>
      <content type="html"><![CDATA[<p>参数中-vmargs的意思是设置JVM参数，所以后面的其实都是JVM的参数了，我们首先了解一下JVM内存管理的机制，然后再解释每个参数代表的含义。</p>
<h3 id="堆-Heap-和非堆-Non-heap-内存"><a href="#堆-Heap-和非堆-Non-heap-内存" class="headerlink" title="堆(Heap)和非堆(Non-heap)内存"></a>堆(Heap)和非堆(Non-heap)内存</h3><p>按照官方的说法：“Java虚拟机具有一个堆，堆是运行时数据区域，所有类实例和数组的内存均从此处分配。堆是在Java虚拟机启动时创建的。”“在JVM中堆之外的内存称为非堆内存(Non-heapmemory)”。可以看出JVM主要管理两种类型的内存：堆和非堆。简单来说堆就是Java代码可及的内存，是留给开发人员使用的；非堆就是JVM留给自己用的，所以方法区、JVM内部处理或优化所需的内存(如JIT编译后的代码缓存)、每个类结构(如运行时常数池、字段和方法数据)以及方法和构造方法的代码都在非堆内存中。</p>
<h3 id="堆内存分配"><a href="#堆内存分配" class="headerlink" title="堆内存分配"></a>堆内存分配</h3><p>JVM初始分配的内存由-Xms指定，默认是物理内存的1/64；JVM最大分配的内存由-Xmx指定，默认是物理内存的1/4。默认空余堆内存小于40%时，JVM就会增大堆直到-Xmx的最大限制；空余堆内存大于70%时，JVM会减少堆直到-Xms的最小限制。因此服务器一般设置-Xms、-Xmx相等以避免在每次GC后调整堆的大小。</p>
<p>非堆内存分配</p>
<p>JVM使用-XX:PermSize设置非堆内存初始值，默认是物理内存的1/64；由XX:MaxPermSize设置最大非堆内存的大小，默认是物理内存的1/4。</p>
<h3 id="JVM内存限制-最大值"><a href="#JVM内存限制-最大值" class="headerlink" title="JVM内存限制(最大值)"></a>JVM内存限制(最大值)</h3><p>首先JVM内存限制于实际的最大物理内存(废话！呵呵)，假设物理内存无限大的话，JVM内存的最大值跟操作系统有很大的关系。简单的说就32位处理器虽然可控内存空间有4GB,但是具体的操作系统会给一个限制，这个限制一般是2GB-3GB（一般来说Windows系统下为1.5G-2G，Linux系统下为2G-3G），而64bit以上的处理器就不会有限制了。</p>
<h3 id="减少jvm内存回收引起的eclipse卡的问题"><a href="#减少jvm内存回收引起的eclipse卡的问题" class="headerlink" title="减少jvm内存回收引起的eclipse卡的问题"></a>减少jvm内存回收引起的eclipse卡的问题</h3><p>这个主要是jvm在client模式，进行内存回收时，会停下所有的其它工作，带回收完毕才去执行其它任务，在这期间eclipse就卡住了。所以适当的增加jvm申请的内存大小来减少其回收的次数甚至不回收，就会是卡的现象有明显改善。 </p>
<p>主要通过以下的几个jvm参数来设置堆内存的： </p>
<ul>
<li>-Xmx512m    最大总堆内存，一般设置为物理内存的1/4</li>
<li>-Xms512m    初始总堆内存，一般将它设置的和最大堆内存一样大，这样就不需要根据当前堆使用情况而调整堆的大小了</li>
<li>-Xmn192m    年轻带堆内存，sun官方推荐为整个堆的3/8</li>
<li>堆内存的组成    总堆内存 = 年轻带堆内存 + 年老带堆内存 + 持久带堆内存</li>
<li>年轻带堆内存    对象刚创建出来时放在这里</li>
<li>年老带堆内存    对象在被真正会回收之前会先放在这里</li>
<li>持久带堆内存    class文件，元数据等放在这里</li>
<li>-XX:PermSize=128m    持久带堆的初始大小</li>
<li>-XX:MaxPermSize=128m    持久带堆的最大大小，eclipse默认为256m。如果要编译jdk这种，一定要把这个设的很大，因为它的类太多了。</li>
</ul>
<h3 id="eclipse运行配置"><a href="#eclipse运行配置" class="headerlink" title="eclipse运行配置"></a>eclipse运行配置</h3><p>Eclipse -&gt; Run -&gt; Run Configurations -&gt; Arguments -&gt; VM arguments<br>或者 Run as -&gt; Run Configurations -&gt; Arguments -&gt; VM arguments<br> -Xms2048m -Xmx2048m<br><img src="http://i.imgur.com/O2JUIKO.png" alt=""></p>
<p>-Xms是设置内存初始化的大小(如上面的2048m)<br>-Xmx是设置最大能够使用内存的大小（如上面的2048m, 最好不要超过物理内存）<br>也可通过 eclipse.ini配置</p>
<p>参考文章：<br><a href="http://blog.csdn.net/gf771115/article/details/20220915" target="_blank" rel="external">Eclipse中进行JVM内存设置</a><br><a href="http://blog.csdn.net/buptdavid/article/details/43270997" target="_blank" rel="external">JVM监控与调优</a><br><a href="http://blog.csdn.net/wuzhilon88/article/details/49201891" target="_blank" rel="external">JVM调优总结(这个总结得比较全面)</a><br><a href="http://uule.iteye.com/blog/2114697" target="_blank" rel="external">JVM性能调优</a></p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> JVM </tag>
            
            <tag> eclipse </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Mahout Item-based推荐的分布式实现]]></title>
      <url>http://yoursite.com/2016/07/25/Mahout%20Item-based%E6%8E%A8%E8%8D%90%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9E%E7%8E%B0/</url>
      <content type="html"><![CDATA[<p>Mahout API地址：<a href="http://apache.github.io/mahout/0.10.1/docs/mahout-mr/overview-summary.html" target="_blank" rel="external">http://apache.github.io/mahout/0.10.1/docs/mahout-mr/overview-summary.html</a></p>
<blockquote>
<p><a href="http://blog.fens.me/mahout-recommendation-api/" target="_blank" rel="external">Mahout推荐算法API详解</a></p>
</blockquote>
<h2 id="Mahout算法框架自带的推荐器有下面这些："><a href="#Mahout算法框架自带的推荐器有下面这些：" class="headerlink" title="Mahout算法框架自带的推荐器有下面这些："></a>Mahout算法框架自带的推荐器有下面这些：</h2><ul>
<li>GenericUserBasedRecommender：基于用户的推荐器，用户数量少时速度快；</li>
<li>GenericItemBasedRecommender：基于商品推荐器，商品数量少时速度快，尤其当外部提供了商品相似度数据后效率更好；</li>
<li>SlopeOneRecommender：基于slope-one算法的推荐器，在线推荐或更新较快，需要事先大量预处理运算，物品数量少时较好；</li>
<li>SVDRecommender：奇异值分解，推荐效果较好，但之前需要大量预处理运算；</li>
<li>KnnRecommender：基于k近邻算法(KNN)，适合于物品数量较小时；</li>
<li>TreeClusteringRecommender：基于聚类的推荐器，在线推荐较快，之前需要大量预处理运算，用户数量较少时效果好；</li>
<li>Mahout最常用的三个推荐器是上述的前三个，本文主要讨论前两种的使用。</li>
</ul>
<h2 id="接口相关介绍"><a href="#接口相关介绍" class="headerlink" title="接口相关介绍"></a>接口相关介绍</h2><p>基于用户或物品的推荐器主要包括以下几个接口：</p>
<p><code>DataModel</code> 是用户喜好信息的抽象接口，它的具体实现支持从任意类型的数据源抽取用户喜好信息。Taste 默认提供 JDBCDataModel 和 FileDataModel，分别支持从数据库和文件中读取用户的喜好信息。<br><code>UserSimilarity</code> 和 <code>ItemSimilarity</code>。UserSimilarity 用于定义两个用户间的相似度，它是基于协同过滤的推荐引擎的核心部分，可以用来计算用户的“邻居”，这里我们将与当前用户口味相似的用户称为他的邻居。ItemSimilarity 类似的，计算内容之间的相似度。<br><code>UserNeighborhood</code> 用于基于用户相似度的推荐方法中，推荐的内容是基于找到与当前用户喜好相似的邻居用户的方式产生的。UserNeighborhood 定义了确定邻居用户的方法，具体实现一般是基于 UserSimilarity 计算得到的。<br><code>Recommender</code> 是推荐引擎的抽象接口，Taste 中的核心组件。程序中，为它提供一个 DataModel，它可以计算出对不同用户的推荐内容。实际应用中，主要使用它的实现类 <code>GenericUserBasedRecommender</code> 或者 <code>GenericItemBasedRecommender</code>，分别实现基于用户相似度的推荐引擎或者基于内容的推荐引擎。<br><code>RecommenderEvaluator</code>：评分器。<br><code>RecommenderIRStatsEvaluator</code>：搜集推荐性能相关的指标，包括准确率、召回率等等。<br>目前，Mahout为DataModel提供了以下几种实现：</p>
<ul>
<li>org.apache.mahout.cf.taste.impl.model.GenericDataModel</li>
<li>org.apache.mahout.cf.taste.impl.model.GenericBooleanPrefDataModel</li>
<li>org.apache.mahout.cf.taste.impl.model.PlusAnonymousUserDataModel</li>
<li>org.apache.mahout.cf.taste.impl.model.file.FileDataModel</li>
<li>org.apache.mahout.cf.taste.impl.model.hbase.HBaseDataModel</li>
<li>org.apache.mahout.cf.taste.impl.model.cassandra.CassandraDataModel</li>
<li>org.apache.mahout.cf.taste.impl.model.mongodb.MongoDBDataModel</li>
<li>org.apache.mahout.cf.taste.impl.model.jdbc.SQL92JDBCDataModel</li>
<li>org.apache.mahout.cf.taste.impl.model.jdbc.MySQLJDBCDataModel</li>
<li>org.apache.mahout.cf.taste.impl.model.jdbc.PostgreSQLJDBCDataModel</li>
<li>org.apache.mahout.cf.taste.impl.model.jdbc.GenericJDBCDataModel</li>
<li>org.apache.mahout.cf.taste.impl.model.jdbc.SQL92BooleanPrefJDBCDataModel</li>
<li>org.apache.mahout.cf.taste.impl.model.jdbc.MySQLBooleanPrefJDBCDataModel</li>
<li>org.apache.mahout.cf.taste.impl.model.jdbc.PostgreBooleanPrefSQLJDBCDataModel</li>
<li>org.apache.mahout.cf.taste.impl.model.jdbc.ReloadFromJDBCDataModel<br>从类名上就可以大概猜出来每个DataModel的用途，奇怪的是竟然没有HDFS的DataModel，有人实现了一个，请参考<a href="https://issues.apache.org/jira/browse/MAHOUT-1579" target="_blank" rel="external">MAHOUT-1579</a>。</li>
</ul>
<p><code>UserSimilarity</code> 和 <code>ItemSimilarity</code> 相似度实现有以下几种：</p>
<ul>
<li><code>CityBlockSimilarity</code>：基于Manhattan距离相似度</li>
<li><code>EuclideanDistanceSimilarity</code>：基于欧几里德距离计算相似度</li>
<li><code>LogLikelihoodSimilarity</code>：基于对数似然比的相似度</li>
<li><code>PearsonCorrelationSimilarity</code>：基于皮尔逊相关系数计算相似度</li>
<li><code>SpearmanCorrelationSimilarity</code>：基于皮尔斯曼相关系数相似度</li>
<li><code>TanimotoCoefficientSimilarity</code>：基于谷本系数计算相似度</li>
<li><code>UncenteredCosineSimilarity</code>：计算 Cosine 相似度<br>以上相似度的说明，请参考Mahout推荐引擎介绍。</li>
</ul>
<p>UserNeighborhood 主要实现有两种：</p>
<ul>
<li>NearestNUserNeighborhood：对每个用户取固定数量N个最近邻居</li>
<li>ThresholdUserNeighborhood：对每个用户基于一定的限制，取落在相似度限制以内的所有用户为邻居</li>
</ul>
<p>Recommender分为以下几种实现：</p>
<ul>
<li>GenericUserBasedRecommender：基于用户的推荐引擎</li>
<li>GenericBooleanPrefUserBasedRecommender：基于用户的无偏好值推荐引擎</li>
<li>GenericItemBasedRecommender：基于物品的推荐引擎</li>
<li>GenericBooleanPrefItemBasedRecommender：基于物品的无偏好值推荐引擎</li>
</ul>
<p>RecommenderEvaluator有以下几种实现：</p>
<ul>
<li>AverageAbsoluteDifferenceRecommenderEvaluator：计算平均差值</li>
<li>RMSRecommenderEvaluator：计算均方根差</li>
<li>RecommenderIRStatsEvaluator的实现类是GenericRecommenderIRStatsEvaluator。</li>
</ul>
<h2 id="单机运行"><a href="#单机运行" class="headerlink" title="单机运行"></a>单机运行</h2><p>首先，需要在maven中加入对mahout的依赖：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;org.apache.mahout&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;mahout-core&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;0.9&lt;/version&gt;</div><div class="line">&lt;/dependency&gt;</div><div class="line"></div><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;org.apache.mahout&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;mahout-integration&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;0.9&lt;/version&gt;</div><div class="line">&lt;/dependency&gt;</div><div class="line"></div><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;org.apache.mahout&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;mahout-math&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;0.9&lt;/version&gt;</div><div class="line">&lt;/dependency&gt;</div><div class="line"></div><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;org.apache.mahout&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;mahout-examples&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;0.9&lt;/version&gt;</div><div class="line">&lt;/dependency&gt;</div></pre></td></tr></table></figure></p>
<p>基于用户的推荐，以FileDataModel为例：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">File modelFile modelFile = new File(&quot;intro.csv&quot;);</div><div class="line"></div><div class="line">DataModel model = new FileDataModel(modelFile);</div><div class="line"></div><div class="line">//用户相似度，使用基于皮尔逊相关系数计算相似度</div><div class="line">UserSimilarity similarity = new PearsonCorrelationSimilarity(model);</div><div class="line"></div><div class="line">//选择邻居用户，使用NearestNUserNeighborhood实现UserNeighborhood接口，选择邻近的4个用户</div><div class="line">UserNeighborhood neighborhood = new NearestNUserNeighborhood(4, similarity, model);</div><div class="line"></div><div class="line">Recommender recommender = new GenericUserBasedRecommender(model, neighborhood, similarity);</div><div class="line"></div><div class="line">//给用户1推荐4个物品</div><div class="line">List&lt;RecommendedItem&gt; recommendations = recommender.recommend(1, 4);</div><div class="line"></div><div class="line">for (RecommendedItem recommendation : recommendations) &#123;</div><div class="line">    System.out.println(recommendation);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<blockquote>
<p>注意： FileDataModel要求输入文件中的字段分隔符为逗号或者制表符，如果你想使用其他分隔符，你可以扩展一个FileDataModel的实现，例如，mahout中已经提供了一个解析MoiveLens的数据集（分隔符为::）的实现GroupLensDataModel。</p>
</blockquote>
<p><code>GenericUserBasedRecommender</code>是基于用户的简单推荐器实现类，推荐主要参照传入的DataModel和UserNeighborhood，总体是三个步骤：</p>
<ol>
<li>从UserNeighborhood获取当前用户Ui最相似的K个用户集合{U1, U2, …Uk}；</li>
<li>从这K个用户集合排除Ui的偏好商品，剩下的Item集合为{Item0, Item1, …Itemm}；</li>
<li>对Item集合里每个Itemj计算Ui可能偏好程度值pref(Ui, Itemj)，并把Item按此数值从高到低排序，前N个item推荐给用户Ui。</li>
<li>对相同用户重复获得推荐结果，我们可以改用CachingRecommender来包装GenericUserBasedRecommender对象，将推荐结果缓存起来：</li>
</ol>
<p><code>Recommender cachingRecommender = new CachingRecommender(recommender);</code></p>
<p>上面代码可以在main方法中直接运行，然后，我们可以获取推荐模型的评分：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">//使用平均绝对差值获得评分</div><div class="line">RecommenderEvaluator evaluator = new AverageAbsoluteDifferenceRecommenderEvaluator();</div><div class="line">// 用RecommenderBuilder构建推荐引擎</div><div class="line">RecommenderBuilder recommenderBuilder = new RecommenderBuilder() &#123;</div><div class="line">    @Override</div><div class="line">    public Recommender buildRecommender(DataModel model) throws TasteException &#123;</div><div class="line">        UserSimilarity similarity = new PearsonCorrelationSimilarity(model);</div><div class="line">        UserNeighborhood neighborhood = new NearestNUserNeighborhood(4, similarity, model);</div><div class="line">        return new GenericUserBasedRecommender(model, neighborhood, similarity);</div><div class="line">    &#125;</div><div class="line">&#125;;</div><div class="line">// Use 70% of the data to train; test using the other 30%.</div><div class="line">double score = evaluator.evaluate(recommenderBuilder, null, model, 0.7, 1.0);</div><div class="line">System.out.println(score);</div></pre></td></tr></table></figure></p>
<p>接下来，可以获取推荐结果的查准率和召回率：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">RecommenderIRStatsEvaluator statsEvaluator = new GenericRecommenderIRStatsEvaluator();</div><div class="line">// Build the same recommender for testing that we did last time:</div><div class="line">RecommenderBuilder recommenderBuilder = new RecommenderBuilder() &#123;</div><div class="line">    @Override</div><div class="line">    public Recommender buildRecommender(DataModel model) throws TasteException &#123;</div><div class="line">        UserSimilarity similarity = new PearsonCorrelationSimilarity(model);</div><div class="line">        UserNeighborhood neighborhood = new NearestNUserNeighborhood(4, similarity, model);</div><div class="line">        return new GenericUserBasedRecommender(model, neighborhood, similarity);</div><div class="line">    &#125;</div><div class="line">&#125;;</div><div class="line">// 计算推荐4个结果时的查准率和召回率</div><div class="line">IRStatistics stats = statsEvaluator.evaluate(recommenderBuilder,null, model, null, 4,</div><div class="line">        GenericRecommenderIRStatsEvaluator.CHOOSE_THRESHOLD,1.0);</div><div class="line">System.out.println(stats.getPrecision());</div><div class="line">System.out.println(stats.getRecall());</div></pre></td></tr></table></figure></p>
<p>如果是基于物品的推荐，代码大体相似，只是没有了UserNeighborhood，然后将上面代码中的User换成Item即可，完整代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line">File modelFile modelFile = new File(&quot;intro.csv&quot;);</div><div class="line"></div><div class="line">DataModel model = new FileDataModel(new File(file));</div><div class="line"></div><div class="line">// Build the same recommender for testing that we did last time:</div><div class="line">RecommenderBuilder recommenderBuilder = new RecommenderBuilder() &#123;</div><div class="line">    @Override</div><div class="line">    public Recommender buildRecommender(DataModel model) throws TasteException &#123;</div><div class="line">        ItemSimilarity similarity = new PearsonCorrelationSimilarity(model);</div><div class="line">        return new GenericItemBasedRecommender(model, similarity);</div><div class="line">    &#125;</div><div class="line">&#125;;</div><div class="line"></div><div class="line">//获取推荐结果</div><div class="line">List&lt;RecommendedItem&gt; recommendations = recommenderBuilder.buildRecommender(model).recommend(1, 4);</div><div class="line"></div><div class="line">for (RecommendedItem recommendation : recommendations) &#123;</div><div class="line">    System.out.println(recommendation);</div><div class="line">&#125;</div><div class="line"></div><div class="line">//计算评分</div><div class="line">RecommenderEvaluator evaluator =</div><div class="line">        new AverageAbsoluteDifferenceRecommenderEvaluator();</div><div class="line">// Use 70% of the data to train; test using the other 30%.</div><div class="line">double score = evaluator.evaluate(recommenderBuilder, null, model, 0.7, 1.0);</div><div class="line">System.out.println(score);</div><div class="line"></div><div class="line">//计算查全率和查准率</div><div class="line">RecommenderIRStatsEvaluator statsEvaluator = new GenericRecommenderIRStatsEvaluator();</div><div class="line"></div><div class="line">// Evaluate precision and recall &quot;at 2&quot;:</div><div class="line">IRStatistics stats = statsEvaluator.evaluate(recommenderBuilder,</div><div class="line">        null, model, null, 4,</div><div class="line">        GenericRecommenderIRStatsEvaluator.CHOOSE_THRESHOLD,</div><div class="line">        1.0);</div><div class="line">System.out.println(stats.getPrecision());</div><div class="line">System.out.println(stats.getRecall());</div></pre></td></tr></table></figure></p>
<h2 id="在Spark中运行"><a href="#在Spark中运行" class="headerlink" title="在Spark中运行"></a>在Spark中运行</h2><p>在Spark中运行，需要将Mahout相关的jar添加到Spark的classpath中，修改/etc/spark/conf/spark-env.sh，添加下面两行代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">SPARK_DIST_CLASSPATH=&quot;$SPARK_DIST_CLASSPATH:/usr/lib/mahout/lib/*&quot;</div><div class="line">SPARK_DIST_CLASSPATH=&quot;$SPARK_DIST_CLASSPATH:/usr/lib/mahout/*&quot;</div></pre></td></tr></table></figure>
<p>然后，以本地模式在spark-shell中运行下面代码交互测试：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">//注意：这里是本地目录</div><div class="line">val model = new FileDataModel(new File(&quot;intro.csv&quot;))</div><div class="line"></div><div class="line">val evaluator = new RMSRecommenderEvaluator()</div><div class="line">val recommenderBuilder = new RecommenderBuilder &#123;</div><div class="line">  override def buildRecommender(dataModel: DataModel): Recommender = &#123;</div><div class="line">    val similarity = new LogLikelihoodSimilarity(dataModel)</div><div class="line">    new GenericItemBasedRecommender(dataModel, similarity)</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">val score = evaluator.evaluate(recommenderBuilder, null, model, 0.95, 0.05)</div><div class="line">println(s&quot;Score=$score&quot;)</div><div class="line"></div><div class="line">val recommender=recommenderBuilder.buildRecommender(model)</div><div class="line">val users=trainingRatings.map(_.user).distinct().take(20)</div><div class="line"></div><div class="line">import scala.collection.JavaConversions._</div><div class="line"></div><div class="line">val result=users.par.map&#123;user=&gt;</div><div class="line">  user+&quot;,&quot;+recommender.recommend(user,40).map(_.getItemID).mkString(&quot;,&quot;)</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><a href="https://github.com/sujitpal/mia-scala-examples上面有一个评估基于物品或是用户的各种相似度下的评分的类，叫做" target="_blank" rel="external">https://github.com/sujitpal/mia-scala-examples上面有一个评估基于物品或是用户的各种相似度下的评分的类，叫做</a> RecommenderEvaluator，供大家学习参考。</p>
<h2 id="分布式运行"><a href="#分布式运行" class="headerlink" title="分布式运行"></a>分布式运行</h2><p>Mahout提供了<code>org.apache.mahout.cf.taste.hadoop.item.RecommenderJob</code>类以MapReduce的方式来实现基于物品的协同过滤，查看该类的使用说明：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">ubuntu@Master:~/data$ mahout org.apache.mahout.cf.taste.hadoop.item.RecommenderJob</div><div class="line">MAHOUT_LOCAL is not set; adding HADOOP_CONF_DIR to classpath.</div><div class="line">Running on hadoop, using /home/ubuntu/hadoop/bin/hadoop and HADOOP_CONF_DIR=/home/ubuntu/hadoop/etc/hadoop</div><div class="line">MAHOUT-JOB: /home/ubuntu/apache-mahout-distribution-0.10.1/mahout-examples-0.10.1-job.jar</div><div class="line">16/07/25 07:41:32 WARN driver.MahoutDriver: No org.apache.mahout.cf.taste.hadoop.item.RecommenderJob.props found on classpath, will use command-line arguments only</div><div class="line">16/07/25 07:41:33 ERROR common.AbstractJob: Missing required option --similarityClassname</div><div class="line">Missing required option --similarityClassname                                   </div><div class="line">Usage:                                                                          </div><div class="line"> [--input &lt;input&gt; --output &lt;output&gt; --numRecommendations &lt;numRecommendations&gt;   </div><div class="line">--usersFile &lt;usersFile&gt; --itemsFile &lt;itemsFile&gt; --filterFile &lt;filterFile&gt;       </div><div class="line">--userItemFile &lt;userItemFile&gt; --booleanData &lt;booleanData&gt; --maxPrefsPerUser     </div><div class="line">&lt;maxPrefsPerUser&gt; --minPrefsPerUser &lt;minPrefsPerUser&gt; --maxSimilaritiesPerItem  </div><div class="line">&lt;maxSimilaritiesPerItem&gt; --maxPrefsInItemSimilarity &lt;maxPrefsInItemSimilarity&gt;  </div><div class="line">--similarityClassname &lt;similarityClassname&gt; --threshold &lt;threshold&gt;             </div><div class="line">--outputPathForSimilarityMatrix &lt;outputPathForSimilarityMatrix&gt; --randomSeed    </div><div class="line">&lt;randomSeed&gt; --sequencefileOutput --help --tempDir &lt;tempDir&gt; --startPhase       </div><div class="line">&lt;startPhase&gt; --endPhase &lt;endPhase&gt;]                                             </div><div class="line">--similarityClassname (-s) similarityClassname    Name of distributed           </div><div class="line">                                                  similarity measures class to  </div><div class="line">                                                  instantiate, alternatively    </div><div class="line">                                                  use one of the predefined     </div><div class="line">                                                  similarities                  </div><div class="line">                                                  ([SIMILARITY_COOCCURRENCE,    </div><div class="line">                                                  SIMILARITY_LOGLIKELIHOOD,     </div><div class="line">                                                  SIMILARITY_TANIMOTO_COEFFICIEN</div><div class="line">                                                  T, SIMILARITY_CITY_BLOCK,     </div><div class="line">                                                  SIMILARITY_COSINE,            </div><div class="line">                                                  SIMILARITY_PEARSON_CORRELATION</div><div class="line">                                                  ,                             </div><div class="line">                                                  SIMILARITY_EUCLIDEAN_DISTANCE]</div><div class="line">                                                  )</div></pre></td></tr></table></figure>
<p>也可输入<code>mahout org.apache.mahout.cf.taste.hadoop.item.RecommenderJob  --help</code>查看详细说明</p>
<p>可见，该类可以接收的命令行参数如下：</p>
<p><code>--input(path)(-i)</code>: 存储用户偏好数据的目录，该目录下可以包含一个或多个存储用户偏好数据的文本文件；<br><code>--output(path)(-o)</code>: 结算结果的输出目录<br><code>--numRecommendations (integer)</code>: 为每个用户推荐的item数量，默认为10<br><code>--usersFile (path)</code>: 指定一个包含了一个或多个存储userID的文件路径，仅为该路径下所有文件包含的userID做推荐计算 (该选项可选)<br><code>--itemsFile (path)</code>: 指定一个包含了一个或多个存储itemID的文件路径，仅为该路径下所有文件包含的itemID做推荐计算 (该选项可选)<br><code>--filterFile (path)</code>: 指定一个路径，该路径下的文件包含了[userID,itemID]值对，userID和itemID用逗号分隔。计算结果将不会为user推荐[userID,itemID]值对中包含的item (该选项可选)<br><code>--booleanData (boolean)</code>: 如果输入数据不包含偏好数值，则将该参数设置为true，默认为false<br><code>--maxPrefsPerUser (integer)</code>: 在最后计算推荐结果的阶段，针对每一个user使用的偏好数据的最大数量，默认为10<br><code>--minPrefsPerUser (integer)</code>: 在相似度计算中，忽略所有偏好数据量少于该值的用户，默认为1<br><code>--maxSimilaritiesPerItem (integer)</code>: 针对每个item的相似度最大值，默认为100<br><code>--maxPrefsPerUserInItemSimilarity (integer)</code>: 在item相似度计算阶段，针对每个用户考虑的偏好数据最大数量，默认为1000<br><code>--similarityClassname (classname)</code>: 向量相似度计算类<br><code>outputPathForSimilarityMatrix</code>：SimilarityMatrix输出目录<br><code>--randomSeed</code>：随机种子 –sequencefileOutput：序列文件输出路径<br><code>--tempDir (path)</code>: 存储临时文件的目录，默认为当前用户的home目录下的temp目录<br><code>--startPhase</code><br><code>--endPhase</code><br><code>--threshold (double)</code>: 忽略相似度低于该阀值的item对</p>
<p>一个例子如下，使用<code>SIMILARITY_LOGLIKELIHOOD</code>相似度推荐物品：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hadoop jar /usr/lib/mahout/mahout-examples-0.9-cdh5.4.0-job.jar org.apache.mahout.cf.taste.hadoop.item.RecommenderJob --input /tmp/mahout/part-00000 --output /tmp/mahout-out  -s SIMILARITY_LOGLIKELIHOOD</div></pre></td></tr></table></figure></p>
<p>自己运行的例子如下：</p>
<p>部分实验数据：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div></pre></td><td class="code"><pre><div class="line">1	25	0.0136316222</div><div class="line">1	116	0.0090877481</div><div class="line">1	5	0.0045438741</div><div class="line">1	23	0.1862988368</div><div class="line">1	17	0.0272632444</div><div class="line">1	3	1.4122360602</div><div class="line">1	11	0.0363509925</div><div class="line">1	12	0.4543874068</div><div class="line">1	120	0.0027263244</div><div class="line">1	93	0.0136316222</div><div class="line">1	21	0.0036350993</div><div class="line">1	6	0.7688234922</div><div class="line">1	47	0.0018175496</div><div class="line">1	66	0.0454387407</div><div class="line">1	27	0.0254456948</div><div class="line">1	44	0.0245369200</div><div class="line">1	315	0.0045438741</div><div class="line">1	28	0.0545264888</div><div class="line">1	138	0.0636142369</div><div class="line">1	108	0.0045438741</div><div class="line">1	1	7.2695320732</div><div class="line">1	85	12.5188577359</div><div class="line">1	168	0.0545264888</div><div class="line">10	4	0.6772009029</div><div class="line">10	6	0.6772009029</div><div class="line">10	217	0.0112866817</div><div class="line">10	2	1.7607223476</div><div class="line">10	1	1.8735891648</div><div class="line">100	25	0.4788867023</div><div class="line">100	5	0.0047793084</div><div class="line">100	17	0.2915378128</div><div class="line">100	26	0.0047793084</div><div class="line">100	3	0.1194827101</div><div class="line">100	11	0.6987348890</div><div class="line">100	4	0.6652797301</div><div class="line">100	12	0.0047793084</div><div class="line">100	30	0.0736013495</div><div class="line">100	32	0.5257239247</div><div class="line">100	31	0.0076468934</div><div class="line">100	37	0.0430137757</div><div class="line">100	29	0.0592634242</div><div class="line">100	44	0.0009558617</div><div class="line">100	13	4.4313747540</div><div class="line">100	1	9.5461906101</div><div class="line">100	10	0.0439696373</div><div class="line">1000	8	0.2902055623</div><div class="line">1000	14	0.0483675937</div><div class="line">1000	5	0.0725513906</div><div class="line">1000	9	0.0725513906</div><div class="line">1000	26	0.3869407497</div><div class="line">1000	3	0.1451027811</div><div class="line">1000	436	0.0120918984</div><div class="line">1000	2	3.9177750907</div><div class="line">1000	15	2.4304715840</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ubuntu@Master:~/data$ mahout org.apache.mahout.cf.taste.hadoop.item.RecommenderJob -i /test/item/ckm_pre_result1000000.txt -o /test/item/outputPersonCorr --similarityClassname org.apache.mahout.math.hadoop.similarity.cooccurrence.measures.PearsonCorrelationSimilarity</div></pre></td></tr></table></figure>
<p>部分结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">1	[196:10.482155,14:9.271373,145:8.875873,177:7.779633,360:7.537198,114:7.1917353,635:7.085346,75:6.8879533,235:6.796164,210:6.586777]</div><div class="line">2	[386:4.339762,631:4.2806735,194:4.274664,153:4.1018524,362:3.7975848,934:3.422003,195:3.0110214,188:2.7676048,30:2.6990044,746:2.693153]</div><div class="line">3	[45:4.2422075,212:4.1731844,270:3.9618893,309:3.960001,204:3.933118,275:3.6498196,321:3.6286862,179:3.487534,240:3.3450491,170:3.28568]</div><div class="line">4	[293:4.3900704,746:3.9469879,51:3.3795352,52:3.3444872,312:2.818981,24:2.719058,649:2.2690945,28:2.1947412,196:2.170363,145:2.008545]</div><div class="line">5	[590:1.1531421,332:1.1508745,336:1.134177,852:1.1335075,561:1.121143,36:1.1099223,535:1.0878772,129:1.0850264,236:1.0413511,83:1.0349866]</div></pre></td></tr></table></figure></p>
<p>默认情况下，mahout使用的reduce数目为1，这样造成大数据处理时效率较低，可以通过参数mahout执行脚本中的<code>MAHOUT_OPTS</code>中的<code>-Dmapred.reduce.tasks</code>参数指定reduce数目。</p>
<p>上面命令运行完成之后，会在当前用户的hdfs主目录生成temp目录，该目录可由–tempDir (path)参数设置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">$ hadoop fs -ls temp</div><div class="line">Found 10 items</div><div class="line">-rw-r--r--   3 root hadoop          7 2015-06-10 14:42 temp/maxValues.bin</div><div class="line">-rw-r--r--   3 root hadoop    5522717 2015-06-10 14:42 temp/norms.bin</div><div class="line">drwxr-xr-x   - root hadoop          0 2015-06-10 14:41 temp/notUsed</div><div class="line">-rw-r--r--   3 root hadoop          7 2015-06-10 14:42 temp/numNonZeroEntries.bin</div><div class="line">-rw-r--r--   3 root hadoop    3452222 2015-06-10 14:41 temp/observationsPerColumn.bin</div><div class="line">drwxr-xr-x   - root hadoop          0 2015-06-10 14:47 temp/pairwiseSimilarity</div><div class="line">drwxr-xr-x   - root hadoop          0 2015-06-10 14:52 temp/partialMultiply</div><div class="line">drwxr-xr-x   - root hadoop          0 2015-06-10 14:39 temp/preparePreferenceMatrix</div><div class="line">drwxr-xr-x   - root hadoop          0 2015-06-10 14:50 temp/similarityMatrix</div><div class="line">drwxr-xr-x   - root hadoop          0 2015-06-10 14:42 temp/weights</div></pre></td></tr></table></figure>
<p>观察yarn的管理界面，该命令会生成9个任务，任务名称依次是：</p>
<ul>
<li>PreparePreferenceMatrixJob-ItemIDIndexMapper-Reducer</li>
<li>PreparePreferenceMatrixJob-ToItemPrefsMapper-Reducer</li>
<li>PreparePreferenceMatrixJob-ToItemVectorsMapper-Reducer</li>
<li>RowSimilarityJob-CountObservationsMapper-Reducer</li>
<li>RowSimilarityJob-VectorNormMapper-Reducer</li>
<li>RowSimilarityJob-CooccurrencesMapper-Reducer</li>
<li>RowSimilarityJob-UnsymmetrifyMapper-Reducer</li>
<li>partialMultiply</li>
<li>RecommenderJob-PartialMultiplyMapper-Reducer</li>
</ul>
<p>从任务名称，大概可以知道每个任务在做什么，如果你的输入参数不一样，生成的任务数可能不一样，这个需要测试一下才能确认。</p>
<p>在hdfs上查看输出的结果，用户和推荐结果用\t分隔，推荐结果中物品之间用逗号分隔，物品后面通过冒号连接评分：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">843 [10709679:4.8334665,8389878:4.833426,9133835:4.7503786,10366169:4.7503185,9007487:4.750272,8149253:4.7501993,10366165:4.750115,9780049:4.750108,8581254:4.750071,10456307:4.7500467]</div><div class="line">6253    [10117445:3.0375953,10340299:3.0340924,8321090:3.0340924,10086615:3.032164,10436801:3.0187714,9668385:3.0141575,8502110:3.013954,10476325:3.0074399,10318667:3.0004222,8320987:3.0003839]</div></pre></td></tr></table></figure></p>
<p>使用Java API方式执行，请参考<a href="http://blog.fens.me/hadoop-mahout-mapreduce-itemcf/" target="_blank" rel="external">Mahout分步式程序开发 基于物品的协同过滤ItemCF</a>。</p>
<p>在Scala或者Spark中，可以以Java API或者命令方式运行，最后还可以通过Spark来处理推荐的结果，例如：过滤、去重、补足数据，这部分内容不做介绍。</p>
<p>本文基本转载自：转载自<a href="http://blog.javachen.com/" target="_blank" rel="external">JavaChen Blog</a>，作者：JavaChen，文章地址<a href="http://blog.javachen.com/2015/06/10/collaborative-filtering-using-mahout.html" target="_blank" rel="external">http://blog.javachen.com/2015/06/10/collaborative-filtering-using-mahout.html</a></p>
<p>其他参考资料:</p>
<ul>
<li><a href="http://blog.fens.me/hadoop-mapreduce-recommend/" target="_blank" rel="external">用Hadoop构建电影推荐系统(自己实现分布式)</a></li>
<li><a href="http://blog.fens.me/hadoop-mahout-recommend-job/" target="_blank" rel="external">用Mahout构建职位推荐引擎(单机)</a></li>
<li><a href="http://blog.fens.me/hadoop-mahout-recommend-book/" target="_blank" rel="external">Mahout构建图书推荐系统(单机)</a></li>
<li><a href="http://blog.fens.me/hadoop-mahout-mapreduce-itemcf/" target="_blank" rel="external">Mahout分步式程序开发 基于物品的协同过滤ItemCF（调用接口）</a></li>
<li><a href="http://www.chinahadoop.cn/group/5/thread/499" target="_blank" rel="external">mahout分布式：Item-based推荐</a></li>
<li><a href="https://mahout.apache.org/users/recommender/intro-itembased-hadoop.html" target="_blank" rel="external">Introduction to Item-Based Recommendations with Hadoop</a></li>
<li><a href="http://my.oschina.net/Cfreedom/blog/201828" target="_blank" rel="external">使用Mahout搭建推荐系统之入门篇4-Mahout实战</a></li>
<li><a href="http://zengzhaozheng.blog.51cto.com/8219051/1557054" target="_blank" rel="external">基于MapReduce的ItemBase推荐算法的共现矩阵实现</a></li>
</ul>
]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Mahout </tag>
            
            <tag> 推荐系统 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[VMWare虚拟机：“锁定文件失败”的解决方法]]></title>
      <url>http://yoursite.com/2016/07/19/VMWare%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BC%9A%E2%80%9C%E9%94%81%E5%AE%9A%E6%96%87%E4%BB%B6%E5%A4%B1%E8%B4%A5%E2%80%9D%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/</url>
      <content type="html"><![CDATA[<h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>如果使用VMWare虚拟机的时候突然系统崩溃蓝屏或者强行关机，有一定几率会导致无法启动，会提示：锁定文件失败，打不开磁盘或快照所依赖的磁盘。</p>
<blockquote>
<p>虚拟磁盘(.vmdk)本身有一个磁盘保护机制，为了防止多台虚拟机同时访问同一个虚拟磁盘(.vmdk)带来的数据丢失和性能削减方面的隐患，每次启动虚拟机的时候虚拟机会使用扩展名为.lck（磁盘锁）文件对虚拟磁盘(.vmdk)进行锁定保护。当虚拟机关闭时.lck（磁盘锁）文件自动删除。但是可能由于您非正常关闭虚拟机，这时虚拟机还没来得及删除您系统上的.lck（磁盘锁）文件，所以当下次您启动虚拟机的时候出现了上述错误。</p>
</blockquote>
<h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><p>打开你存放虚拟机系统文件的文件夹，注意，是系统文件，不是虚拟机的安装目录。搜索关键字<code>*.lck</code>，删除搜索到的文件即可。</p>
]]></content>
      
        <categories>
            
            <category> 计算机技巧 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> VMWare </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[亚马逊EC2搭建Shadowsocks]]></title>
      <url>http://yoursite.com/2016/07/19/%E4%BA%9A%E9%A9%AC%E9%80%8AEC2%E6%90%AD%E5%BB%BAShadowsocks/</url>
      <content type="html"><![CDATA[<p>在网上寻找优秀的科学上网方式中发现，自己搭建Shadowscoks是非常不错的方式，并且AWS有一年的免费使用期限，到期后再买别的VPS就行了。<br><a href="https://segmentfault.com/a/1190000003101075" target="_blank" rel="external">https://segmentfault.com/a/1190000003101075</a><br>上面连接的教程从注册申请AWS到搭建服务已经非常详细，自己再做一些补充。</p>
<h2 id="服务器端配置"><a href="#服务器端配置" class="headerlink" title="服务器端配置"></a>服务器端配置</h2><p>在EC2上创建好Linux服务器后（本人为Ubuntu）需要对其安装环境<br>参考官方文档<a href="http://docs.aws.amazon.com/zh_cn/AWSEC2/latest/UserGuide/putty.html" target="_blank" rel="external">使用 PuTTY 从 Windows 连接到 Linux 实例</a>连接服务器</p>
<h3 id="安装shadowsocks依赖"><a href="#安装shadowsocks依赖" class="headerlink" title="安装shadowsocks依赖"></a>安装shadowsocks依赖</h3><ol>
<li><code>sudo -s // 获取超级管理员权限</code></li>
<li><code>apt-get update // 更新apt-get</code></li>
<li><code>apt-get install python-pip // 安装python包管理工具pip</code></li>
<li><code>pip install shadowsocks // 安装shadowsocks</code></li>
</ol>
<h3 id="配置shadowsocks"><a href="#配置shadowsocks" class="headerlink" title="配置shadowsocks"></a>配置shadowsocks</h3><p><code>vim /etc/shadowsocks.json</code></p>
<p>单一端口配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">&quot;server&quot;:&quot;server_ip&quot;, #EC2实例的IP，注意这里我们不能填写公有IP，需要填写私有IP或者0.0.0.0  填0.0.0.0即可</div><div class="line">&quot;server_port&quot;:8388, #server端监听的端口，需要在EC2实例中开放此端口</div><div class="line">&quot;local_address&quot;: &quot;127.0.0.1&quot;,</div><div class="line">&quot;local_port&quot;:1080,</div><div class="line">&quot;password&quot;:&quot;password&quot;, #密码</div><div class="line">&quot;timeout&quot;:300,</div><div class="line">&quot;method&quot;:&quot;aes-256-cfb&quot;, #加密方式</div><div class="line">&quot;fast_open&quot;: false #是否开启fast open</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>如果想要把VPN分享给其它人而不泄露自己的密码，也可以在配置文件中设置多端口+多密码的模式，如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">&quot;server&quot;:&quot;server_ip&quot;, #EC2实例的IP，注意这里我们不能填写公有IP，需要填写私有IP或者0.0.0.0</div><div class="line">&quot;local_address&quot;: &quot;127.0.0.1&quot;,</div><div class="line">&quot;local_port&quot;:1080,</div><div class="line">&quot;port_password&quot;:</div><div class="line">&#123;</div><div class="line">&quot;8088”: “password8088”,</div><div class="line">&quot;8089”: &quot;password8089”</div><div class="line">&#125;</div><div class="line">&quot;timeout&quot;:300,</div><div class="line">&quot;method&quot;:&quot;aes-256-cfb&quot;, #加密方式</div><div class="line">&quot;fast_open&quot;: false #是否开启fast open</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="配置完成后启动Shawdowsocks"><a href="#配置完成后启动Shawdowsocks" class="headerlink" title="配置完成后启动Shawdowsocks"></a>配置完成后启动Shawdowsocks</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">启动：ssserver -c /etc/shadowsocks.json -d start</div><div class="line">停止：ssserver -c /etc/shadowsocks.json -d stop</div><div class="line">重启：ssserver -c /etc/shadowsocks.json -d restart</div><div class="line">查看状态：ssserver -c /etc/shadowsocks.json -d status</div></pre></td></tr></table></figure>
<h3 id="关闭服务器防火墙"><a href="#关闭服务器防火墙" class="headerlink" title="关闭服务器防火墙"></a>关闭服务器防火墙</h3><p><code>sudo ufw disable</code></p>
<h3 id="开启AWS入站端口"><a href="#开启AWS入站端口" class="headerlink" title="开启AWS入站端口"></a>开启AWS入站端口</h3><p>配置好shaodowsocks后，还需要将配置中的端口打开,这样客户端的服务才能链接得上EC2中的shadowsocks服务。<br>在EC2网页中编辑入站规则将配置文件中的端口号（如8388）加入入站规则。<br>服务器端配置完毕。</p>
<h2 id="客户端下载"><a href="#客户端下载" class="headerlink" title="客户端下载"></a>客户端下载</h2><p><a href="https://www.gaotizi.com/knowledgebase/2/shadowsocks.html" target="_blank" rel="external">shadowsocks下载地址1</a><br><a href="https://shadowsocks.com/client.html" target="_blank" rel="external">shadowsocks下载地址2</a><br>windows10尽量使用2.3版本，否则可能出现500或者502错误<br><a href="http://pan.baidu.com/s/1hqIk4mS" target="_blank" rel="external">http://pan.baidu.com/s/1hqIk4mS</a></p>
<h3 id="500或者502错误"><a href="#500或者502错误" class="headerlink" title="500或者502错误"></a>500或者502错误</h3><ul>
<li>使用2.3版本</li>
<li>或者尝试以下命令<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">netsh interface ipv4  reset</div><div class="line">netsh interface ipv6  reset</div><div class="line">netsh winsock reset</div></pre></td></tr></table></figure></li>
</ul>
]]></content>
      
        <categories>
            
            <category> 计算机技巧 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 科学上网 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[window下搭建eclipse运行MapReduce环境]]></title>
      <url>http://yoursite.com/2016/07/13/window%E4%B8%8B%E6%90%AD%E5%BB%BAeclipse%E8%BF%90%E8%A1%8CMapReduce%E7%8E%AF%E5%A2%83/</url>
      <content type="html"><![CDATA[<h2 id="系统环境及所需文件"><a href="#系统环境及所需文件" class="headerlink" title="系统环境及所需文件"></a>系统环境及所需文件</h2><ul>
<li>eclipse-jee-mars-2</li>
<li>hadoop2.7.2</li>
<li><a href="https://github.com/winghc/hadoop2x-eclipse-plugin" target="_blank" rel="external">hadoop-eclipse-plugin</a></li>
<li><a href="http://download.csdn.net/download/chenxf10/9564165" target="_blank" rel="external">hadoop.dll &amp; winutils.exe</a></li>
</ul>
<h2 id="修改Master节点的hdfs-site-xml"><a href="#修改Master节点的hdfs-site-xml" class="headerlink" title="修改Master节点的hdfs-site.xml"></a>修改Master节点的hdfs-site.xml</h2><pre><code>&lt;property&gt;      
    &lt;name&gt;dfs.permissions&lt;/name&gt;      
    &lt;value&gt;false&lt;/value&gt;  
&lt;/property&gt; 
</code></pre><p>旨在取消权限检查</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&lt;property&gt; </div><div class="line">	&lt;name&gt;dfs.web.ugi&lt;/name&gt; </div><div class="line">	&lt;value&gt;Skye,supergroup&lt;/value&gt; </div><div class="line">&lt;/property&gt;</div></pre></td></tr></table></figure>
<h2 id="配置Hadoop插件"><a href="#配置Hadoop插件" class="headerlink" title="配置Hadoop插件"></a>配置Hadoop插件</h2><ol>
<li>windows下载hadoop-2.7.2解压到某目录下，如：E:\hadoop\hadoop-2.7.2</li>
<li>下载hadoop-eclipse-plugin插件hadoop-eclipse-plugin，将release目录下的hadoop-eclipse-plugin-2.6.0.jar拷贝到eclipse/plugins，重启eclipse。</li>
<li>插件配置windows-&gt;show view-&gt;other 显示mapreduce视图</li>
<li>window-&gt;preferences-&gt;hadoop map/reduce 指定windows上的hadoop根目录（即：E:\hadoop\hadoop-2.7.2）</li>
<li>在Map/Reduce Locations 面板中，点击小象图标定义hadoop<br><img src="http://i.imgur.com/61yzGm9.png" alt=""><br>解释：<br>MapReduce Master<br>Host：虚拟机hadoop master对应ip<br>Port：hdfs-site.xml中dfs.datanode.ipc.address指定的的端口号。此处填9001<br>DFS Master中Port：core-site.xml中fs.defaultFS指定的端口。应填9000<br>User name：linux中运行hadoop的用户。 </li>
</ol>
<h2 id="配置完毕查看结果"><a href="#配置完毕查看结果" class="headerlink" title="配置完毕查看结果"></a>配置完毕查看结果</h2><p><img src="http://i.imgur.com/zVOXsbw.png" alt=""></p>
<h2 id="windows下运行环境配置"><a href="#windows下运行环境配置" class="headerlink" title="windows下运行环境配置"></a>windows下运行环境配置</h2><ol>
<li>在系统环境变量中增加HADOOP_HOME，并在Path中加入%HADOOP_HOME%\bin</li>
<li>将下载下来的hadoop.dll,winutils.exe拷贝到HADOOP_HOME/bin目录下</li>
</ol>
<h2 id="创建-MapReduce工程并运行"><a href="#创建-MapReduce工程并运行" class="headerlink" title="创建 MapReduce工程并运行"></a>创建 MapReduce工程并运行</h2><p>需要拷贝 服务器hadoop中的log4j.properties文件到工程的src目录</p>
<p><code>run on hadoop</code></p>
<p>运行时报如下错误，弄了好长一段时间，发现原因是服务器通过内网ip访问，外网无法解析。用虚拟机连接成功.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div></pre></td><td class="code"><pre><div class="line">16/07/13 10:42:38 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.</div><div class="line">16/07/13 10:42:39 INFO mapreduce.Job: Job job_local510776960_0001 running in uber mode : false</div><div class="line">16/07/13 10:42:39 INFO mapreduce.Job:  map 0% reduce 0%</div><div class="line">16/07/13 10:42:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3bfe5dd7</div><div class="line">16/07/13 10:42:39 INFO mapred.MapTask: Processing split: hdfs://Master:9000/test/test3.txt:0+259</div><div class="line">16/07/13 10:42:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)</div><div class="line">16/07/13 10:42:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100</div><div class="line">16/07/13 10:42:39 INFO mapred.MapTask: soft limit at 83886080</div><div class="line">16/07/13 10:42:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600</div><div class="line">16/07/13 10:42:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600</div><div class="line">16/07/13 10:42:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer</div><div class="line">16/07/13 10:43:00 WARN hdfs.BlockReaderFactory: I/O error constructing remote block reader.</div><div class="line">java.net.ConnectException: Connection timed out: no further information</div><div class="line">	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)</div><div class="line">	at sun.nio.ch.SocketChannelImpl.finishConnect(Unknown Source)</div><div class="line">	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)</div><div class="line">	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)</div><div class="line">	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3436)</div><div class="line">	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)</div><div class="line">	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)</div><div class="line">	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)</div><div class="line">	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)</div><div class="line">	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)</div><div class="line">	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)</div><div class="line">	at java.io.DataInputStream.read(Unknown Source)</div><div class="line">	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:59)</div><div class="line">	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)</div><div class="line">	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)</div><div class="line">	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:91)</div><div class="line">	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:144)</div><div class="line">	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:184)</div><div class="line">	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:556)</div><div class="line">	at org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)</div><div class="line">	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)</div><div class="line">	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)</div><div class="line">	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)</div><div class="line">	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)</div><div class="line">	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)</div><div class="line">	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)</div><div class="line">	at java.util.concurrent.FutureTask.run(Unknown Source)</div><div class="line">	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)</div><div class="line">	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)</div><div class="line">	at java.lang.Thread.run(Unknown Source)</div><div class="line">16/07/13 10:43:00 WARN hdfs.DFSClient: Failed to connect to /10.0.0.14:50010 for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further information</div><div class="line">java.net.ConnectException: Connection timed out: no further information</div><div class="line">	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)</div><div class="line">	at sun.nio.ch.SocketChannelImpl.finishConnect(Unknown Source)</div><div class="line">	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)</div><div class="line">	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)</div><div class="line">	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3436)</div><div class="line">	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)</div><div class="line">	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)</div><div class="line">	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)</div><div class="line">	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)</div><div class="line">	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)</div><div class="line">	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)</div><div class="line">	at java.io.DataInputStream.read(Unknown Source)</div><div class="line">	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:59)</div><div class="line">	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)</div><div class="line">	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)</div><div class="line">	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:91)</div><div class="line">	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:144)</div><div class="line">	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:184)</div><div class="line">	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:556)</div><div class="line">	at org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)</div><div class="line">	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)</div><div class="line">	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)</div><div class="line">	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)</div><div class="line">	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)</div><div class="line">	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)</div><div class="line">	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)</div><div class="line">	at java.util.concurrent.FutureTask.run(Unknown Source)</div><div class="line">	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)</div><div class="line">	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)</div><div class="line">	at java.lang.Thread.run(Unknown Source)</div></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MapReduce </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[mapreduce任务运行时shuffle Error]]></title>
      <url>http://yoursite.com/2016/07/11/mapreduce%E4%BB%BB%E5%8A%A1%E8%BF%90%E8%A1%8C%E6%97%B6shuffle%20Error/</url>
      <content type="html"><![CDATA[<p><em>本文引用参考</em>：<a href="http://blog.csdn.net/dslztx/article/details/46445725" target="_blank" rel="external">MapReduce任务Shuffle Error错误</a><br><em>相关参考连接</em>：<a href="http://blog.csdn.net/stark_summer/article/details/48494391" target="_blank" rel="external"> yarn &amp; mapreduce 配置参数总结</a></p>
<h2 id="错误描述"><a href="#错误描述" class="headerlink" title="错误描述"></a>错误描述</h2><p>在运行MapReduce任务的时候，出现如下错误：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">Error: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#1</div><div class="line">        at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:134)</div><div class="line">        at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:376)</div><div class="line">        at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)</div><div class="line">        at java.security.AccessController.doPrivileged(Native Method)</div><div class="line">        at javax.security.auth.Subject.doAs(Subject.java:396)</div><div class="line">        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1556)</div><div class="line">        at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)</div><div class="line">Caused by: java.lang.OutOfMemoryError: Java heap space</div><div class="line">        at org.apache.hadoop.io.BoundedByteArrayOutputStream.&lt;init&gt;(BoundedByteArrayOutputStream.java:56)</div><div class="line">        at org.apache.hadoop.io.BoundedByteArrayOutputStream.&lt;init&gt;(BoundedByteArrayOutputStream.java:46)</div><div class="line">        at org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.&lt;init&gt;(InMemoryMapOutput.java:63)</div><div class="line">        at org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.unconditionalReserve(MergeManagerImpl.java:297)</div><div class="line">        at org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.reserve(MergeManagerImpl.java:287)</div><div class="line">        at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyMapOutput(Fetcher.java:411)</div><div class="line">        at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:341)</div><div class="line">        at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:165)</div></pre></td></tr></table></figure></p>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>  根据《Hadoop:The Definitive Guide 4th　Edition》所述(P203-219)，map任务和reduce任务之间要经过一个shuffle过程，该过程复制map任务的输出作为reduce任务的输入。<br>  具体的来说，shuffle过程的输入是：map任务的输出文件，它的输出接收者是：运行reduce任务的机子上的内存buffer，并且shuffle过程以并行方式运行。<br>  参数mapreduce.reduce.shuffle.input.buffer.percent控制运行reduce任务的机子上多少比例的内存用作上述buffer(默认值为0.70)，参数mapreduce.reduce.shuffle.parallelcopies控制shuffle过程的并行度(默认值为5)。那么”mapreduce.reduce.shuffle.input.buffer.percent” * “mapreduce.reduce.shuffle.parallelcopies” 必须小于等于1，否则就会出现如上错误<br>因此，我将mapreduce.reduce.shuffle.input.buffer.percent设置成值为0.1，就可以正常运行了（设置成0.2，还是会抛同样的错）</p>
<p><code>job.getConfiguration().setStrings(&quot;mapreduce.reduce.shuffle.input.buffer.percent&quot;, &quot;0.1&quot;);</code><br>或者在<code>maperd-site.xml</code>中修改<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">   &lt;name&gt;mapreduce.reduce.input.buffer.percent&lt;/name&gt;</div><div class="line">   &lt;value&gt;0.0&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div></pre></td></tr></table></figure></p>
<p>  另外，可以发现如果使用两个参数的默认值，那么两者乘积为3.5，大大大于1了，为什么没有经常抛出以上的错误呢？<br>1)首先，把默认值设为比较大，主要是基于性能考虑，将它们设为比较大，可以大大加快从map复制数据的速度<br>2)其次，要抛出如上异常，还需满足另外一个条件，就是map任务的数据一下子准备好了等待shuffle去复制，在这种情况下，就会导致shuffle过程的“线程数量”和“内存buffer使用量”都是满负荷的值，自然就造成了内存不足的错误；而如果map任务的数据是断断续续完成的，那么没有一个时刻shuffle过程的“线程数量”和“内存buffer使用量”是满负荷值的，自然也就不会抛出如上错误</p>
<p>另外，如果在设置以上参数后，还是出现错误，那么有可能是运行Reduce任务的进程的内存总量不足，可以通过mapred.child.java.opts参数来调节，比如设置mapred.child.java.opts=-Xmx2024m</p>
]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MapReduce </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MapReduce 多文件输入]]></title>
      <url>http://yoursite.com/2016/06/16/MapReduce%20%E5%A4%9A%E6%96%87%E4%BB%B6%E8%BE%93%E5%85%A5/</url>
      <content type="html"><![CDATA[<h2 id="多路径输入"><a href="#多路径输入" class="headerlink" title="多路径输入"></a>多路径输入</h2><ol>
<li><p>FileInputFormat.addInputPath 多次调用加载不同路径</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">FileInputFormat.addInputPath(job, new Path(args[0]));</div><div class="line">FileInputFormat.addInputPath(job, new Path(args[1]));</div></pre></td></tr></table></figure>
</li>
<li><p>FileInputFormat.addInputPaths一次调用加载 多路径字符串用逗号隔开</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">FileInputFormat.addInputPaths(job, &quot;hdfs://master:9000/cs/path1,hdfs://RS5-112:9000/cs/path2&quot;);</div></pre></td></tr></table></figure>
</li>
<li><p>多种输入**MultipleInputs可以加载不同路径的输入文件，并且每个路径可用不同的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">maperMultipleInputs.addInputPath(job, new Path(&quot;hdfs://master:9000/cs/path1&quot;), TextInputFormat.class,MultiTypeFileInput1Mapper.class);</div><div class="line">MultipleInputs.addInputPath(job, new Path(&quot;hdfs://master:9000/cs/path3&quot;), TextInputFormat.class,MultiTypeFileInput3Mapper.class);</div></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="网上例子："><a href="#网上例子：" class="headerlink" title="网上例子："></a>网上例子：</h2><pre><code>package example;

import java.io.IOException;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.MultipleInputs;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
/**
* 多类型文件输入
* @author lijl
*
*/

public class MultiTypeFileInputMR {
static class MultiTypeFileInput1Mapper extends Mapper&lt;LongWritable, Text, Text, Text&gt;{
public void map(LongWritable key,Text value,Context context){
try {
String[] str = value.toString().split(&quot;\\|&quot;);
context.write(new Text(str[0]), new Text(str[1]));
} catch (IOException e) {
e.printStackTrace();
} catch (InterruptedException e) {
e.printStackTrace();
}
}
}
static class MultiTypeFileInput3Mapper extends Mapper&lt;LongWritable, Text, Text, Text&gt;{
public void map(LongWritable key,Text value,Context context){
try {
String[] str = value.toString().split(&quot;&quot;);
context.write(new Text(str[0]), new Text(str[1]));
} catch (IOException e) {
e.printStackTrace();
} catch (InterruptedException e) {
e.printStackTrace();
}
}
}
static class MultiTypeFileInputReducer extends Reducer&lt;Text, Text, Text, Text&gt;{
public void reduce(Text key,Iterable&lt;Text&gt; values,Context context){
try {
for(Text value:values){
context.write(key,value);
}

} catch (IOException e) {
e.printStackTrace();
} catch (InterruptedException e) {
e.printStackTrace();
}
}
}

public static void main(String[] args) throws IOException, InterruptedException, ClassNotFoundException {
Configuration conf = new Configuration();
conf.set(&quot;mapred.textoutputformat.separator&quot;, &quot;,&quot;);
Job job = new Job(conf,&quot;MultiPathFileInput&quot;);
job.setJarByClass(MultiTypeFileInputMR.class);
FileOutputFormat.setOutputPath(job, new Path(&quot;hdfs://RS5-112:9000/cs/path6&quot;));

job.setMapOutputKeyClass(Text.class);
job.setMapOutputValueClass(Text.class);
job.setOutputKeyClass(Text.class);
job.setOutputValueClass(Text.class);

job.setReducerClass(MultiTypeFileInputReducer.class);
job.setNumReduceTasks(1);
MultipleInputs.addInputPath(job, new Path(&quot;hdfs://RS5-112:9000/cs/path1&quot;), TextInputFormat.class,MultiTypeFileInput1Mapper.class);
MultipleInputs.addInputPath(job, new Path(&quot;hdfs://RS5-112:9000/cs/path3&quot;), TextInputFormat.class,MultiTypeFileInput3Mapper.class);
System.exit(job.waitForCompletion(true)?0:1);
}

}
</code></pre><h2 id="自己例子"><a href="#自己例子" class="headerlink" title="自己例子"></a>自己例子</h2><p>QLMapper.java<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line">package com.hdu.mr;</div><div class="line"></div><div class="line">import java.io.IOException;</div><div class="line"></div><div class="line">import org.apache.hadoop.io.LongWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Mapper;</div><div class="line"></div><div class="line">public class QLMapper extends Mapper&lt;LongWritable, Text, Text, LongWritable&gt; &#123;</div><div class="line">	String[] mbUnlike = &#123; &quot;盒子&quot;, &quot;助手&quot;, &quot;输入法&quot;, &quot;平台&quot; &#125;;</div><div class="line">	String mbdylxLike = &quot;游戏&quot;;</div><div class="line">	String mbdylxUnlike = &quot;网页游戏&quot;;</div><div class="line">	String delWeb = &quot;访问网站&quot;;</div><div class="line">	Text outputValue = new Text();</div><div class="line"></div><div class="line">	@Override</div><div class="line">	protected void map(LongWritable key, Text value, Mapper&lt;LongWritable, Text, Text, LongWritable&gt;.Context context)</div><div class="line">			throws IOException, InterruptedException &#123;</div><div class="line">		// 接收数据v1</div><div class="line">		String line = value.toString();</div><div class="line">		// 切分数据</div><div class="line">		String[] words = line.split(&quot;&quot;);</div><div class="line">		// String[] words = line.split(&quot;\t&quot;);</div><div class="line"></div><div class="line">		boolean flag = true;</div><div class="line"></div><div class="line">		for (int i = 0; i &lt; 4; i++) &#123;</div><div class="line">			if (words.length &lt; 5) &#123; // 过滤 长度小于4的信息 即访问网站等</div><div class="line">				flag = false;</div><div class="line">				break;</div><div class="line">			&#125;</div><div class="line">			if (words[3].indexOf(mbUnlike[i]) != -1) &#123; // 有其中一个则为false</div><div class="line">				flag = false;</div><div class="line">				break;</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line"></div><div class="line">		if (flag == true) &#123;</div><div class="line">			if (words[4].indexOf(mbdylxUnlike) != -1) &#123; // 有网页游戏则为false</div><div class="line">				flag = false;</div><div class="line">			&#125; else if (words[4].indexOf(mbdylxLike) == -1) &#123; // 没有游戏则为false</div><div class="line">				flag = false;</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">		if (flag == true) &#123;</div><div class="line">			outputValue.set(line);</div><div class="line">			context.write(outputValue, new LongWritable(1L));</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>QLReducer.java<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">package com.hdu.mr;</div><div class="line"></div><div class="line">import java.io.IOException;</div><div class="line"></div><div class="line">import org.apache.hadoop.io.LongWritable;</div><div class="line">import org.apache.hadoop.io.NullWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Reducer;</div><div class="line"></div><div class="line">public class QLReducer extends Reducer&lt;Text, LongWritable, Text, NullWritable&gt; &#123;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	protected void reduce(Text key, Iterable&lt;LongWritable&gt; values,</div><div class="line">			Reducer&lt;Text, LongWritable, Text, NullWritable&gt;.Context context) throws IOException, InterruptedException &#123;</div><div class="line">		// 接收数据</div><div class="line"></div><div class="line">		// 输出</div><div class="line">		context.write(key, NullWritable.get());</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>DataClean.java<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">package com.hdu.mr;</div><div class="line"></div><div class="line">import java.io.IOException;</div><div class="line"></div><div class="line">import org.apache.hadoop.io.LongWritable;</div><div class="line">import org.apache.hadoop.io.NullWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Reducer;</div><div class="line"></div><div class="line">public class QLReducer extends Reducer&lt;Text, LongWritable, Text, NullWritable&gt; &#123;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	protected void reduce(Text key, Iterable&lt;LongWritable&gt; values,</div><div class="line">			Reducer&lt;Text, LongWritable, Text, NullWritable&gt;.Context context) throws IOException, InterruptedException &#123;</div><div class="line">		// 接收数据</div><div class="line"></div><div class="line">		// 输出</div><div class="line">		context.write(key, NullWritable.get());</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MapReduce </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[HBase集群搭建]]></title>
      <url>http://yoursite.com/2016/06/16/HBase%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</url>
      <content type="html"><![CDATA[<h2 id="1-上传hbase安装包"><a href="#1-上传hbase安装包" class="headerlink" title="1. 上传hbase安装包"></a>1. 上传hbase安装包</h2><h2 id="2-解压"><a href="#2-解压" class="headerlink" title="2. 解压"></a>2. 解压</h2><h2 id="3-配置hbase集群，要修改3个文件（首先zk集群已经安装好了）"><a href="#3-配置hbase集群，要修改3个文件（首先zk集群已经安装好了）" class="headerlink" title="3. 配置hbase集群，要修改3个文件（首先zk集群已经安装好了）"></a>3. 配置hbase集群，要修改3个文件（首先zk集群已经安装好了）</h2><p><em>注意：要把hadoop的hdfs-site.xml和core-site.xml 放到hbase/conf下</em></p>
<h4 id="vim-hbase-env-sh"><a href="#vim-hbase-env-sh" class="headerlink" title="vim hbase-env.sh"></a>vim hbase-env.sh</h4><pre><code>export JAVA_HOME=/usr/java/jdk1.7.0_55
//告诉hbase使用外部的zk 
export HBASE_MANAGES_ZK=false
</code></pre><h4 id="vim-hbase-site-xml"><a href="#vim-hbase-site-xml" class="headerlink" title="vim hbase-site.xml"></a>vim hbase-site.xml</h4><pre><code> &lt;configuration&gt;
    &lt;!-- 指定hbase在HDFS上存储的路径 --&gt;
    &lt;property&gt;
            &lt;name&gt;hbase.rootdir&lt;/name&gt;
            &lt;value&gt;hdfs://ns1/hbase&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 指定hbase是分布式的 --&gt;
    &lt;property&gt;
            &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;
            &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 指定zk的地址，多个用“,”分割 --&gt;
    &lt;property&gt;
            &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;
            &lt;value&gt;itcast04:2181,itcast05:2181,itcast06:2181&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre><h4 id="vim-regionservers"><a href="#vim-regionservers" class="headerlink" title="vim regionservers"></a>vim regionservers</h4><pre><code>itcast03
itcast04
itcast05
itcast06
</code></pre><h2 id="4-将配置好的HBase拷贝到每一个节点并同步时间"><a href="#4-将配置好的HBase拷贝到每一个节点并同步时间" class="headerlink" title="4. 将配置好的HBase拷贝到每一个节点并同步时间"></a>4. 将配置好的HBase拷贝到每一个节点并同步时间</h2><pre><code>scp -r /itcast/hbase-0.96.2-hadoop2/ itcast02:/itcast/
scp -r /itcast/hbase-0.96.2-hadoop2/ itcast03:/itcast/
scp -r /itcast/hbase-0.96.2-hadoop2/ itcast04:/itcast/
scp -r /itcast/hbase-0.96.2-hadoop2/ itcast05:/itcast/
scp -r /itcast/hbase-0.96.2-hadoop2/ itcast06:/itcast/
</code></pre><h2 id="5-启动所有的hbase"><a href="#5-启动所有的hbase" class="headerlink" title="5. 启动所有的hbase"></a>5. 启动所有的hbase</h2><pre><code>分别启动zk
    ./zkServer.sh start
启动hbase集群
    start-dfs.sh
启动hbase，在主节点上运行：
    start-hbase.sh
</code></pre><h2 id="6-通过浏览器访问hbase管理页面"><a href="#6-通过浏览器访问hbase管理页面" class="headerlink" title="6.通过浏览器访问hbase管理页面"></a>6.通过浏览器访问hbase管理页面</h2><pre><code>192.168.1.201:60010
</code></pre><h2 id="7-为保证集群的可靠性，要启动多个HMaster-在itcast02上启动"><a href="#7-为保证集群的可靠性，要启动多个HMaster-在itcast02上启动" class="headerlink" title="7.为保证集群的可靠性，要启动多个HMaster,在itcast02上启动"></a>7.为保证集群的可靠性，要启动多个HMaster,在itcast02上启动</h2><pre><code>hbase-daemon.sh start master
</code></pre>]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> HBase </tag>
            
        </tags>
        
    </entry>
    
  
  
</search>
