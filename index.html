<!doctype html>



  


<html class="theme-next pisces use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Lobster Two:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description" content="学习总结 思想感悟">
<meta property="og:type" content="website">
<meta property="og:title" content="Skye's Blog">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Skye's Blog">
<meta property="og:description" content="学习总结 思想感悟">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Skye's Blog">
<meta name="twitter:description" content="学习总结 思想感悟">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: '博主'
    }
  };
</script>




  <link rel="canonical" href="http://yoursite.com/"/>

  <title> Skye's Blog </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Skye's Blog</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">Forever youthful,forever weeping</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/12/16/MapReduce程序异常捕获存储/" itemprop="url">
                  MapReduce程序异常捕获存储
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-12-16T15:24:29+08:00" content="2016-12-16">
              2016-12-16
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/12/16/MapReduce程序异常捕获存储/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/12/16/MapReduce程序异常捕获存储/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>在Map或reduce中使用multipleOutput来进行异常存储：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">try&#123;</span><br><span class="line">	...</span><br><span class="line">	...</span><br><span class="line">	context.write(newKey,newValue);</span><br><span class="line"></span><br><span class="line">&#125;catch(Exception e)&#123;</span><br><span class="line">	multipleOutput.write(new Text( null == e.getMessage()? (&quot;error:&quot;): e.getMessage),new Text(value.toString()),&quot;_error/part&quot;);</span><br><span class="line">	e.printStackTrace();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/12/12/MapReduce应用中CombineFileInputFormat原理与用法/" itemprop="url">
                  MapReduce应用中CombineFileInputFormat原理与用法
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-12-12T21:26:41+08:00" content="2016-12-12">
              2016-12-12
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/12/12/MapReduce应用中CombineFileInputFormat原理与用法/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/12/12/MapReduce应用中CombineFileInputFormat原理与用法/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>转载自：<a href="http://ju.outofmemory.cn/entry/72024" target="_blank" rel="external">http://ju.outofmemory.cn/entry/72024</a></p>
</blockquote>
<p>HDFS本身被设计来存储大文件，但是有时难免会有小文件出现，有时很可能时大量的小文件。通过MapReduce处理大量小文件时会遇到些问题。</p>
<p>MapReduce程序会将输入的文件进行分片(Split)，每个分片对应一个map任务，而默认一个文件至少有一个分片，一个分片也只属于一个文件。这样大量的小文件会导致大量的map任务，导致资源过度消耗，且效率低下。Hadoop自身包含了CombineFileInputFormat，其功能是将多个小文件合并如一个分片，由一个map任务处理，这样就减少了不必要的map数量。</p>
<p>在了解CombineFileInputFormat之前，我们应了解其父类FileInputFormat的基本处理逻辑。注意这里的FileInputFormat的路径是<strong>org.apache.hadoop.mapreduce.lib.input.FileInputFormat</strong>，是新的MapReduce API。 mapred包下的FileInputFormat对应老的API，不再推荐使用。</p>
<p><a href="http://www.sqlparty.com/wp-content/uploads/2013/12/CombineFileInputFormat_type.png" target="_blank" rel="external"><img src="http://www.sqlparty.com/wp-content/uploads/2013/12/CombineFileInputFormat_type.png" alt="CombineFileInputFormat_type"></a></p>
<h2 id="FileInputFormat的基本处理逻辑"><a href="#FileInputFormat的基本处理逻辑" class="headerlink" title="FileInputFormat的基本处理逻辑"></a>FileInputFormat的基本处理逻辑</h2><p>FileInputFormat是基于文件的InputFormat的抽象基类，如上图所示，基于文件的衍生类有很多，如文本文件TextInputFormat，序列文件SequenceFileInputFormat等。</p>
<p>FileInputFormat提供了分片的基本实现getSplits(JobContext)，其子类可以重写isSplitable(JobContext, Path)方法，来使得输入的一个或多个文件是否不做分片，完整由被一个Map任务进行处理。</p>
<p>FileInputFormat有如下特点：</p>
<ol>
<li>将以下划线&#8221;_&#8221;或点&#8221;.&#8221;开头的文件作为隐藏文件，不做为输入文件。</li>
<li>所有文件isSplitable(JobContext, Path)都是true，但是针对如果输入文件时压缩的、流式的，那么子类中应重新该函数，判断是否真的可以分片。</li>
<li><p>由于每个文件块大小可能不一样，所以每个文件分别计算分片大小，计算规则如下：</p>
<ol>
<li><p>取值A：</p>
<ol>
<li>FormatMinSplitSize，本Format设置的最小Split大小，通过GetFormatMinSplitSize()获取，此类中定义为1个字节。</li>
<li>MinSplitSize，配置文件(配置键mapreduce.input.fileinputformat.split.minsize)或者直接设置，通过GetMinSplitSize()获取)，未设置则为0。</li>
<li>取两者较大值。</li>
</ol>
</li>
<li><p>取值B:</p>
<ol>
<li>MaxSplitSize，通过配置文件设置或者SetMaxSplitSize()设置，通过GetMaxSplitSize()获取，无设置则取LONG.MAXVALUE。</li>
<li>文件块大小BLOCKSIZE</li>
<li>取两者较小值</li>
</ol>
</li>
<li><p>再取A、B的较大值。</p>
</li>
<li>例：常用的TextInputFormat类中，没有对分片算法进行重写，那么我们可以认为，使用TextInputFormat时，在未做其他设置的情况下，默认分片大小等于BLOCKSIZE，如果设置了mapreduce.input.fileinputformat.split.minsize，则取其与BLOCK的较大值。</li>
</ol>
</li>
<li><p>分片大小确定后，就将文件进行依次划分。</p>
</li>
</ol>
<h2 id="文本类型TextInputFormat的使用"><a href="#文本类型TextInputFormat的使用" class="headerlink" title="文本类型TextInputFormat的使用"></a>文本类型TextInputFormat的使用</h2><p>如上我们知道TextInputFormat是FileInputFormat的子类，其自定义内容很少，通过它可以大致知道扩展FileInputFormat大致需要做些什么。整个类如下：</p>
<pre><code>public class TextInputFormat extends FileInputFormat&amp;lt;LongWritable, Text&amp;gt; {

  @Override
  public RecordReader&amp;lt;LongWritable, Text&amp;gt;
    createRecordReader(InputSplit split,
                       TaskAttemptContext context) {
    String delimiter = context.getConfiguration().get(
        &amp;quot;textinputformat.record.delimiter&amp;quot; );
    byte[] recordDelimiterBytes = null;
    if ( null != delimiter)
      recordDelimiterBytes = delimiter.getBytes(Charsets. UTF_8);
    return new LineRecordReader(recordDelimiterBytes);
  }

  @Override
  protected boolean isSplitable(JobContext context, Path file) {
    final CompressionCodec codec =
      new CompressionCodecFactory(context.getConfiguration()).getCodec(file);
    if ( null == codec) {
      return true;
    }
    return codec instanceof SplittableCompressionCodec;
  }
}
</code></pre><p>分片的方式采用的是父类FileInputFormat的逻辑，上文中已经说明。重写了isSplitable()，根据文本文件的压缩属性来判断是否可以进行分片。</p>
<p>而createRecorderReader()是定义文本文件的读取方式，实际文件读取是通过它返回的RecordReader&lt;LongWritable, Text&gt;类实现的。</p>
<p>这样，在整个输入文件读取过程，大致会涉及如下几个步骤：</p>
<ol>
<li>指定输入文件路径，如FileInputFormat.addInputPaths(job, args[0])</li>
<li>指定文件的处理类型，如job.setInputFormatClass(MyInputFormat. class)</li>
<li><p>在这个InputFormatClass内部，考虑:</p>
<ol>
<li>是否可以进行分片 isSplitable(JobContext context, Path file)</li>
<li>如何分片 List&lt;InputSplit&gt; getSplits(JobContext job)</li>
<li>如何读取分片中的记录 RecordReader&lt;LongWritable, Text&gt; createRecordReader(InputSplit split,TaskAttemptContext context)</li>
<li>以上确定后，用户开发的Map任务中就可以直接处理每一条记录KeyValue。</li>
</ol>
</li>
</ol>
<p>这些步骤下，我们基本就可以理解TextInputFormat如何被使用了。其他类型的InputFormat子类，其流程步骤也基本与上相同，可以重写相关的类方法来实现不同处理方式。</p>
<p>从TextInputFormat中的分片逻辑(FileInputFormat的getSplits)中可以确定，分片都是针对单个文件而言的，如果文件本身较小，没有达到一个分片大小，那么每个小文件都是一个分片。而一个分片就对应一个Map任务。如果有大量的小文件作为Map的输入，那么其会导致生成大量Map任务，造成处理的缓慢、资源的浪费，如何减少map任务的数量提高处理效率呢？CombineInputFormat就是为解决这样的问题。</p>
<h2 id="3-CombineInputFormat原理与用法"><a href="#3-CombineInputFormat原理与用法" class="headerlink" title="3.CombineInputFormat原理与用法"></a>3.CombineInputFormat原理与用法</h2><p>CombineInputFormat的功能，是将一个<strong>目录</strong>（可能包括多个小文件，不包括子目录）作为一个map的输入，而不是通常使用一个<strong>文件</strong>作为输入。</p>
<p>CombineInputFormat本身是个抽象类，要使用它，涉及：</p>
<p><strong> 1)CombineFileSplit </strong></p>
<p>我们的目标是使得一个split不是属于一个文件，而是可能包含多个文件，所以这里不再使用常用的FileSplit，而是CombineFileSplit，包括了各个文件的路径、长度、读的起始位置等信息。CombineFileSplit是CombineInputFormat中getSplits()的对象类型。</p>
<p><strong>2)CombineInputFormat 核心处理类</strong></p>
<p>2.1)其基本思想：</p>
<p>分片从指定路径下的多个文件构建，不同文件可以放入不同的pool，一个分片只能包含一个pool中的文件，可以包括多个文件的Block。pool其实是针对文件进行了逻辑划分，不同的pool中的文件分别进行分片。分片的逻辑如下文所示。</p>
<p>2.2)分片的逻辑：</p>
<ol>
<li>如果指定了maxSplitSize(&#8220;mapreduce.input.fileinputformat.split.maxsize&#8221;)，那么在同一个节点上的Blocks合并，一个超过maxSplitSize就生成新分片。如果没有指定，则只汇总本节点BLock，暂不分片。</li>
<li>如果指定了minSizeNode(&#8220;mapreduce.input.fileinputformat.split.minsize.per.node&#8221;),那么会把1.中处理剩余的Block，进行合并，如果超过minSizeNode，那么全部作为一个分片。否则这些Block与同一机架Rack上的块进行合并。</li>
<li>每个节点上如上同样的方式处理，然后针对整个Rack的所有Block，按照1.方式处理。剩余部分，如果指定了minSizeRack(&#8220;mapreduce.input.fileinputformat.split.minsize.per.rack&#8221;)，并且超过minSizeRack，则全部作为一个分片，否则这些Block保留，等待与所有机架上的剩余Block进行汇总处理。</li>
<li>每个机架上都按照1，2，3方式处理，汇总所有处理剩下的部分，再按照1的逻辑处理。再剩余的，作为一个分片。</li>
</ol>
<p>以上逻辑我们可以知道：</p>
<p>如果只设置maxSplitSize(如job.getConfiguration().set( &#8220;mapreduce.input.fileinputformat.split.maxsize&#8221; , &#8220;33554432&#8243;))，那么基本每个分片大小都需凑满maxSplitSize。</p>
<p><strong>如果maxSplitSize，minSizeNode，minSizeRack三个都没有设置，那是所有输入整合成一个分片！</strong></p>
<p><strong>3)CombineFileRecordReader </strong></p>
<p>针对一个CombineFileSplit分片的通用RecordReader。CombineFileSplit中包含多个文件的块信息，CombineFileRecordReader是文件层面的处理，例如何时切换到分片中的下一个文件，而单个文件的处理，则需要自定义RecordReader的子类，读取文件的记录。</p>
<p>hadoop自带的示例应用org.apache.hadoop.examples.MultiFileWordCount，用到了CombineInputFormat，其处理流程：</p>
<p><a href="http://www.sqlparty.com/wp-content/uploads/2013/12/MultiFileWordCount.png" target="_blank" rel="external"><img src="http://www.sqlparty.com/wp-content/uploads/2013/12/MultiFileWordCount.png" alt="MultiFileWordCount"></a></p>
<p>要使用CombineInputFormat进行应用开发，可以参考org.apache.hadoop.examples.MultiFileWordCount中使用方式，需要自行实现CombineFileInputFormat的子类与实际读取逐条记录的RecordReader子类。</p>
<p>而MultiFileWordCount的使用如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">shell&amp;gt; hadoop fs -ls -h /tmp/carl/2013-07-12/</span><br><span class="line"></span><br><span class="line"> Found 4 items</span><br><span class="line"></span><br><span class="line"> -rw-r&amp;#8211;r&amp;#8211;   3 hdfs hadoop    246.6 M 2013-12-03 13:07 /tmp/carl/2013-07-12/000059_0</span><br><span class="line"></span><br><span class="line"> -rw-r&amp;#8211;r&amp;#8211;   3 hdfs hadoop    244.9 M 2013-12-03 13:11 /tmp/carl/2013-07-12/000124_0</span><br><span class="line"></span><br><span class="line"> -rw-r&amp;#8211;r&amp;#8211;   3 hdfs hadoop    244.9 M 2013-12-03 13:15 /tmp/carl/2013-07-12/000126_0</span><br><span class="line"></span><br><span class="line"> -rw-r&amp;#8211;r&amp;#8211;   3 hdfs hadoop     85.2 M 2013-12-03 13:17 /tmp/carl/2013-07-12/000218_0</span><br><span class="line"></span><br><span class="line">shell&amp;gt; hadoop jar hadoop-mapreduce-examples-2.0.0-cdh4.4.0.jar multifilewc /tmp/carl/2013-07-12/ /tmp/carl/c8/</span><br><span class="line"></span><br><span class="line"> &amp;#8230;</span><br><span class="line"></span><br><span class="line"> 13/12/24 19:31:23 INFO input.FileInputFormat: Total input paths to process : 4</span><br><span class="line"></span><br><span class="line"> 13/12/24 19:31:23 INFO mapreduce.JobSubmitter: number of splits:1</span><br><span class="line"></span><br><span class="line"> &amp;#8230;</span><br><span class="line"></span><br><span class="line"> Job Counters</span><br><span class="line"></span><br><span class="line"> Killed reduce tasks=1</span><br><span class="line"></span><br><span class="line"> Launched map tasks=1</span><br><span class="line"></span><br><span class="line"> Launched reduce tasks=17</span><br><span class="line"></span><br><span class="line"> Other local map tasks=1</span><br><span class="line"></span><br><span class="line"> Total time spent by all maps in occupied slots (ms)=37923</span><br><span class="line"></span><br><span class="line"> Total time spent by all reduces in occupied slots (ms)=1392681</span><br><span class="line"></span><br><span class="line"> ...</span><br></pre></td></tr></table></figure></p>
<p>因为MultiFileWordCount没有设置maxSplitSize，所以这里只有一个分片。</p>
<h2 id="4-CombineInputFormat应用"><a href="#4-CombineInputFormat应用" class="headerlink" title="4.CombineInputFormat应用"></a>4.CombineInputFormat应用</h2><h3 id="4-1-使用场景"><a href="#4-1-使用场景" class="headerlink" title="4.1.使用场景"></a>4.1.使用场景</h3><p>CombineInputFormat处理少量，较大的文件没有优势，相反，如果没有合理的设置maxSplitSize，minSizeNode，minSizeRack，则可能会导致一个map任务需要大量访问非本地的Block造成网络开销，反而比正常的非合并方式更慢。</p>
<p>而针对大量远小于块大小的小文件处理，CombineInputFormat的使用还是很有优势。</p>
<h3 id="4-2-测试"><a href="#4-2-测试" class="headerlink" title="4.2.测试"></a>4.2.测试</h3><p>我们以hadoop的示例程序WordCount和MulitFileWordCount来处理1000个小文件为例进行对比。</p>
<p>生成小文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line">shell&amp;gt; cat file_gen.sh</span><br><span class="line"></span><br><span class="line"> #!/bin/sh</span><br><span class="line"></span><br><span class="line"> for i in $(seq 1000)</span><br><span class="line"></span><br><span class="line"> do</span><br><span class="line"></span><br><span class="line"> echo &amp;#8220;abc asdf as df asd f sadf  werweiro &amp;#8220;$i &amp;gt; file_$&#123;i&#125;</span><br><span class="line"></span><br><span class="line"> done</span><br><span class="line"></span><br><span class="line"> shell&amp;gt; ./file_gen.sh</span><br><span class="line"></span><br><span class="line"> shell&amp;gt; ls -lh</span><br><span class="line"></span><br><span class="line"> &amp;#8230;</span><br><span class="line"></span><br><span class="line"> -rw-r&amp;#8211;r&amp;#8211; 1 root root 40 Dec 25 10:14 file_962</span><br><span class="line"></span><br><span class="line"> -rw-r&amp;#8211;r&amp;#8211; 1 root root 40 Dec 25 10:14 file_963</span><br><span class="line"></span><br><span class="line"> -rw-r&amp;#8211;r&amp;#8211; 1 root root 40 Dec 25 10:14 file_964</span><br><span class="line"></span><br><span class="line"> -rw-r&amp;#8211;r&amp;#8211; 1 root root 40 Dec 25 10:14 file_965</span><br><span class="line"></span><br><span class="line"> -rw-r&amp;#8211;r&amp;#8211; 1 root root 40 Dec 25 10:14 file_966</span><br><span class="line"></span><br><span class="line"> -rw-r&amp;#8211;r&amp;#8211; 1 root root 40 Dec 25 10:14 file_967</span><br><span class="line"></span><br><span class="line"> &amp;#8230;</span><br><span class="line"></span><br><span class="line">上面生成大量小文件，上传这些小文件：</span><br><span class="line"></span><br><span class="line">shell&amp;gt; hadoop fs -put file* /tmp/carl2/</span><br><span class="line"></span><br><span class="line">**wordcount**使用TextInputFormat方式，小文件一个个处理：</span><br><span class="line"></span><br><span class="line">shell&amp;gt; hadoop jar hadoop-mapreduce-examples-2.0.0-cdh4.4.0.jar wordcount /tmp/carl2/ /tmp/carl_result3/</span><br><span class="line"></span><br><span class="line"> &amp;#8230;</span><br><span class="line"></span><br><span class="line"> 13/12/25 10:34:25 INFO input.FileInputFormat: Total input paths to process : 1000</span><br><span class="line"></span><br><span class="line"> 13/12/25 10:34:27 INFO mapreduce.JobSubmitter: number of splits:1000</span><br><span class="line"></span><br><span class="line"> &amp;#8230;</span><br><span class="line"></span><br><span class="line"> 13/12/25 10:34:33 INFO mapreduce.Job:  map 0% reduce 0%</span><br><span class="line"></span><br><span class="line"> 13/12/25 10:34:40 INFO mapreduce.Job:  map 1% reduce 0%</span><br><span class="line"></span><br><span class="line"> 13/12/25 10:34:41 INFO mapreduce.Job:  map 2% reduce 0%</span><br><span class="line"></span><br><span class="line"> &amp;#8230;</span><br><span class="line"></span><br><span class="line"> 13/12/25 10:40:56 INFO mapreduce.Job:  map 100% reduce 94%</span><br><span class="line"></span><br><span class="line"> 13/12/25 10:40:57 INFO mapreduce.Job:  map 100% reduce 100%</span><br><span class="line"></span><br><span class="line"> &amp;#8230;</span><br><span class="line"></span><br><span class="line">可以看到，生成了1000个map任务，总耗时超过6分钟!</span><br><span class="line"></span><br><span class="line">**multifilewc**使用CombineInputFormat方式，没有设置maxSplitSize的情况下，所有小文件会汇总成一个Split。</span><br><span class="line"></span><br><span class="line">shell&amp;gt; hadoop jar hadoop-mapreduce-examples-2.0.0-cdh4.4.0.jar multifilewc /tmp/carl2/ /tmp/carl_result4/</span><br><span class="line"></span><br><span class="line"> &amp;#8230;</span><br><span class="line"></span><br><span class="line"> 13/12/25 10:42:04 INFO input.FileInputFormat: Total input paths to process : 1000</span><br><span class="line"></span><br><span class="line"> 13/12/25 10:42:07 INFO mapreduce.JobSubmitter: number of splits:1</span><br><span class="line"></span><br><span class="line"> &amp;#8230;</span><br><span class="line"></span><br><span class="line"> 13/12/25 10:42:12 INFO mapreduce.Job:  map 0% reduce 0%</span><br><span class="line"></span><br><span class="line"> 13/12/25 10:42:19 INFO mapreduce.Job:  map 100% reduce 0%</span><br><span class="line"></span><br><span class="line"> 13/12/25 10:42:24 INFO mapreduce.Job:  map 100% reduce 25%</span><br><span class="line"></span><br><span class="line"> 13/12/25 10:42:25 INFO mapreduce.Job:  map 100% reduce 31%</span><br><span class="line"></span><br><span class="line"> 13/12/25 10:42:27 INFO mapreduce.Job:  map 100% reduce 38%</span><br><span class="line"></span><br><span class="line"> 13/12/25 10:42:28 INFO mapreduce.Job:  map 100% reduce 56%</span><br><span class="line"></span><br><span class="line"> 13/12/25 10:42:29 INFO mapreduce.Job:  map 100% reduce 63%</span><br><span class="line"></span><br><span class="line"> 13/12/25 10:42:30 INFO mapreduce.Job:  map 100% reduce 69%</span><br><span class="line"></span><br><span class="line"> 13/12/25 10:42:31 INFO mapreduce.Job:  map 100% reduce 81%</span><br><span class="line"></span><br><span class="line"> 13/12/25 10:42:32 INFO mapreduce.Job:  map 100% reduce 88%</span><br><span class="line"></span><br><span class="line"> 13/12/25 10:42:33 INFO mapreduce.Job:  map 100% reduce 100%</span><br></pre></td></tr></table></figure></p>
<p>可以看到，只用一个map任务进行处理，大量小文件可以使用网络迅速的汇总，总耗时不到30秒！</p>
<p>测试的结果可以大致看出，针对大量小文件，使用CombineInputFormat具有较大优势。</p>
<p>参考：</p>
<p><a href="http://stackoverflow.com/questions/14541759/how-can-i-work-with-large-number-of-small-files-in-hadoop" target="_blank" rel="external">http://stackoverflow.com/questions/14541759/how-can-i-work-with-large-number-of-small-files-in-hadoop</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/12/09/Java获取与当天相差几天的日期两种方式/" itemprop="url">
                  Java获取与当天相差几天的日期两种方式
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-12-09T21:32:27+08:00" content="2016-12-09">
              2016-12-09
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Java/" itemprop="url" rel="index">
                    <span itemprop="name">Java</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/12/09/Java获取与当天相差几天的日期两种方式/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/12/09/Java获取与当天相差几天的日期两种方式/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Date date=new Date();//取时间  </span><br><span class="line">Calendar calendar = new GregorianCalendar();  </span><br><span class="line">calendar.setTime(date);  </span><br><span class="line">calendar.add(calendar.DATE,1);//把日期往后增加一天.整数往后推,负数往前移动  </span><br><span class="line">date=calendar.getTime(); //这个时间就是日期往后推一天的结果   </span><br><span class="line">SimpleDateFormat formatter = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;);  </span><br><span class="line">String dateString = formatter.format(date);  </span><br><span class="line">System.out.println(dateString);</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">/** </span><br><span class="line">     *获取两日期之间天数 </span><br><span class="line">     */  </span><br><span class="line">    public String getDate(Date d,long i)&#123;  </span><br><span class="line">         SimpleDateFormat df=new SimpleDateFormat(&quot;yyyy-MM-dd&quot;);     </span><br><span class="line">         /*System.out.println(&quot;今天的日期：&quot;+df.format(d));    </span><br><span class="line">         System.out.println(&quot;两天前的日期：&quot; + df.format(new Date(d.getTime() - 2 * 24 * 60 * 60 * 1000)));   </span><br><span class="line">         System.out.println(&quot;三天后的日期：&quot; + df.format(new Date(d.getTime() + 3 * 24 * 60 * 60 * 1000)));*/  </span><br><span class="line">         return df.format(new Date(d.getTime() + i * 24 * 60 * 60 * 1000));  </span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/12/09/Log4j配置/" itemprop="url">
                  Log4j配置
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-12-09T21:31:24+08:00" content="2016-12-09">
              2016-12-09
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Java/" itemprop="url" rel="index">
                    <span itemprop="name">Java</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/12/09/Log4j配置/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/12/09/Log4j配置/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ul>
<li><p>加入log4j-1.2.8.jar到lib下。</p>
</li>
<li><p>在CLASSPATH下建立log4j.properties。</p>
</li>
<li><p>在bin目录下加入  log4j.properties</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">#①配置根Logger，其语法为： </span><br><span class="line"># </span><br><span class="line">#log4j.rootLogger = [level],appenderName,appenderName2,... </span><br><span class="line">#level是日志记录的优先级，分为OFF,TRACE,DEBUG,INFO,WARN,ERROR,FATAL,ALL </span><br><span class="line">##Log4j建议只使用四个级别，优先级从低到高分别是DEBUG,INFO,WARN,ERROR </span><br><span class="line">#通过在这里定义的级别，您可以控制到应用程序中相应级别的日志信息的开关 </span><br><span class="line">#比如在这里定义了INFO级别，则应用程序中所有DEBUG级别的日志信息将不被打印出来 </span><br><span class="line">#appenderName就是指定日志信息输出到哪个地方。可同时指定多个输出目的 </span><br><span class="line">################################################################################ </span><br><span class="line">################################################################################ </span><br><span class="line">#②配置日志信息输出目的地Appender，其语法为： </span><br><span class="line"># </span><br><span class="line">#log4j.appender.appenderName = fully.qualified.name.of.appender.class </span><br><span class="line">#log4j.appender.appenderName.optionN = valueN </span><br><span class="line"># </span><br><span class="line">#Log4j提供的appender有以下几种： </span><br><span class="line">#1)org.apache.log4j.ConsoleAppender(输出到控制台) </span><br><span class="line">#2)org.apache.log4j.FileAppender(输出到文件) </span><br><span class="line">#3)org.apache.log4j.DailyRollingFileAppender(每天产生一个日志文件) </span><br><span class="line">#4)org.apache.log4j.RollingFileAppender(文件大小到达指定尺寸的时候产生一个新的文件) </span><br><span class="line">#5)org.apache.log4j.WriterAppender(将日志信息以流格式发送到任意指定的地方) </span><br><span class="line"># </span><br><span class="line">#1)ConsoleAppender选项属性 </span><br><span class="line"># -Threshold = DEBUG:指定日志消息的输出最低层次 </span><br><span class="line"># -ImmediateFlush = TRUE:默认值是true,所有的消息都会被立即输出 </span><br><span class="line"># -Target = System.err:默认值System.out,输出到控制台(err为红色,out为黑色) </span><br><span class="line"># </span><br><span class="line">#2)FileAppender选项属性 </span><br><span class="line"># -Threshold = INFO:指定日志消息的输出最低层次 </span><br><span class="line"># -ImmediateFlush = TRUE:默认值是true,所有的消息都会被立即输出 </span><br><span class="line"># -File = C:\log4j.log:指定消息输出到C:\log4j.log文件 </span><br><span class="line"># -Append = FALSE:默认值true,将消息追加到指定文件中，false指将消息覆盖指定的文件内容 </span><br><span class="line"># -Encoding = UTF-8:可以指定文件编码格式 </span><br><span class="line"># </span><br><span class="line">#3)DailyRollingFileAppender选项属性 </span><br><span class="line"># -Threshold = WARN:指定日志消息的输出最低层次 </span><br><span class="line"># -ImmediateFlush = TRUE:默认值是true,所有的消息都会被立即输出 </span><br><span class="line"># -File = C:\log4j.log:指定消息输出到C:\log4j.log文件 </span><br><span class="line"># -Append = FALSE:默认值true,将消息追加到指定文件中，false指将消息覆盖指定的文件内容 </span><br><span class="line"># -DatePattern=&apos;.&apos;yyyy-ww:每周滚动一次文件,即每周产生一个新的文件。还可以按用以下参数: </span><br><span class="line">#              &apos;.&apos;yyyy-MM:每月 </span><br><span class="line">#              &apos;.&apos;yyyy-ww:每周 </span><br><span class="line">#              &apos;.&apos;yyyy-MM-dd:每天 </span><br><span class="line">#              &apos;.&apos;yyyy-MM-dd-a:每天两次 </span><br><span class="line">#              &apos;.&apos;yyyy-MM-dd-HH:每小时 </span><br><span class="line">#              &apos;.&apos;yyyy-MM-dd-HH-mm:每分钟 </span><br><span class="line"># -Encoding = UTF-8:可以指定文件编码格式 </span><br><span class="line"># </span><br><span class="line">#4)RollingFileAppender选项属性 </span><br><span class="line"># -Threshold = ERROR:指定日志消息的输出最低层次 </span><br><span class="line"># -ImmediateFlush = TRUE:默认值是true,所有的消息都会被立即输出 </span><br><span class="line"># -File = C:/log4j.log:指定消息输出到C:/log4j.log文件 </span><br><span class="line"># -Append = FALSE:默认值true,将消息追加到指定文件中，false指将消息覆盖指定的文件内容 </span><br><span class="line"># -MaxFileSize = 100KB:后缀可以是KB,MB,GB.在日志文件到达该大小时,将会自动滚动.如:log4j.log.1 </span><br><span class="line"># -MaxBackupIndex = 2:指定可以产生的滚动文件的最大数 </span><br><span class="line"># -Encoding = UTF-8:可以指定文件编码格式 </span><br><span class="line">################################################################################ </span><br><span class="line">################################################################################ </span><br><span class="line">#③配置日志信息的格式(布局)，其语法为： </span><br><span class="line"># </span><br><span class="line">#log4j.appender.appenderName.layout = fully.qualified.name.of.layout.class </span><br><span class="line">#log4j.appender.appenderName.layout.optionN = valueN </span><br><span class="line"># </span><br><span class="line">#Log4j提供的layout有以下几种： </span><br><span class="line">#5)org.apache.log4j.HTMLLayout(以HTML表格形式布局) </span><br><span class="line">#6)org.apache.log4j.PatternLayout(可以灵活地指定布局模式) </span><br><span class="line">#7)org.apache.log4j.SimpleLayout(包含日志信息的级别和信息字符串) </span><br><span class="line">#8)org.apache.log4j.TTCCLayout(包含日志产生的时间、线程、类别等等信息) </span><br><span class="line">#9)org.apache.log4j.xml.XMLLayout(以XML形式布局) </span><br><span class="line"># </span><br><span class="line">#5)HTMLLayout选项属性 </span><br><span class="line"># -LocationInfo = TRUE:默认值false,输出java文件名称和行号 </span><br><span class="line"># -Title=Struts Log Message:默认值 Log4J Log Messages </span><br><span class="line"># </span><br><span class="line">#6)PatternLayout选项属性 </span><br><span class="line"># -ConversionPattern = %m%n:格式化指定的消息(参数意思下面有) </span><br><span class="line"># </span><br><span class="line">#9)XMLLayout选项属性 </span><br><span class="line"># -LocationInfo = TRUE:默认值false,输出java文件名称和行号 </span><br><span class="line"># </span><br><span class="line">#Log4J采用类似C语言中的printf函数的打印格式格式化日志信息，打印参数如下： </span><br><span class="line"># %m 输出代码中指定的消息 </span><br><span class="line"># %p 输出优先级，即DEBUG,INFO,WARN,ERROR,FATAL </span><br><span class="line"># %r 输出自应用启动到输出该log信息耗费的毫秒数 </span><br><span class="line"># %c 输出所属的类目,通常就是所在类的全名 </span><br><span class="line"># %t 输出产生该日志事件的线程名 </span><br><span class="line"># %n 输出一个回车换行符，Windows平台为“\r\n”，Unix平台为“\n” </span><br><span class="line"># %d 输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式 </span><br><span class="line">#    如：%d&#123;yyyy年MM月dd日 HH:mm:ss,SSS&#125;，输出类似：2012年01月05日 22:10:28,921 </span><br><span class="line"># %l 输出日志事件的发生位置，包括类目名、发生的线程，以及在代码中的行数 </span><br><span class="line">#    如：Testlog.main(TestLog.java:10) </span><br><span class="line"># %F 输出日志消息产生时所在的文件名称 </span><br><span class="line"># %L 输出代码中的行号 </span><br><span class="line"># %x 输出和当前线程相关联的NDC(嵌套诊断环境),像java servlets多客户多线程的应用中 </span><br><span class="line"># %% 输出一个&quot;%&quot;字符 </span><br><span class="line"># </span><br><span class="line"># 可以在%与模式字符之间加上修饰符来控制其最小宽度、最大宽度、和文本的对齐方式。如： </span><br><span class="line">#  %5c: 输出category名称，最小宽度是5，category&lt;5，默认的情况下右对齐 </span><br><span class="line">#  %-5c:输出category名称，最小宽度是5，category&lt;5，&quot;-&quot;号指定左对齐,会有空格 </span><br><span class="line">#  %.5c:输出category名称，最大宽度是5，category&gt;5，就会将左边多出的字符截掉，&lt;5不会有空格 </span><br><span class="line">#  %20.30c:category名称&lt;20补空格，并且右对齐，&gt;30字符，就从左边交远销出的字符截掉 </span><br><span class="line">################################################################################ </span><br><span class="line">################################################################################ </span><br><span class="line">#④指定特定包的输出特定的级别 </span><br><span class="line">#log4j.logger.org.springframework=DEBUG </span><br><span class="line">################################################################################ </span><br><span class="line"></span><br><span class="line">#OFF,systemOut,logFile,logDailyFile,logRollingFile,logMail,logDB,ALL </span><br><span class="line">log4j.rootLogger =ALL,systemOut,logFile,logDailyFile,logRollingFile,logMail,logDB </span><br><span class="line"></span><br><span class="line">#输出到控制台 </span><br><span class="line">log4j.appender.systemOut = org.apache.log4j.ConsoleAppender </span><br><span class="line">log4j.appender.systemOut.layout = org.apache.log4j.PatternLayout </span><br><span class="line">log4j.appender.systemOut.layout.ConversionPattern = [%-5p][%-22d&#123;yyyy/MM/dd HH:mm:ssS&#125;][%l]%n%m%n </span><br><span class="line">log4j.appender.systemOut.Threshold = DEBUG </span><br><span class="line">log4j.appender.systemOut.ImmediateFlush = TRUE </span><br><span class="line">log4j.appender.systemOut.Target = System.out </span><br><span class="line"></span><br><span class="line">#输出到文件 </span><br><span class="line">log4j.appender.logFile = org.apache.log4j.FileAppender </span><br><span class="line">log4j.appender.logFile.layout = org.apache.log4j.PatternLayout </span><br><span class="line">log4j.appender.logFile.layout.ConversionPattern = [%-5p][%-22d&#123;yyyy/MM/dd HH:mm:ssS&#125;][%l]%n%m%n </span><br><span class="line">log4j.appender.logFile.Threshold = DEBUG </span><br><span class="line">log4j.appender.logFile.ImmediateFlush = TRUE </span><br><span class="line">log4j.appender.logFile.Append = TRUE </span><br><span class="line">log4j.appender.logFile.File = ../Struts2/WebRoot/log/File/log4j_Struts.log </span><br><span class="line">log4j.appender.logFile.Encoding = UTF-8 </span><br><span class="line"></span><br><span class="line">#按DatePattern输出到文件 </span><br><span class="line">log4j.appender.logDailyFile = org.apache.log4j.DailyRollingFileAppender </span><br><span class="line">log4j.appender.logDailyFile.layout = org.apache.log4j.PatternLayout </span><br><span class="line">log4j.appender.logDailyFile.layout.ConversionPattern = [%-5p][%-22d&#123;yyyy/MM/dd HH:mm:ssS&#125;][%l]%n%m%n </span><br><span class="line">log4j.appender.logDailyFile.Threshold = DEBUG </span><br><span class="line">log4j.appender.logDailyFile.ImmediateFlush = TRUE </span><br><span class="line">log4j.appender.logDailyFile.Append = TRUE </span><br><span class="line">log4j.appender.logDailyFile.File = ../Struts2/WebRoot/log/DailyFile/log4j_Struts </span><br><span class="line">log4j.appender.logDailyFile.DatePattern = &apos;.&apos;yyyy-MM-dd-HH-mm&apos;.log&apos; </span><br><span class="line">log4j.appender.logDailyFile.Encoding = UTF-8 </span><br><span class="line"></span><br><span class="line">#设定文件大小输出到文件 </span><br><span class="line">log4j.appender.logRollingFile = org.apache.log4j.RollingFileAppender </span><br><span class="line">log4j.appender.logRollingFile.layout = org.apache.log4j.PatternLayout </span><br><span class="line">log4j.appender.logRollingFile.layout.ConversionPattern = [%-5p][%-22d&#123;yyyy/MM/dd HH:mm:ssS&#125;][%l]%n%m%n </span><br><span class="line">log4j.appender.logRollingFile.Threshold = DEBUG </span><br><span class="line">log4j.appender.logRollingFile.ImmediateFlush = TRUE </span><br><span class="line">log4j.appender.logRollingFile.Append = TRUE </span><br><span class="line">log4j.appender.logRollingFile.File = ../Struts2/WebRoot/log/RollingFile/log4j_Struts.log </span><br><span class="line">log4j.appender.logRollingFile.MaxFileSize = 1MB </span><br><span class="line">log4j.appender.logRollingFile.MaxBackupIndex = 10 </span><br><span class="line">log4j.appender.logRollingFile.Encoding = UTF-8 </span><br><span class="line"></span><br><span class="line">#用Email发送日志 </span><br><span class="line">log4j.appender.logMail = org.apache.log4j.net.SMTPAppender </span><br><span class="line">log4j.appender.logMail.layout = org.apache.log4j.HTMLLayout </span><br><span class="line">log4j.appender.logMail.layout.LocationInfo = TRUE </span><br><span class="line">log4j.appender.logMail.layout.Title = Struts2 Mail LogFile </span><br><span class="line">log4j.appender.logMail.Threshold = DEBUG </span><br><span class="line">log4j.appender.logMail.SMTPDebug = FALSE </span><br><span class="line">log4j.appender.logMail.SMTPHost = SMTP.163.com </span><br><span class="line">log4j.appender.logMail.From = xly3000@163.com </span><br><span class="line">log4j.appender.logMail.To = xly3000@gmail.com </span><br><span class="line">#log4j.appender.logMail.Cc = xly3000@gmail.com </span><br><span class="line">#log4j.appender.logMail.Bcc = xly3000@gmail.com </span><br><span class="line">log4j.appender.logMail.SMTPUsername = xly3000 </span><br><span class="line">log4j.appender.logMail.SMTPPassword = 1234567 </span><br><span class="line">log4j.appender.logMail.Subject = Log4j Log Messages </span><br><span class="line">#log4j.appender.logMail.BufferSize = 1024 </span><br><span class="line">#log4j.appender.logMail.SMTPAuth = TRUE </span><br><span class="line"></span><br><span class="line">#将日志登录到MySQL数据库 </span><br><span class="line">log4j.appender.logDB = org.apache.log4j.jdbc.JDBCAppender </span><br><span class="line">log4j.appender.logDB.layout = org.apache.log4j.PatternLayout </span><br><span class="line">log4j.appender.logDB.Driver = com.mysql.jdbc.Driver </span><br><span class="line">log4j.appender.logDB.URL = jdbc:mysql://127.0.0.1:3306/xly </span><br><span class="line">log4j.appender.logDB.User = root </span><br><span class="line">log4j.appender.logDB.Password = 123456 </span><br><span class="line">log4j.appender.logDB.Sql = INSERT INTOT_log4j(project_name,create_date,level,category,file_name,thread_name,line,all_category,message)values(&apos;Struts2&apos;,&apos;%d&#123;yyyy-MM-ddHH:mm:ss&#125;&apos;,&apos;%p&apos;,&apos;%c&apos;,&apos;%F&apos;,&apos;%t&apos;,&apos;%L&apos;,&apos;%l&apos;,&apos;%m&apos;)</span><br></pre></td></tr></table></figure>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/12/02/mapreduce调优/" itemprop="url">
                  mapreduce调优
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-12-02T09:16:39+08:00" content="2016-12-02">
              2016-12-02
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/12/02/mapreduce调优/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/12/02/mapreduce调优/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="对应用程序进行调优"><a href="#对应用程序进行调优" class="headerlink" title="对应用程序进行调优"></a>对应用程序进行调优</h2><ol>
<li><p>避免输入大量小文件。大量的小文件(不足一个block大小)作为输入数据会产生很多的Map任务(默认一个分片对应一个Map任务)，而每个Map任务实际工作量又非常小，系统要花更多的时间来将这些Map任务的输出进行整合。如果将大量的小文件进行预处理合并成一个或几个大文件，任务执行的效率可能会提升几十倍。可手动将小文件合并成大文件，或通过Hadoop的SequenceFile、CombineFileInputFormat将多个文件打包到一个输入单元中，使得每个Map处理更多的数据，从而提高性能。</p>
</li>
<li><p>输入文件size巨大，但不是小文件。这种情况可以通过增大每个mapper的input size，即增大minSize或者增大blockSize来减少所需的mapper的数量。增大blockSize通常不可行，因为当HDFS被hadoop namenode -format之后，blockSize就已经确定了（由格式化时dfs.block.size决定），如果要更改blockSize，需要重新格式化HDFS，这样当然会丢失已有的数据。所以通常情况下只能通过增大minSize，即增大mapred.min.split.size的值。</p>
</li>
<li><p>预判并过滤无用数据。可以使用一些过滤工具，在作业执行之前将数据中无用的数据进行过滤，可极大提高MapReduce执行效率。Bloom Filter是一种功能强大的过滤器，执行效率高，时间复杂度为O(1)，缺点是存在一定的误判可能，详细参考《Bloom Filter概念和原理》。当将一个非常大的表和一个非常小的表进行表连接操作时，可以使用Bloom Filter将小表数据作为Bloom Filter的输入数据，将大表的原始数据进行过滤(过滤不通过的数据一定是不可用的，过滤通过的数据可能有用可能无用)，可提高程序执行的效率。</p>
</li>
<li><p>合理使用分布式缓存DistributedCache。DistributedCache可以将一些字典、jar包、配置文件等缓存到需要执行map任务的节点中，避免map任务多次重复读取这些资源，尤其在join操作时，使用DistributedCache缓存小表数据在map端进行join操作，可避免shuffle、reduce等操作，提高程序运行效率。</p>
</li>
<li><p>重用Writable类型。避免大量多次new这些Writable对象，这会花费java垃圾收集器大量的清理工作，建议在map函数外定义这些Writable对象，如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">class MyMapper … &#123;</span><br><span class="line">    Text wordText = new Text();</span><br><span class="line">    IntWritable one = new IntWritable(1);</span><br><span class="line">    public void map(...) &#123;</span><br><span class="line">        for (String word: words) &#123;</span><br><span class="line">            wordText.set(word);</span><br><span class="line">            context.write(wordText, one);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>合理设置Combiner。Combine阶段处于Map端操作的最后一步，设置Combine操作可大大提高MapReduce的执行效率，前提是增加Combine不能改变最终的结果值，换句话说，不是所有的MapReduce程序都能添加Combine，如求平均数的MapReduce程序就不适合设置Combine操作。通常Combine函数与Reduce函数一致</p>
</li>
</ol>
<h2 id="对参数进行调优（基于hadoop2-6-0）"><a href="#对参数进行调优（基于hadoop2-6-0）" class="headerlink" title="对参数进行调优（基于hadoop2.6.0）"></a>对参数进行调优（基于hadoop2.6.0）</h2><p><strong>HDFS参数调优(hdfs-site.xml)</strong></p>
<ul>
<li><p>dfs.namenode.handler.count：namenode用于处理RPC的线程数，默认值10，可根据NameNode所在节点机器配置适当调大，如32、64；</p>
</li>
<li><p>dfs.datanode.handler.count：datanode上用于处理RPC的线程数，2.6版本默认值10，早期1.x版本默认值为3，可根据datanode节点的配置适当调整；</p>
</li>
</ul>
<p><strong>MapReduce参数调优(mapred-site.xml)</strong></p>
<ul>
<li><p>mapreduce.tasktracker.map.tasks.maximum：每个nodemanager节点上可运行的最大map任务数，默认值2，可根据实际值调整为10~100；</p>
</li>
<li><p>mapreduce.tasktracker.reduce.tasks.maximum：每个nodemanager节点上可运行的最大reduce任务数，默认值2，可根据实际值调整为10~100；</p>
</li>
<li><p>mapreduce.output.fileoutputformat.compress：是否对任务输出产生的结果进行压缩，默认值false。对传输数据进行压缩，既可以减少文件的存储空间，又可以加快数据在网络不同节点之间的传输速度。</p>
</li>
<li><p>mapreduce.output.fileoutputformat.compress.type：输出产生任务数据的压缩方式，默认值RECORD，可配置值有：NONE、RECORD、BLOCK</p>
</li>
<li><p>mapreduce.map.output.compress：map端压缩</p>
</li>
<li><p>mapreduce.map.output.compress.codec：map压缩格式</p>
</li>
<li><p>mapreduce.task.io.sort.mb：map任务输出结果的内存环形缓冲区大小，默认值100M，可根据map节点的机器进行配置，貌似不能超过值mapred.child.java.opts；</p>
</li>
<li><p>mapreduce.map.sort.spill.percent：map任务输出环形缓冲区大小溢写触发最大比例，默认值80%，这个值一般不建议修改；</p>
</li>
<li><p>mapreduce.reduce.shuffle.parallelcopies：reduce节点通过http拷贝map输出结果数据到本地的最大工作线程数，默认值5，可根据节点机器配置适当修改；</p>
</li>
<li><p>mapreduce.reduce.shuffle.input.buffer.percent：reduce节点在shuffle阶段拷贝map输出结果数据到本地时，内存缓冲区大小所占JVM内存的比例，默认值0.7，一般不建议修改；</p>
</li>
<li><p>mapreduce.reduce.shuffle.merge.percent：reduce节点shuffle内存缓冲区溢写触发最大比例，默认值0.66，一般不建议修改；</p>
</li>
<li><p>mapred.child.java.opts：配置每个map或reduce使用的内存数量，默认值-Xmx200m，即200M。如果nodemanager所在节点</p>
</li>
</ul>
<h2 id="Map和Reduce个数设置"><a href="#Map和Reduce个数设置" class="headerlink" title="Map和Reduce个数设置"></a>Map和Reduce个数设置</h2><ol>
<li><p>map的数量<br>map的数量通常是由hadoop集群的DFS块大小确定的，也就是输入文件的总块数，正常的map数量的并行规模大致是每一个Node是10~100个，对于CPU消耗较小的作业可以设置Map数量为300个左右，但是由于hadoop的没一个任务在初始化时需要一定的时间，因此比较合理的情况是每个map执行的时间至少超过1分钟。具体的数据分片是这样的，InputFormat在默认情况下会根据hadoop集群的DFS块大小进行分片，每一个分片会由一个map任务来进行处理，当然用户还是可以通过参数mapred.min.split.size参数在作业提交客户端进行自定义设置。还有一个重要参数就是mapred.map.tasks，这个参数设置的map数量仅仅是一个提示，只有当InputFormat 决定了map任务的个数比mapred.map.tasks值小时才起作用。同样，Map任务的个数也能通过使用JobConf 的conf.setNumMapTasks(int num)方法来手动地设置。这个方法能够用来增加map任务的个数，但是不能设定任务的个数小于Hadoop系统通过分割输入数据得到的值。因此，如果你有一个大小是10TB的输入数据，并设置DFS块大小为 128M，你必须设置至少82K个map任务，除非你设置的mapred.map.tasks参数比这个数还要大。当然为了提高集群的并发效率，可以设置一个默认的map数量，当用户的map数量较小或者比本身自动分割的值还小时可以使用一个相对交大的默认值，从而提高整体hadoop集群的效率。</p>
</li>
<li><p>reduece的数量<br>reduce在运行时往往需要从相关map端复制数据到reduce节点来处理，因此相比于map任务。reduce节点资源是相对比较缺少的，同时相对运行较慢，正确的reduce任务的个数应该是0.95或者1.75 *（节点数 ×mapred.tasktracker.tasks.maximum参数值）。mapred.tasktracker.tasks.reduce.maximum的数量一般设置为各节点cpu core数量,或者数量减1，即能同时计算的slot数量。如果任务数是节点个数的0.95倍，那么所有的reduce任务能够在 map任务的输出传输结束后同时开始运行。如果任务数是节点个数的1.75倍，那么高速的节点会在完成他们第一批reduce任务计算之后开始计算第二批 reduce任务，这样的情况更有利于负载均衡。同时需要注意增加reduce的数量虽然会增加系统的资源开销，但是可以改善负载匀衡，降低任务失败带来的负面影响。同样，Reduce任务也能够与 map任务一样，通过设定JobConf 的conf.setNumReduceTasks(int num)方法来增加任务个数。<br>cpu数量 = 服务器CPU总核数 / 每个CPU的核数<br>服务器CPU总核数 = more /proc/cpuinfo | grep ‘processor’ | wc -l<br>每个CPU的核数 = more /proc/cpuinfo | grep ‘cpu cores’</p>
</li>
<li><p>reduce数量为0<br>有些作业不需要进行归约进行处理，那么就可以设置reduce的数量为0来进行处理，这种情况下用户的作业运行速度相对较高，map的输出会直接写入到 SetOutputPath(path)设置的输出目录，而不是作为中间结果写到本地。同时Hadoop框架在写入文件系统前并不对之进行排序。</p>
</li>
</ol>
<p>参考转载</p>
<blockquote>
<p><a href="http://www.cnblogs.com/hanganglin/p/4563716.html" target="_blank" rel="external">http://www.cnblogs.com/hanganglin/p/4563716.html</a><br><a href="https://my.oschina.net/Chanthon/blog/150500" target="_blank" rel="external">https://my.oschina.net/Chanthon/blog/150500</a></p>
</blockquote>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/11/29/Jena学习笔记（二） SPARQL/" itemprop="url">
                  Jena学习笔记（二） SPARQL
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-11-29T22:11:29+08:00" content="2016-11-29">
              2016-11-29
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/paper/" itemprop="url" rel="index">
                    <span itemprop="name">paper</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/11/29/Jena学习笔记（二） SPARQL/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/11/29/Jena学习笔记（二） SPARQL/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>官方描述：Apache Jena（或简称Jena）是一个用于构建语义Web和关联数据应用程序的自由和开源的Java框架。 该框架由不同的API组成，用于处理RDF数据。</p>
<p>Jena是一个用于Java语义Web应用程序的API（应用程序编程接口）。它不是一个程序或工具，如果这是你正在寻找，我建议或许TopBraid Composer作为一个好的选择。因此，Jena的主要用途是帮助您编写处理RDF和OWL文档和描述的Java代码。</p>
<p>SPARQL是用于访问由W3C RDF数据访问工作组设计的RDF的查询语言和协议。</p>
<p>作为一种查询语言，SPARQL是“数据导向的”，因为它只查询模型中保存的信息;在查询语言本身没有推理。当然，Jena模型是“聪明的”，因为它提供了某些三元组存在的印象，即按需创建它们，包括OWL推理。除了以查询的形式获取应用程序想要的描述外，SPARQL不执行任何操作，并以一组bindings或RDF图形的形式返回该信息。</p>
</blockquote>
<p>官方网站：<a href="http://jena.apache.org/index.html" target="_blank" rel="external">http://jena.apache.org/index.html</a><br>SPARQL教程：<a href="http://jena.apache.org/tutorials/sparql.html" target="_blank" rel="external">http://jena.apache.org/tutorials/sparql.html</a></p>
<hr>
<h3 id="设置环境变量"><a href="#设置环境变量" class="headerlink" title="设置环境变量"></a>设置环境变量</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Setting up your Environment</span><br><span class="line">An environment variable JENAROOT is used by all the command line tools to configure the class path automatically for you. You can set this up as follows:</span><br><span class="line"></span><br><span class="line">On Linux / Mac</span><br><span class="line"></span><br><span class="line">export JENAROOT=the directory you downloaded Jena to</span><br><span class="line">export PATH=$PATH:$JENAROOT/bin</span><br><span class="line">On Windows</span><br><span class="line"></span><br><span class="line">SET JENAROOT=the directory you downloaded Jena to</span><br><span class="line">SET PATH=%PATH%;%JENAROOT%\bat</span><br></pre></td></tr></table></figure>
<h3 id="数据格式"><a href="#数据格式" class="headerlink" title="数据格式"></a>数据格式</h3><p>首先，我们需要清楚查询要查询的数据。 SPARQL查询RDF图。 RDF图是一组三元组（Jena调用RDF图“模型”和三元组“语句”，因为这是他们在第一次设计Jena API时调用的）。</p>
<p>重要的是要意识到三元组的重要性，而不是序列化。序列化只是一种写三元组的方式。 RDF / XML是W3C的建议，但是可能很难看到序列化形式的三元组，因为有多种方法来编码同一个图。在本教程中，我们使用了一个更像“三元组”的序列化，称为Turtle（另请参阅W3C语义网络引文中描述的N3语言）。</p>
<p>我们将从vc-db-1.rdf中的简单数据开始：此文件包含用于多个vCard人员描述的RDF。 vCard在RFC2426中描述，并且RDF翻译在W3C笔记“在RDF / XML中表示vCard对象”中描述。我们的示例数据库只包含一些名称信息。</p>
<p>图形上，数据看起来像：<br><img src="http://i.imgur.com/Nd0fFky.png" alt=""></p>
<p>在三元组中，如下所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">@prefix vCard:   &lt;http://www.w3.org/2001/vcard-rdf/3.0#&gt; .</span><br><span class="line">@prefix rdf:     &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt; .</span><br><span class="line">@prefix :        &lt;#&gt; .</span><br><span class="line"></span><br><span class="line">&lt;http://somewhere/MattJones/&gt;</span><br><span class="line">    vCard:FN    &quot;Matt Jones&quot; ;</span><br><span class="line">    vCard:N     [ vCard:Family</span><br><span class="line">                              &quot;Jones&quot; ;</span><br><span class="line">                  vCard:Given</span><br><span class="line">                              &quot;Matthew&quot;</span><br><span class="line">                ] .</span><br><span class="line"></span><br><span class="line">&lt;http://somewhere/RebeccaSmith/&gt;</span><br><span class="line">    vCard:FN    &quot;Becky Smith&quot; ;</span><br><span class="line">    vCard:N     [ vCard:Family</span><br><span class="line">                              &quot;Smith&quot; ;</span><br><span class="line">                  vCard:Given</span><br><span class="line">                              &quot;Rebecca&quot;</span><br><span class="line">                ] .</span><br><span class="line"></span><br><span class="line">&lt;http://somewhere/JohnSmith/&gt;</span><br><span class="line">    vCard:FN    &quot;John Smith&quot; ;</span><br><span class="line">    vCard:N     [ vCard:Family</span><br><span class="line">                              &quot;Smith&quot; ;</span><br><span class="line">                  vCard:Given</span><br><span class="line">                              &quot;John&quot;</span><br><span class="line">                ] .</span><br><span class="line"></span><br><span class="line">&lt;http://somewhere/SarahJones/&gt;</span><br><span class="line">    vCard:FN    &quot;Sarah Jones&quot; ;</span><br><span class="line">    vCard:N     [ vCard:Family</span><br><span class="line">                              &quot;Jones&quot; ;</span><br><span class="line">                  vCard:Given</span><br><span class="line">                              &quot;Sarah&quot;</span><br><span class="line">                ] .</span><br></pre></td></tr></table></figure></p>
<p>更加明确的：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">@prefix vCard:   &lt;http://www.w3.org/2001/vcard-rdf/3.0#&gt; .</span><br><span class="line">@prefix rdf:     &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt; .</span><br><span class="line"></span><br><span class="line">&lt;http://somewhere/MattJones/&gt;  vCard:FN   &quot;Matt Jones&quot; .</span><br><span class="line">&lt;http://somewhere/MattJones/&gt;  vCard:N    _:b0 .</span><br><span class="line">_:b0  vCard:Family &quot;Jones&quot; .</span><br><span class="line">_:b0  vCard:Given  &quot;Matthew&quot; .</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;http://somewhere/RebeccaSmith/&gt; vCard:FN    &quot;Becky Smith&quot; .</span><br><span class="line">&lt;http://somewhere/RebeccaSmith/&gt; vCard:N     _:b1 .</span><br><span class="line">_:b1 vCard:Family &quot;Smith&quot; .</span><br><span class="line">_:b1 vCard:Given  &quot;Rebecca&quot; .</span><br><span class="line"></span><br><span class="line">&lt;http://somewhere/JohnSmith/&gt;    vCard:FN    &quot;John Smith&quot; .</span><br><span class="line">&lt;http://somewhere/JohnSmith/&gt;    vCard:N     _:b2 .</span><br><span class="line">_:b2 vCard:Family &quot;Smith&quot; .</span><br><span class="line">_:b2 vCard:Given  &quot;John&quot;  .</span><br><span class="line"></span><br><span class="line">&lt;http://somewhere/SarahJones/&gt;   vCard:FN    &quot;Sarah Jones&quot; .</span><br><span class="line">&lt;http://somewhere/SarahJones/&gt;   vCard:N     _:b3 .</span><br><span class="line">_:b3 vCard:Family  &quot;Jones&quot; .</span><br><span class="line">_:b3 vCard:Given   &quot;Sarah&quot; .</span><br></pre></td></tr></table></figure></p>
<p>重要的是要意识到这些是相同的RDF图，并且图中的三元组没有特定的顺序。计算机不在乎其顺序。</p>
<h3 id="第一个SPARQL查询"><a href="#第一个SPARQL查询" class="headerlink" title="第一个SPARQL查询"></a>第一个SPARQL查询</h3><p>看一个简单的查询并展示如何使用Jena执行它。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SELECT ?x</span><br><span class="line">WHERE &#123; ?x  &lt;http://www.w3.org/2001/vcard-rdf/3.0#FN&gt;  &quot;John Smith&quot; &#125;</span><br></pre></td></tr></table></figure></p>
<p>用命令行查询应用程序执行所述查询:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">---------------------------------</span><br><span class="line">| x                             |</span><br><span class="line">=================================</span><br><span class="line">| &lt;http://somewhere/JohnSmith/&gt; |</span><br><span class="line">---------------------------------</span><br></pre></td></tr></table></figure></p>
<p>这通过将WHERE子句中的三元模式与RDF图中的三元组进行匹配来实现。三元组的谓词和对象是固定值，因此模式将只匹配与这些值的三元组。主体是一个变量，并且对变量没有其他限制。模式匹配任何三元组与这些谓词和对象值，它匹配x的结果。</p>
<p>&lt;&gt;中包含的项目是一个URI（实际上是一个IRI），而包含在“”中的项目是一个普通的字面量。就像Turtle，N3或N-triples一样，输入的文字用\ ^ \ ^编写，语言标签可以用@添加。</p>
<p>？x是一个称为x的变量。？不会形成名称的一部分，这就是为什么它不会出现在表的输出中。<br>该查询返回x查询变量中的匹配项。所示的输出是通过一条ARQ的命令获得的。</p>
<h4 id="执行查询"><a href="#执行查询" class="headerlink" title="执行查询"></a>执行查询</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Windows setup</span><br><span class="line">Execute:</span><br><span class="line"></span><br><span class="line">bat\sparql.bat --data=doc\Tutorial\vc-db-1.rdf --query=doc\Tutorial\q1.rq</span><br><span class="line">You can just put the bat/ directory on your classpath or copy the programs out of it.</span><br><span class="line"></span><br><span class="line">bash scripts for Linux/Cygwin/Unix</span><br><span class="line">Execute:</span><br><span class="line"></span><br><span class="line">bin/sparql --data=doc/Tutorial/vc-db-1.rdf --query=doc/Tutorial/q1.rq</span><br></pre></td></tr></table></figure>
<p>在Linux中执行结果<br><img src="http://i.imgur.com/HvWk6xW.png" alt=""></p>
<h4 id="获取所有人的FullName"><a href="#获取所有人的FullName" class="headerlink" title="获取所有人的FullName"></a>获取所有人的FullName</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SELECT ?x ?fname</span><br><span class="line">WHERE &#123;?x  &lt;http://www.w3.org/2001/vcard-rdf/3.0#FN&gt;  ?fname&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">//执行</span><br><span class="line">ubuntu@master:~/paper/doc$ sparql --data=vc-db-1.rdf --query=q-bp1.rq</span><br><span class="line">----------------------------------------------------</span><br><span class="line">| x                                | fname         |</span><br><span class="line">====================================================</span><br><span class="line">| &lt;http://somewhere/JohnSmith/&gt;    | &quot;John Smith&quot;  |</span><br><span class="line">| &lt;http://somewhere/SarahJones/&gt;   | &quot;Sarah Jones&quot; |</span><br><span class="line">| &lt;http://somewhere/MattJones/&gt;    | &quot;Matt Jones&quot;  |</span><br><span class="line">| &lt;http://somewhere/RebeccaSmith/&gt; | &quot;Becky Smith&quot; |</span><br><span class="line">----------------------------------------------------</span><br></pre></td></tr></table></figure>
<h4 id="指定前缀"><a href="#指定前缀" class="headerlink" title="指定前缀"></a>指定前缀</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@master:~/paper/doc$ cat q2.rq </span><br><span class="line">PREFIX vCard:      &lt;http://www.w3.org/2001/vcard-rdf/3.0#&gt;</span><br><span class="line"></span><br><span class="line">SELECT ?x</span><br><span class="line">WHERE</span><br><span class="line"> &#123; ?x vCard:FN &quot;John Smith&quot; &#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@master:~/paper/doc$ sparql --data=vc-db-1.rdf --query=q2.rq</span><br><span class="line">---------------------------------</span><br><span class="line">| x                             |</span><br><span class="line">=================================</span><br><span class="line">| &lt;http://somewhere/JohnSmith/&gt; |</span><br><span class="line">---------------------------------</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/11/26/Jena学习笔记（一） RDF/" itemprop="url">
                  Jena学习笔记（一） RDF
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-11-26T22:56:02+08:00" content="2016-11-26">
              2016-11-26
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/paper/" itemprop="url" rel="index">
                    <span itemprop="name">paper</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/11/26/Jena学习笔记（一） RDF/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/11/26/Jena学习笔记（一） RDF/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>官方描述：Apache Jena（或简称Jena）是一个用于构建语义Web和关联数据应用程序的自由和开源的Java框架。 该框架由不同的API组成，用于处理RDF数据。</p>
<p>Jena是一个用于Java语义Web应用程序的API（应用程序编程接口）。它不是一个程序或工具，如果这是你正在寻找，我建议或许TopBraid Composer作为一个好的选择。因此，Jena的主要用途是帮助您编写处理RDF和OWL文档和描述的Java代码。</p>
</blockquote>
<p>官方网站：<a href="http://jena.apache.org/index.html" target="_blank" rel="external">http://jena.apache.org/index.html</a><br>RDF API教程：<a href="http://jena.apache.org/tutorials/rdf_api.html" target="_blank" rel="external">http://jena.apache.org/tutorials/rdf_api.html</a></p>
<hr>
<h3 id="RDF定义"><a href="#RDF定义" class="headerlink" title="RDF定义"></a>RDF定义</h3><p>资源描述框架（RDF）是最初设计为元数据数据模型的万维网联盟（W3C）规范[1]的家族。 它已经被用作用于概念描述或者在web资源中实现的信息的建模的一般方法，使用各种语法符号和数据串行化格式。 它也用于知识管理应用程序中。<br>RDF数据模型类似于诸如实体关系或类图的经典概念建模方法，因为它基于以主语谓词对象的形式对资源（特别是web资源）进行语句表。这些表达式在RDF术语中称为三元组。主语表示资源，谓词表示资源的特征或方面，并且表示主语和对象之间的关系。例如，在RDF中表示“天空具有蓝色”的概念的一种方式是作为三元组：表示“天空”的主题，表示“具有颜色”的谓词和表示“蓝色”的对象。因此，RDF将面向对象设计中的实体 - 属性 - 值模型的经典符号中使用的对象交换对象;实体（天空），属性（颜色）和值（蓝色）。 RDF是具有几种串行格式（即，文件格式）的抽象模型，因此资源或三元组被编码的特定方式随格式而变化。</p>
<h3 id="下载Jena并从Eclipse建立工程，导入jar"><a href="#下载Jena并从Eclipse建立工程，导入jar" class="headerlink" title="下载Jena并从Eclipse建立工程，导入jar"></a>下载Jena并从Eclipse建立工程，导入jar</h3><ul>
<li>RDF API 教程 <a href="http://jena.apache.org/tutorials/rdf_api.html" target="_blank" rel="external">http://jena.apache.org/tutorials/rdf_api.html</a></li>
</ul>
<h3 id="建立如下RDF图并打印"><a href="#建立如下RDF图并打印" class="headerlink" title="建立如下RDF图并打印"></a>建立如下RDF图并打印</h3><p><img src="http://i.imgur.com/m8ZtRNG.png" alt=""><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">package com.hdu.rdf;</span><br><span class="line"></span><br><span class="line">import org.apache.jena.rdf.model.Model;</span><br><span class="line">import org.apache.jena.rdf.model.ModelFactory;</span><br><span class="line">import org.apache.jena.rdf.model.Property;</span><br><span class="line">import org.apache.jena.rdf.model.RDFNode;</span><br><span class="line">import org.apache.jena.rdf.model.Resource;</span><br><span class="line">import org.apache.jena.rdf.model.Statement;</span><br><span class="line">import org.apache.jena.rdf.model.StmtIterator;</span><br><span class="line">import org.apache.jena.vocabulary.VCARD;</span><br><span class="line"></span><br><span class="line">public class Tutorial2AddProperty &#123;</span><br><span class="line">	public static void main(String[] args) &#123;</span><br><span class="line">		// some definitions</span><br><span class="line">		String personURI = &quot;http://somewhere/JohnSmith&quot;;</span><br><span class="line">		String givenName = &quot;John&quot;;</span><br><span class="line">		String familyName = &quot;Smith&quot;;</span><br><span class="line">		String fullName = givenName + &quot; &quot; + familyName;</span><br><span class="line"></span><br><span class="line">		// create an empty model</span><br><span class="line">		Model model = ModelFactory.createDefaultModel();</span><br><span class="line"></span><br><span class="line">		// create the resource</span><br><span class="line">		// and add the properties cascading style</span><br><span class="line">		Resource johnSmith = model.createResource(personURI).addProperty(VCARD.FN, fullName).addProperty(VCARD.N,</span><br><span class="line">				model.createResource().addProperty(VCARD.Given, givenName).addProperty(VCARD.Family, familyName));</span><br><span class="line">		// model.write(System.out);</span><br><span class="line"></span><br><span class="line">		// list the statements in the graph</span><br><span class="line">		StmtIterator iter = model.listStatements();</span><br><span class="line">		// print out the predicate, subject and object of each statement</span><br><span class="line">		while (iter.hasNext()) &#123;</span><br><span class="line">			Statement stmt = iter.nextStatement();</span><br><span class="line">			Resource subject = stmt.getSubject(); // get the subject</span><br><span class="line">			Property predicate = stmt.getPredicate(); // get the predicate</span><br><span class="line">			RDFNode object = stmt.getObject(); // get the object</span><br><span class="line"></span><br><span class="line">			System.out.print(subject.toString());</span><br><span class="line">			System.out.print(&quot; &quot; + predicate.toString() + &quot; &quot;);</span><br><span class="line">			if (object instanceof Resource) &#123;</span><br><span class="line">				System.out.print(object.toString());</span><br><span class="line">			&#125; else &#123;</span><br><span class="line">				// object is a literal</span><br><span class="line">				System.out.print(&quot; \&quot;&quot; + object.toString() + &quot;\&quot;&quot;);</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			System.out.println(&quot; .&quot;);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>结果</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">//iterator遍历 每行包含三个字段，表示每个语句的主题，谓词和对象</span><br><span class="line">http://somewhere/JohnSmith http://www.w3.org/2001/vcard-rdf/3.0#N anon:14df86:ecc3dee17b:-7fff .</span><br><span class="line">anon:14df86:ecc3dee17b:-7fff http://www.w3.org/2001/vcard-rdf/3.0#Family  &quot;Smith&quot; .</span><br><span class="line">anon:14df86:ecc3dee17b:-7fff http://www.w3.org/2001/vcard-rdf/3.0#Given  &quot;John&quot; .</span><br><span class="line">http://somewhere/JohnSmith http://www.w3.org/2001/vcard-rdf/3.0#FN  &quot;John Smith&quot; .</span><br><span class="line"></span><br><span class="line">//write输出  xml格式</span><br><span class="line">&lt;rdf:RDF</span><br><span class="line">  xmlns:rdf=&apos;http://www.w3.org/1999/02/22-rdf-syntax-ns#&apos;</span><br><span class="line">  xmlns:vcard=&apos;http://www.w3.org/2001/vcard-rdf/3.0#&apos;</span><br><span class="line"> &gt;</span><br><span class="line">  &lt;rdf:Description rdf:about=&apos;http://somewhere/JohnSmith&apos;&gt;</span><br><span class="line">    &lt;vcard:FN&gt;John Smith&lt;/vcard:FN&gt;</span><br><span class="line">    &lt;vcard:N rdf:nodeID=&quot;A0&quot;/&gt;</span><br><span class="line">  &lt;/rdf:Description&gt;</span><br><span class="line">  &lt;rdf:Description rdf:nodeID=&quot;A0&quot;&gt;</span><br><span class="line">    &lt;vcard:Given&gt;John&lt;/vcard:Given&gt;</span><br><span class="line">    &lt;vcard:Family&gt;Smith&lt;/vcard:Family&gt;</span><br><span class="line">  &lt;/rdf:Description&gt;</span><br><span class="line">&lt;/rdf:RDF&gt;</span><br></pre></td></tr></table></figure></p>
<p><strong>说明</strong></p>
<p>他的RDF规范指定如何将RDF表示为XML。 RDF XML语法相当复杂。读者参考由RDFCore WG开发的引物以进行更详细的介绍。但是，让我们快速看看如何解释上面的。</p>
<p>RDF通常嵌入在<rdf：rdf>元素中。如果有其他方式知道某些XML是RDF，但是它通常存在，那么该元素是可选的。 RDF元素定义文档中使用的两个命名空间。然后是一个<rdf：description>元素，描述其URI为“http：// somewhere / JohnSmith”的资源。如果缺少rdf：about属性，则此元素将表示空白节点。</rdf：description></rdf：rdf></p>
<p><vcard：fn>元素描述了资源的属性。属性名称是vcard命名空间中的“FN”。 RDF通过连接命名空间前缀的URI引用和名称的本地名称部分的“FN”，将其转换为URI引用。这提供了一个URI引用”<a href="http://www.w3.org/2001/vcard-rdf/3.0#FN&quot;。属性的值是文字&quot;John" target="_blank" rel="external">http://www.w3.org/2001/vcard-rdf/3.0#FN&quot;。属性的值是文字&quot;John</a> Smith”。</vcard：fn></p>
<p><vcard：n>元素是一个资源。在这种情况下，资源由相对URI引用表示。 RDF通过将其与当前文档的基本URI连接，将其转换为绝对URI引用。</vcard：n></p>
<p>此RDF XML中有错误;它不完全代表我们创建的模型。模型中的空白节点已经被赋予URI引用。它不再是空白。 RDF / XML语法不能表示所有RDF模型;例如它不能表示作为两个语句的对象的空白节点。我们用来编写这个RDF / XML的’dumb’作者没有尝试正确地写入可以正确写入的Models子集。它为每个空白节点提供一个URI，使其不再为空。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// now write the model in XML form to a file</span><br><span class="line">model.write(System.out, &quot;RDF/XML-ABBREV&quot;);</span><br><span class="line"></span><br><span class="line">// now write the model in N-TRIPLES form to a file</span><br><span class="line">model.write(System.out, &quot;N-TRIPLES&quot;);</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&lt;rdf:RDF</span><br><span class="line">    xmlns:rdf=&quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#&quot;</span><br><span class="line">    xmlns:vcard=&quot;http://www.w3.org/2001/vcard-rdf/3.0#&quot;&gt;</span><br><span class="line">  &lt;rdf:Description rdf:about=&quot;http://somewhere/JohnSmith&quot;&gt;</span><br><span class="line">    &lt;vcard:N rdf:parseType=&quot;Resource&quot;&gt;</span><br><span class="line">      &lt;vcard:Family&gt;Smith&lt;/vcard:Family&gt;</span><br><span class="line">      &lt;vcard:Given&gt;John&lt;/vcard:Given&gt;</span><br><span class="line">    &lt;/vcard:N&gt;</span><br><span class="line">    &lt;vcard:FN&gt;John Smith&lt;/vcard:FN&gt;</span><br><span class="line">  &lt;/rdf:Description&gt;</span><br><span class="line">&lt;/rdf:RDF&gt;</span><br><span class="line">&lt;http://somewhere/JohnSmith&gt; &lt;http://www.w3.org/2001/vcard-rdf/3.0#N&gt; _:BX2D71b38d8eX3A1589596bd63X3AX2D7fff .</span><br><span class="line">&lt;http://somewhere/JohnSmith&gt; &lt;http://www.w3.org/2001/vcard-rdf/3.0#FN&gt; &quot;John Smith&quot; .</span><br><span class="line">_:BX2D71b38d8eX3A1589596bd63X3AX2D7fff &lt;http://www.w3.org/2001/vcard-rdf/3.0#Family&gt; &quot;Smith&quot; .</span><br><span class="line">_:BX2D71b38d8eX3A1589596bd63X3AX2D7fff &lt;http://www.w3.org/2001/vcard-rdf/3.0#Given&gt; &quot;John&quot; .</span><br></pre></td></tr></table></figure>
<h3 id="读取RDF"><a href="#读取RDF" class="headerlink" title="读取RDF"></a>读取RDF</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">static final String inputFileName = &quot;vc-db-1.rdf&quot;;</span><br><span class="line"></span><br><span class="line"> // create an empty model</span><br><span class="line"> Model model = ModelFactory.createDefaultModel();</span><br><span class="line"></span><br><span class="line"> // use the FileManager to find the input file</span><br><span class="line"> InputStream in = FileManager.get().open( inputFileName );</span><br><span class="line">if (in == null) &#123;</span><br><span class="line">    throw new IllegalArgumentException(</span><br><span class="line">                                 &quot;File: &quot; + inputFileName + &quot; not found&quot;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// read the RDF/XML file</span><br><span class="line">model.read(in, null);</span><br><span class="line"></span><br><span class="line">// write it to standard out</span><br><span class="line">model.write(System.out);</span><br></pre></td></tr></table></figure>
<p><strong>读取结果</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">&lt;rdf:RDF</span><br><span class="line">  xmlns:rdf=&apos;http://www.w3.org/1999/02/22-rdf-syntax-ns#&apos;</span><br><span class="line">  xmlns:vcard=&apos;http://www.w3.org/2001/vcard-rdf/3.0#&apos;</span><br><span class="line"> &gt;</span><br><span class="line">  &lt;rdf:Description rdf:nodeID=&quot;A0&quot;&gt;</span><br><span class="line">    &lt;vcard:Family&gt;Smith&lt;/vcard:Family&gt;</span><br><span class="line">    &lt;vcard:Given&gt;John&lt;/vcard:Given&gt;</span><br><span class="line">  &lt;/rdf:Description&gt;</span><br><span class="line">  &lt;rdf:Description rdf:about=&apos;http://somewhere/JohnSmith/&apos;&gt;</span><br><span class="line">    &lt;vcard:FN&gt;John Smith&lt;/vcard:FN&gt;</span><br><span class="line">    &lt;vcard:N rdf:nodeID=&quot;A0&quot;/&gt;</span><br><span class="line">  &lt;/rdf:Description&gt;</span><br><span class="line">  &lt;rdf:Description rdf:about=&apos;http://somewhere/SarahJones/&apos;&gt;</span><br><span class="line">    &lt;vcard:FN&gt;Sarah Jones&lt;/vcard:FN&gt;</span><br><span class="line">    &lt;vcard:N rdf:nodeID=&quot;A1&quot;/&gt;</span><br><span class="line">  &lt;/rdf:Description&gt;</span><br><span class="line">  &lt;rdf:Description rdf:about=&apos;http://somewhere/MattJones/&apos;&gt;</span><br><span class="line">    &lt;vcard:FN&gt;Matt Jones&lt;/vcard:FN&gt;</span><br><span class="line">    &lt;vcard:N rdf:nodeID=&quot;A2&quot;/&gt;</span><br><span class="line">  &lt;/rdf:Description&gt;</span><br><span class="line">  &lt;rdf:Description rdf:nodeID=&quot;A3&quot;&gt;</span><br><span class="line">    &lt;vcard:Family&gt;Smith&lt;/vcard:Family&gt;</span><br><span class="line">    &lt;vcard:Given&gt;Rebecca&lt;/vcard:Given&gt;</span><br><span class="line">  &lt;/rdf:Description&gt;</span><br><span class="line">  &lt;rdf:Description rdf:nodeID=&quot;A1&quot;&gt;</span><br><span class="line">    &lt;vcard:Family&gt;Jones&lt;/vcard:Family&gt;</span><br><span class="line">    &lt;vcard:Given&gt;Sarah&lt;/vcard:Given&gt;</span><br><span class="line">  &lt;/rdf:Description&gt;</span><br><span class="line">  &lt;rdf:Description rdf:nodeID=&quot;A2&quot;&gt;</span><br><span class="line">    &lt;vcard:Family&gt;Jones&lt;/vcard:Family&gt;</span><br><span class="line">    &lt;vcard:Given&gt;Matthew&lt;/vcard:Given&gt;</span><br><span class="line">  &lt;/rdf:Description&gt;</span><br><span class="line">  &lt;rdf:Description rdf:about=&apos;http://somewhere/RebeccaSmith/&apos;&gt;</span><br><span class="line">    &lt;vcard:FN&gt;Becky Smith&lt;/vcard:FN&gt;</span><br><span class="line">    &lt;vcard:N rdf:nodeID=&quot;A3&quot;/&gt;</span><br><span class="line">  &lt;/rdf:Description&gt;</span><br><span class="line">&lt;/rdf:RDF&gt;</span><br></pre></td></tr></table></figure></p>
<h3 id="Jena-RDF包"><a href="#Jena-RDF包" class="headerlink" title="Jena RDF包"></a>Jena RDF包</h3><p>Jena是用于语义Web应用程序的Java API。应用程序开发人员的关键RDF包是org.apache.jena.rdf.model。 API已经根据接口进行了定义，以便应用程序代码可以在不改变的情况下与不同的实现工作。此包包含用于表示模型，资源，属性，文字，语句和RDF的所有其他关键概念的接口，以及用于创建模型的ModelFactory。所以应用程序代码保持独立的实现，最好是尽可能使用接口，而不是特定的类实现。</p>
<p>org.apache.jena.tutorial包包含本教程中使用的所有示例的工作源代码。</p>
<p>org.apache.jena … impl包包含可能对许多实现通用的实现类。例如，它们定义类ResourceImpl，PropertyImpl和LiteralImpl，它们可以被不同的实现直接使用或子类化。应用程序应该很少，如果有的话，直接使用这些类。例如，不是创建ResourceImpl的新实例，最好使用正在使用的任何模型的createResource方法。这样，如果模型实现使用了Resource的优化实现，则两种类型之间不需要转换。</p>
<h3 id="浏览模型"><a href="#浏览模型" class="headerlink" title="浏览模型"></a>浏览模型</h3><p>给定资源的URI，可以使用Model.getResource（String uri）方法从模型中检索资源对象。 此方法定义为返回一个Resource对象（如果模型中存在），否则创建一个新对象。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">static final String inputFileName = &quot;vc-db-1.rdf&quot;;</span><br><span class="line">    static final String johnSmithURI = &quot;http://somewhere/JohnSmith/&quot;;</span><br><span class="line">    </span><br><span class="line">    public static void main (String args[]) &#123;</span><br><span class="line">        // create an empty model</span><br><span class="line">        Model model = ModelFactory.createDefaultModel();</span><br><span class="line">       </span><br><span class="line">        // use the FileManager to find the input file</span><br><span class="line">        InputStream in = FileManager.get().open(inputFileName);</span><br><span class="line">        if (in == null) &#123;</span><br><span class="line">            throw new IllegalArgumentException( &quot;File: &quot; + inputFileName + &quot; not found&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        // read the RDF/XML file</span><br><span class="line">        model.read(new InputStreamReader(in), &quot;&quot;);</span><br><span class="line">        </span><br><span class="line">        // retrieve the Adam Smith vcard resource from the model</span><br><span class="line">        Resource vcard = model.getResource(johnSmithURI);</span><br><span class="line"></span><br><span class="line">        // retrieve the value of the N property</span><br><span class="line">        Resource name = (Resource) vcard.getRequiredProperty(VCARD.N)</span><br><span class="line">                                        .getObject();</span><br><span class="line">        // retrieve the given name property</span><br><span class="line">        String fullName = vcard.getRequiredProperty(VCARD.FN)</span><br><span class="line">                               .getString();</span><br><span class="line">        // add two nick name properties to vcard</span><br><span class="line">		// 获取johnSmithURI资源后，对其添加两个nickname属性</span><br><span class="line">        vcard.addProperty(VCARD.NICKNAME, &quot;Smithy&quot;)</span><br><span class="line">             .addProperty(VCARD.NICKNAME, &quot;Adman&quot;);</span><br><span class="line">        </span><br><span class="line">        // set up the output</span><br><span class="line">        System.out.println(&quot;The nicknames of \&quot;&quot; + fullName + &quot;\&quot; are:&quot;);</span><br><span class="line">        // list the nicknames</span><br><span class="line">		//返回声明迭代器，获取对象</span><br><span class="line">        StmtIterator iter = vcard.listProperties(VCARD.NICKNAME);</span><br><span class="line">        while (iter.hasNext()) &#123;</span><br><span class="line">            System.out.println(&quot;    &quot; + iter.nextStatement().getObject()</span><br><span class="line">                                            .toString());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">The nicknames of &quot;John Smith&quot; are:</span><br><span class="line">    Adman</span><br><span class="line">    Smithy</span><br></pre></td></tr></table></figure>
<h3 id="查询模型"><a href="#查询模型" class="headerlink" title="查询模型"></a>查询模型</h3><p>上一节讨论从具有已知URI的资源导航模型的情况。 本节介绍搜索模型。 核心Jena API仅支持有限的查询原语。 更强大的查询功能在SPARQL中。</p>
<p>Model.listStatements（）方法列出了模型中的所有语句，也许是查询模型的最粗糙的方法。 它的使用不推荐在非常大的模型。 Model.listSubjects（）是类似的，但返回一个迭代器在所有具有属性的资源，即一些语句的主题。</p>
<p>Model.listSubjectsWithProperty（Property p，RDFNode o）将返回所有资源的迭代器，这些资源具有值为o的属性p。 如果我们假设只有vcard资源会有vcard：FN属性，并且在我们的数据中，所有这些资源都有这样的属性，那么我们可以找到所有的vcards：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">static final String inputFileName = &quot;vc-db-1.rdf&quot;;</span><br><span class="line">   </span><br><span class="line">   public static void main (String args[]) &#123;</span><br><span class="line">       // create an empty model</span><br><span class="line">       Model model = ModelFactory.createDefaultModel();</span><br><span class="line">      </span><br><span class="line">       // use the FileManager to find the input file</span><br><span class="line">       InputStream in = FileManager.get().open(inputFileName);</span><br><span class="line">       if (in == null) &#123;</span><br><span class="line">           throw new IllegalArgumentException( &quot;File: &quot; + inputFileName + &quot; not found&quot;);</span><br><span class="line">       &#125;</span><br><span class="line">       </span><br><span class="line">       // read the RDF/XML file</span><br><span class="line">       model.read( in, &quot;&quot;);</span><br><span class="line">       </span><br><span class="line">       // select all the resources with a VCARD.FN property</span><br><span class="line">       ResIterator iter = model.listResourcesWithProperty(VCARD.FN);</span><br><span class="line">       if (iter.hasNext()) &#123;</span><br><span class="line">           System.out.println(&quot;The database contains vcards for:&quot;);</span><br><span class="line">           while (iter.hasNext()) &#123;</span><br><span class="line">               System.out.println(&quot;  &quot; + iter.nextResource()</span><br><span class="line">                                             .getRequiredProperty(VCARD.FN)</span><br><span class="line">                                             .getString() );</span><br><span class="line">           &#125;</span><br><span class="line">       &#125; else &#123;</span><br><span class="line">           System.out.println(&quot;No vcards were found in the database&quot;);</span><br><span class="line">       &#125;            </span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">The database contains vcards for:</span><br><span class="line">  Sarah Jones</span><br><span class="line">  John Smith</span><br><span class="line">  Becky Smith</span><br><span class="line">  Matt Jones</span><br></pre></td></tr></table></figure>
<h3 id="模型操作"><a href="#模型操作" class="headerlink" title="模型操作"></a>模型操作</h3><p>Jena提供了操作模型作为一个整体的三个操作,分別是并集，交集和差的运算。</p>
<p>两个模型的并集是表示每个模型的语句集合的合并。这是RDF设计支持的关键操作之一。它允许合并来自不同数据源的数据。 考虑以下两个模型：<br><img src="http://i.imgur.com/F1ooVdI.png" alt=""> <img src="http://i.imgur.com/HDmwweL.png" alt=""></p>
<p>当这些被合并时，两个http：//…JohnSmith节点被合并成一个，并且vcard：FN 弧被丢弃以产生：<br><img src="http://i.imgur.com/6cZO0rR.png" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">static final String inputFileName1 = &quot;vc-db-3.rdf&quot;;    </span><br><span class="line"> static final String inputFileName2 = &quot;vc-db-4.rdf&quot;;</span><br><span class="line"> </span><br><span class="line"> public static void main (String args[]) &#123;</span><br><span class="line">     // create an empty model</span><br><span class="line">     Model model1 = ModelFactory.createDefaultModel();</span><br><span class="line">     Model model2 = ModelFactory.createDefaultModel();</span><br><span class="line">    </span><br><span class="line">     // use the class loader to find the input file</span><br><span class="line">     InputStream in1 = FileManager.get().open(inputFileName1);</span><br><span class="line">     if (in1 == null) &#123;</span><br><span class="line">         throw new IllegalArgumentException( &quot;File: &quot; + inputFileName1 + &quot; not found&quot;);</span><br><span class="line">     &#125;</span><br><span class="line">     InputStream in2 = FileManager.get().open(inputFileName2);</span><br><span class="line">     if (in2 == null) &#123;</span><br><span class="line">         throw new IllegalArgumentException( &quot;File: &quot; + inputFileName2 + &quot; not found&quot;);</span><br><span class="line">     &#125;</span><br><span class="line">     </span><br><span class="line">     // read the RDF/XML files</span><br><span class="line">     model1.read( in1, &quot;&quot; );</span><br><span class="line">     model2.read( in2, &quot;&quot; );</span><br><span class="line">     </span><br><span class="line">     // merge the graphs</span><br><span class="line">     Model model = model1.union(model2);</span><br><span class="line">     </span><br><span class="line">     // print the graph as RDF/XML</span><br><span class="line">     model.write(System.out, &quot;RDF/XML-ABBREV&quot;);</span><br><span class="line">     System.out.println();</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;rdf:RDF</span><br><span class="line">    xmlns:rdf=&quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#&quot;</span><br><span class="line">    xmlns:vcard=&quot;http://www.w3.org/2001/vcard-rdf/3.0#&quot;&gt;</span><br><span class="line">  &lt;rdf:Description rdf:about=&quot;http://somewhere/JohnSmith/&quot;&gt;</span><br><span class="line">    &lt;vcard:N rdf:parseType=&quot;Resource&quot;&gt;</span><br><span class="line">      &lt;vcard:Given&gt;John&lt;/vcard:Given&gt;</span><br><span class="line">      &lt;vcard:Family&gt;Smith&lt;/vcard:Family&gt;</span><br><span class="line">    &lt;/vcard:N&gt;</span><br><span class="line">    &lt;vcard:EMAIL&gt;</span><br><span class="line">      &lt;vcard:internet&gt;</span><br><span class="line">        &lt;rdf:value&gt;John@somewhere.com&lt;/rdf:value&gt;</span><br><span class="line">      &lt;/vcard:internet&gt;</span><br><span class="line">    &lt;/vcard:EMAIL&gt;</span><br><span class="line">    &lt;vcard:FN&gt;John Smith&lt;/vcard:FN&gt;</span><br><span class="line">  &lt;/rdf:Description&gt;</span><br><span class="line">&lt;/rdf:RDF&gt;</span><br></pre></td></tr></table></figure>
<h3 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h3><p>RDF定义了一种特殊的资源来表示事物的集合。 这些资源称为容器。 容器的成员可以是文字或资源。 有三种容器：</p>
<p>BAG是一个无序的集合<br>ALT是旨在表示可选的无序集合<br>SEQ是有序集合<br>容器由资源表示。 该资源将有一个rdf：type属性，其值应为rdf：Bag，rdf：Alt或rdf：Seq之一，或其中一个的子类，具体取决于容器的类型。 容器的第一个成员是容器的rdf：_1属性的值; 容器的第二个成员是容器的rdf：_2属性的值，等等。 rdf：_nnn属性被称为序数属性。</p>
<p>例如，包含Smith的vcards的简单包的模型可能如下所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">static final String inputFileName = &quot;vc-db-1.rdf&quot;;</span><br><span class="line">   </span><br><span class="line">   public static void main (String args[]) &#123;</span><br><span class="line">       // create an empty model</span><br><span class="line">       Model model = ModelFactory.createDefaultModel();</span><br><span class="line">      </span><br><span class="line">       // use the class loader to find the input file</span><br><span class="line">       InputStream in = FileManager.get().open( inputFileName );</span><br><span class="line">       if (in == null) &#123;</span><br><span class="line">           throw new IllegalArgumentException( &quot;File: &quot; + inputFileName + &quot; not found&quot;);</span><br><span class="line">       &#125;</span><br><span class="line">       </span><br><span class="line">       // read the RDF/XML file</span><br><span class="line">       model.read(new InputStreamReader(in), &quot;&quot;);</span><br><span class="line">       </span><br><span class="line">       // create a bag</span><br><span class="line">       Bag smiths = model.createBag();</span><br><span class="line">       </span><br><span class="line">       // select all the resources with a VCARD.FN property</span><br><span class="line">       // whose value ends with &quot;Smith&quot;</span><br><span class="line">       StmtIterator iter = model.listStatements(</span><br><span class="line">           new </span><br><span class="line">               SimpleSelector(null, VCARD.FN, (RDFNode) null) &#123;</span><br><span class="line">                   @Override</span><br><span class="line">                   public boolean selects(Statement s) &#123;</span><br><span class="line">                           return s.getString().endsWith(&quot;Smith&quot;);</span><br><span class="line">                   &#125;</span><br><span class="line">               &#125;);</span><br><span class="line">       // add the Smith&apos;s to the bag</span><br><span class="line">       while (iter.hasNext()) &#123;</span><br><span class="line">           smiths.add( iter.nextStatement().getSubject());</span><br><span class="line">       &#125;</span><br><span class="line">       </span><br><span class="line">       // print the graph as RDF/XML</span><br><span class="line">       model.write(new PrintWriter(System.out));</span><br><span class="line">       System.out.println();</span><br><span class="line">       </span><br><span class="line">       // print out the members of the bag</span><br><span class="line">       NodeIterator iter2 = smiths.iterator();</span><br><span class="line">       if (iter2.hasNext()) &#123;</span><br><span class="line">           System.out.println(&quot;The bag contains:&quot;);</span><br><span class="line">           while (iter2.hasNext()) &#123;</span><br><span class="line">               System.out.println(&quot;  &quot; +</span><br><span class="line">                   ((Resource) iter2.next())</span><br><span class="line">                                    .getRequiredProperty(VCARD.FN)</span><br><span class="line">                                    .getString());</span><br><span class="line">           &#125;</span><br><span class="line">       &#125; else &#123;</span><br><span class="line">           System.out.println(&quot;The bag is empty&quot;);</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">&lt;rdf:RDF</span><br><span class="line">    xmlns:rdf=&quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#&quot;</span><br><span class="line">    xmlns:vcard=&quot;http://www.w3.org/2001/vcard-rdf/3.0#&quot;&gt;</span><br><span class="line">  &lt;rdf:Description rdf:about=&quot;http://somewhere/SarahJones/&quot;&gt;</span><br><span class="line">    &lt;vcard:N rdf:parseType=&quot;Resource&quot;&gt;</span><br><span class="line">      &lt;vcard:Given&gt;Sarah&lt;/vcard:Given&gt;</span><br><span class="line">      &lt;vcard:Family&gt;Jones&lt;/vcard:Family&gt;</span><br><span class="line">    &lt;/vcard:N&gt;</span><br><span class="line">    &lt;vcard:FN&gt;Sarah Jones&lt;/vcard:FN&gt;</span><br><span class="line">  &lt;/rdf:Description&gt;</span><br><span class="line">  &lt;rdf:Bag&gt;</span><br><span class="line">    &lt;rdf:li&gt;</span><br><span class="line">      &lt;rdf:Description rdf:about=&quot;http://somewhere/RebeccaSmith/&quot;&gt;</span><br><span class="line">        &lt;vcard:N rdf:parseType=&quot;Resource&quot;&gt;</span><br><span class="line">          &lt;vcard:Given&gt;Rebecca&lt;/vcard:Given&gt;</span><br><span class="line">          &lt;vcard:Family&gt;Smith&lt;/vcard:Family&gt;</span><br><span class="line">        &lt;/vcard:N&gt;</span><br><span class="line">        &lt;vcard:FN&gt;Becky Smith&lt;/vcard:FN&gt;</span><br><span class="line">      &lt;/rdf:Description&gt;</span><br><span class="line">    &lt;/rdf:li&gt;</span><br><span class="line">    &lt;rdf:li&gt;</span><br><span class="line">      &lt;rdf:Description rdf:about=&quot;http://somewhere/JohnSmith/&quot;&gt;</span><br><span class="line">        &lt;vcard:N rdf:parseType=&quot;Resource&quot;&gt;</span><br><span class="line">          &lt;vcard:Given&gt;John&lt;/vcard:Given&gt;</span><br><span class="line">          &lt;vcard:Family&gt;Smith&lt;/vcard:Family&gt;</span><br><span class="line">        &lt;/vcard:N&gt;</span><br><span class="line">        &lt;vcard:FN&gt;John Smith&lt;/vcard:FN&gt;</span><br><span class="line">      &lt;/rdf:Description&gt;</span><br><span class="line">    &lt;/rdf:li&gt;</span><br><span class="line">  &lt;/rdf:Bag&gt;</span><br><span class="line">  &lt;rdf:Description rdf:about=&quot;http://somewhere/MattJones/&quot;&gt;</span><br><span class="line">    &lt;vcard:N rdf:parseType=&quot;Resource&quot;&gt;</span><br><span class="line">      &lt;vcard:Given&gt;Matthew&lt;/vcard:Given&gt;</span><br><span class="line">      &lt;vcard:Family&gt;Jones&lt;/vcard:Family&gt;</span><br><span class="line">    &lt;/vcard:N&gt;</span><br><span class="line">    &lt;vcard:FN&gt;Matt Jones&lt;/vcard:FN&gt;</span><br><span class="line">  &lt;/rdf:Description&gt;</span><br><span class="line">&lt;/rdf:RDF&gt;</span><br><span class="line"></span><br><span class="line">The bag contains:</span><br><span class="line">  Becky Smith</span><br><span class="line">  John Smith</span><br></pre></td></tr></table></figure>
<h3 id="词汇表"><a href="#词汇表" class="headerlink" title="词汇表"></a>词汇表</h3><p>空白节点（Blank Node）<br>表示资源，但不指示资源的URI。空白节点表现为一阶逻辑中存在的合格变量。<br>Dublin Core<br>关于Web资源的元数据标准。更多信息可以在Dublin Core网站上找到。<br>文字（Literal）<br>可以是属性值的字符串。<br>对象（Object）<br>三元组的一部分，即语句的值。<br>谓词（Predicate）<br>三元组的属性部分。<br>属性（Property）<br>属性是资源的属性。例如DC.title是一个属性，和RDF.type一样。<br>资源（Resource）<br>一些实体。它可以是诸如网页的web资源，或者它可以是具体的物理事物，例如树或汽车。它可以是一个抽象的想法，如象棋或足球。资源由URI命名。<br>声明（Statement）<br>RDF模型中的弧，通常被解释为事实。<br>主语Subject）<br>作为RDF模型中的弧源的资源<br>三元组（Triple）<br>包含主语，谓词和对象的结构。语句的另一个术语。</p>
<h3 id="脚注"><a href="#脚注" class="headerlink" title="脚注"></a>脚注</h3><p>RDF资源的标识符可以包括片段标识符，例如， http：// hostname / rdf / tutorial /＃ch-简介，因此，严格地说，RDF资源由URI引用标识。<br>除了作为一个字符串，字面量还有一个可选的语言编码来表示字符串的语言。例如，文字“two”对于英语可能具有“en”的语言编码，而对于法国，文字“deux”可能具有“fr”的语言编码。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/11/26/Distributed Cache在mapreduce中读取小文件/" itemprop="url">
                  Distributed Cache在mapreduce中读取小文件
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-11-26T22:48:13+08:00" content="2016-11-26">
              2016-11-26
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/11/26/Distributed Cache在mapreduce中读取小文件/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/11/26/Distributed Cache在mapreduce中读取小文件/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Distributed Cache 在 MapReduce 任务中应用很广， 它可以大大提高一些被频繁读取文件的访问速度。被添加到 Distributed Cache 的文件会被拷贝到 Mapper 和 Reducer 的运行目录中。</p>
<p><strong>在job添加如下方法 </strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">remoteReGamePath为hdfs文件路径字符串</span><br><span class="line">job.addCacheFile(new Path(remoteReGamePath).toUri());</span><br></pre></td></tr></table></figure></p>
<p><strong>以下例子为在map中读取此文件并存入集合</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">private Set&lt;String&gt; recommendGame = new HashSet&lt;String&gt;();</span><br><span class="line">/**</span><br><span class="line">		 * 读取推荐游戏文件</span><br><span class="line">		 * </span><br><span class="line">		 * @param uri</span><br><span class="line">		 */</span><br><span class="line">		private void readReGame(URI uri) &#123;</span><br><span class="line">			try &#123;</span><br><span class="line">				Path patternsPath = new Path(uri.getPath());</span><br><span class="line">				String patternsFileName = patternsPath.getName().toString();</span><br><span class="line">				BufferedReader reader = new BufferedReader(new FileReader(</span><br><span class="line">						patternsFileName));</span><br><span class="line">				String line;</span><br><span class="line">				while ((line = reader.readLine()) != null) &#123;</span><br><span class="line">					// TODO: your code here</span><br><span class="line">					//</span><br><span class="line">					recommendGame.add(line.split(&quot;,&quot;)[0]);</span><br><span class="line">				&#125;</span><br><span class="line">				reader.close();</span><br><span class="line"></span><br><span class="line">			&#125; catch (FileNotFoundException e) &#123;</span><br><span class="line">				// TODO Auto-generated catch block</span><br><span class="line">				e.printStackTrace();</span><br><span class="line">			&#125; catch (IOException e) &#123;</span><br><span class="line">				// TODO Auto-generated catch block</span><br><span class="line">				e.printStackTrace();</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		@Override</span><br><span class="line">		protected void setup(</span><br><span class="line">				Mapper&lt;LongWritable, Text, Text, Text&gt;.Context context)</span><br><span class="line">				throws IOException, InterruptedException &#123;</span><br><span class="line">			// TODO Auto-generated method stub</span><br><span class="line">			super.setup(context);</span><br><span class="line">			//获取cache  uri</span><br><span class="line">			URI[] uri = context.getCacheFiles();</span><br><span class="line"></span><br><span class="line">			readReGame(uri[0]);</span><br><span class="line"></span><br><span class="line">		&#125;</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/11/26/mapreduce多目录输出笔记/" itemprop="url">
                  mapreduce多目录输出笔记
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-11-26T22:23:21+08:00" content="2016-11-26">
              2016-11-26
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/11/26/mapreduce多目录输出笔记/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/11/26/mapreduce多目录输出笔记/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="使用MultipleOutputs实现多目录-文件输出"><a href="#使用MultipleOutputs实现多目录-文件输出" class="headerlink" title="使用MultipleOutputs实现多目录/文件输出"></a>使用MultipleOutputs实现多目录/文件输出</h3><p><code>org.apache.hadoop.mapreduce.lib.output.MultipleOutputs</code></p>
<p><strong>在map或者reduce类中加入如下方法</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">private MultipleOutputs&lt;Text, NullWritable&gt; mos;</span><br><span class="line"></span><br><span class="line">	@Override</span><br><span class="line">	protected void setup(Reducer&lt;Text, NullWritable, Text, NullWritable&gt;.Context context)</span><br><span class="line">			throws IOException, InterruptedException &#123;</span><br><span class="line">		// TODO Auto-generated method stub</span><br><span class="line">		super.setup(context);</span><br><span class="line">		mos = new MultipleOutputs&lt;Text, NullWritable&gt;(context);// 初始化mos</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	@Override</span><br><span class="line">	protected void cleanup(Reducer&lt;Text, NullWritable, Text, NullWritable&gt;.Context context)</span><br><span class="line">			throws IOException, InterruptedException &#123;</span><br><span class="line">		// TODO Auto-generated method stub</span><br><span class="line">		super.cleanup(context);</span><br><span class="line">		mos.close();</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>在需要输出数据的地方，可以使用定义好的 mos 进行输出</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mos.write(&quot;outputName&quot;, key, value);</span><br><span class="line">mos.write(&quot;outputName&quot;, key, value, &quot;filePrefix&quot;); </span><br><span class="line">mos.write(&quot;outputName&quot;, key, value, &quot;path/filePrefix&quot;);//到文件夹</span><br></pre></td></tr></table></figure></p>
<p><strong>在Job Driver 时定义一些 Named Output</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">MultipleOutputs.addNamedOutput(job, &quot;outputXName&quot;,</span><br><span class="line">    XXXOutputFormat.class, OutputXKey.class, OutputXValue.class);</span><br><span class="line">MultipleOutputs.addNamedOutput(job, &quot;outputYName&quot;,</span><br><span class="line">    YYYOutputFormat.class, OutputYKey.class, OutputYValue.class);</span><br></pre></td></tr></table></figure></p>
<p><strong>取消类似part-r-00000的空文件</strong><br><code>LazyOutputFormat.setOutputFormatClass(job, TextOutputFormat.class)</code><br><strong>例子</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br></pre></td><td class="code"><pre><span class="line">package com.hdu.recommend.mr;</span><br><span class="line"></span><br><span class="line">import java.io.IOException;</span><br><span class="line"></span><br><span class="line">import org.apache.hadoop.conf.Configuration;</span><br><span class="line">import org.apache.hadoop.fs.Path;</span><br><span class="line">import org.apache.hadoop.io.LongWritable;</span><br><span class="line">import org.apache.hadoop.io.NullWritable;</span><br><span class="line">import org.apache.hadoop.io.Text;</span><br><span class="line">import org.apache.hadoop.mapreduce.Job;</span><br><span class="line">import org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line">import org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.output.MultipleOutputs;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.output.NullOutputFormat;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;</span><br><span class="line">import org.apache.hadoop.yarn.conf.YarnConfiguration;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> * @author Skye</span><br><span class="line"> *</span><br><span class="line"> */</span><br><span class="line">public class DataCleanIconAndWeb &#123;</span><br><span class="line">	public static class QLMapper extends</span><br><span class="line">			Mapper&lt;LongWritable, Text, Text, NullWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">		private String webGame = &quot;网页游戏&quot;;</span><br><span class="line"></span><br><span class="line">		Text outputValue = new Text();</span><br><span class="line">		// 设置多文件输出</span><br><span class="line">		private MultipleOutputs&lt;Text,NullWritable&gt; mos;</span><br><span class="line">		@Override</span><br><span class="line">		protected void setup(Mapper&lt;LongWritable, Text, Text, NullWritable&gt;.Context context)</span><br><span class="line">				throws IOException, InterruptedException &#123;</span><br><span class="line">			// TODO Auto-generated method stub</span><br><span class="line">			super.setup(context);</span><br><span class="line">			mos = new MultipleOutputs&lt;Text, NullWritable&gt;(context);// 初始化mos</span><br><span class="line">		&#125;</span><br><span class="line">		@Override</span><br><span class="line">		protected void cleanup(Mapper&lt;LongWritable, Text, Text, NullWritable&gt;.Context context)</span><br><span class="line">				throws IOException, InterruptedException &#123;</span><br><span class="line">			// TODO Auto-generated method stub</span><br><span class="line">			super.cleanup(context);</span><br><span class="line">			mos.close();</span><br><span class="line">		&#125;</span><br><span class="line">		@Override</span><br><span class="line">		protected void map(LongWritable key, Text value, Context context)</span><br><span class="line">				throws IOException, InterruptedException &#123;</span><br><span class="line">			// 接收数据v1</span><br><span class="line">			String line = value.toString();</span><br><span class="line">			// 切分数据</span><br><span class="line">			String[] words = line.split(&quot;&quot;);</span><br><span class="line">			// String[] words = line.split(&quot;\t&quot;);</span><br><span class="line">			boolean isWeb = false;</span><br><span class="line">			boolean flag = true;</span><br><span class="line">			</span><br><span class="line">			//一系列处理代码</span><br><span class="line">			//***</span><br><span class="line">			//***</span><br><span class="line">			//***</span><br><span class="line">			String action = words[1] + &quot;\t&quot; + words[0] + &quot;\t&quot; + words[2]</span><br><span class="line">						+ &quot;\t&quot; + words[3] + &quot;\t&quot; + words[5];</span><br><span class="line"></span><br><span class="line">			outputValue.set(action);</span><br><span class="line">			mos.write(&quot;iconRecord&quot;, outputValue, NullWritable.get(),&quot;iconRecord/icon&quot;);</span><br><span class="line">			</span><br><span class="line">			</span><br><span class="line">	</span><br><span class="line">			String action = words[1] + &quot;\t&quot; + words[0] + &quot;\t&quot;</span><br><span class="line">							+ words[2] + &quot;\t&quot; + words[3] + &quot;\t&quot; + words[4]</span><br><span class="line">							+ &quot;\t&quot; + words[5];</span><br><span class="line"></span><br><span class="line">			outputValue.set(action);</span><br><span class="line">			mos.write( &quot;webRecord&quot;,outputValue, NullWritable.get(),&quot;webRecord/web&quot;);</span><br><span class="line">				</span><br><span class="line"></span><br><span class="line">			</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	</span><br><span class="line"></span><br><span class="line">	public static void run(String originalDataPath, String dataCleanOutputFile)</span><br><span class="line">			throws Exception &#123;</span><br><span class="line"></span><br><span class="line">		// 构建Job对象</span><br><span class="line">		Configuration conf = new Configuration();</span><br><span class="line"></span><br><span class="line">		Job job = Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">		// 注意：main方法所在的类</span><br><span class="line">		job.setJarByClass(DataCleanIconAndWeb.class);</span><br><span class="line">		job.getConfiguration().setBoolean(&quot;mapreduce.output.fileoutputformat.compress&quot;, false);</span><br><span class="line">		job.getConfiguration().setStrings(</span><br><span class="line">				&quot;mapreduce.reduce.shuffle.input.buffer.percent&quot;, &quot;0.1&quot;);</span><br><span class="line">		job.getConfiguration().setBoolean(&quot;mapreduce.output.fileoutputformat.compress&quot;, false);</span><br><span class="line">		job.setNumReduceTasks(3);</span><br><span class="line"></span><br><span class="line">		// 设置Mapper相关属性</span><br><span class="line">		job.setMapperClass(QLMapper.class);</span><br><span class="line">		job.setMapOutputKeyClass(Text.class);</span><br><span class="line">		job.setMapOutputValueClass(NullWritable.class);</span><br><span class="line"></span><br><span class="line">		</span><br><span class="line">		FileInputFormat.setInputPaths(job, new Path(originalDataPath));</span><br><span class="line"></span><br><span class="line">		</span><br><span class="line"></span><br><span class="line">		// 设置Reducer相关属性</span><br><span class="line">		</span><br><span class="line">		job.setOutputKeyClass(Text.class);</span><br><span class="line">		job.setOutputValueClass(NullWritable.class);</span><br><span class="line"></span><br><span class="line">		FileOutputFormat.setOutputPath(job, new Path(dataCleanOutputFile));</span><br><span class="line">		</span><br><span class="line">		MultipleOutputs.addNamedOutput(job, &quot;iconRecord&quot;,</span><br><span class="line">				TextOutputFormat.class, Text.class, NullWritable.class);</span><br><span class="line">		MultipleOutputs.addNamedOutput(job, &quot;webRecord&quot;,</span><br><span class="line">				TextOutputFormat.class, Text.class, NullWritable.class);</span><br><span class="line">		</span><br><span class="line">		// 文件格式</span><br><span class="line">		job.setInputFormatClass(TextInputFormat.class);</span><br><span class="line">		//取消part-r-00000新式文件输出</span><br><span class="line">		LazyOutputFormat.setOutputFormatClass(job, TextOutputFormat.class);</span><br><span class="line">		</span><br><span class="line">		</span><br><span class="line">		//job.setOutputFormatClass(TextOutputFormat.class);</span><br><span class="line">		// 提交任务</span><br><span class="line">		job.waitForCompletion(true);</span><br><span class="line"></span><br><span class="line">		long endTime = System.currentTimeMillis();</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>参考<br><a href="http://gnailuy.com/dataplatform/2015/11/22/common-techniques-for-mapreduce/" target="_blank" rel="external">http://gnailuy.com/dataplatform/2015/11/22/common-techniques-for-mapreduce/</a><br><a href="http://blog.csdn.net/zgc625238677/article/details/51524786" target="_blank" rel="external">http://blog.csdn.net/zgc625238677/article/details/51524786</a><br><a href="https://www.iteblog.com/archives/848" target="_blank" rel="external">https://www.iteblog.com/archives/848</a></p>
</blockquote>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/11/26/hive数据导入/" itemprop="url">
                  hive数据查询导出
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-11-26T22:17:43+08:00" content="2016-11-26">
              2016-11-26
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/11/26/hive数据导入/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/11/26/hive数据导入/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="hive数据查询导出"><a href="#hive数据查询导出" class="headerlink" title="hive数据查询导出"></a>hive数据查询导出</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">insert overwrite directory &apos;/user/hdu/recommend/gameRecommendNew4/test11.26/gameprestep1&apos;</span><br><span class="line">row format delimited</span><br><span class="line">fields terminated by &apos;\t&apos;</span><br><span class="line">SELECT userid , gamename , COUNT(*) AS count , MAX(gamestarttime) AS lasttime</span><br><span class="line">FROM userdetailtwo</span><br><span class="line">GROUP BY userid , gamename</span><br></pre></td></tr></table></figure>
<p><strong>出错</strong><br><code>FAILED: ParseException line 2:0 cannot recognize input near &#39;row&#39; &#39;format&#39; &#39;delimited&#39; in statement</code></p>
<p><strong>原因</strong><br>This is because the hive query will by default use the ^ as the delimiter. You can try the same by exporting to local file system.That should be supported.</p>
<p><strong>解决</strong><br>create an external table to the location where you want your output file.Use create table as command and insert the required data into the external table.By that you will get the data in the HDFS location<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">create external table user_game_count_lasttime2(userid STRING ,gamename STRING,count INT,lasttime STRING)</span><br><span class="line">ROW FORMAT DELIMITED</span><br><span class="line">FIElDS TERMINATED BY &apos;\t&apos;</span><br><span class="line">STORED AS TEXTFILE</span><br><span class="line">LOCATION &apos;/user/hdu/recommend/gameRecommendNew4/test11.26/gameprestep1_2&apos;;</span><br><span class="line"></span><br><span class="line">insert overwrite table user_game_count_lasttime2 </span><br><span class="line">SELECT userid , gamename , COUNT(*) AS count , MAX(gamestarttime) AS lasttime</span><br><span class="line">FROM userdetailtwo</span><br><span class="line">GROUP BY userid , gamename;</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.png"
               alt="Skye" />
          <p class="site-author-name" itemprop="name">Skye</p>
          <p class="site-description motion-element" itemprop="description">学习总结 思想感悟</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">41</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">10</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">20</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/1811544100" target="_blank" title="Weibo">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                  Weibo
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://github.com/Skyexu" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
          
        </div>

        
        

        
        

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2016</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Skye</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.0.1"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"skyexu"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
  






  
  
  

  

  

</body>
</html>
